{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import PandasTools, AllChem\n",
    "from molvecgen.vectorizers import SmilesVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import pandas, numpy, random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMILESMolDataset(Dataset):\n",
    "    def __init__(self, molecules, y, vectorizer):\n",
    "        self.molecules = molecules\n",
    "        self.y = y\n",
    "        self.vectorizer = vectorizer\n",
    "    def __len__(self):\n",
    "        return len(self.molecules)\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        mols = self.molecules[idx]\n",
    "         \n",
    "        #The vectorizer was written to work with batches, \n",
    "        #but PyTorch datasets unfortunately works with single samples\n",
    "        sample = self.vectorizer.transform([mols])[0]\n",
    "        label = float(self.y[idx] > baseline)\n",
    "        #print(\"self.y[idx]\", self.y[idx], 'label', label)\n",
    "\n",
    "        target = torch.FloatTensor([label])\n",
    "        \n",
    "        return sample, label, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>mu</th>\n",
       "      <th>alpha</th>\n",
       "      <th>homo</th>\n",
       "      <th>lumo</th>\n",
       "      <th>gap</th>\n",
       "      <th>r2</th>\n",
       "      <th>zpve</th>\n",
       "      <th>cv</th>\n",
       "      <th>u0</th>\n",
       "      <th>u298</th>\n",
       "      <th>h298</th>\n",
       "      <th>g298</th>\n",
       "      <th>Molecule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Cc1cc[nH]c1</td>\n",
       "      <td>1.6978</td>\n",
       "      <td>55.32</td>\n",
       "      <td>-0.1982</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>528.9258</td>\n",
       "      <td>0.109903</td>\n",
       "      <td>20.948</td>\n",
       "      <td>-249.395323</td>\n",
       "      <td>-249.389640</td>\n",
       "      <td>-249.388696</td>\n",
       "      <td>-249.424242</td>\n",
       "      <td><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Cc1c[nH]cn1</td>\n",
       "      <td>3.3147</td>\n",
       "      <td>51.32</td>\n",
       "      <td>-0.2157</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>500.6403</td>\n",
       "      <td>0.098598</td>\n",
       "      <td>19.536</td>\n",
       "      <td>-265.457424</td>\n",
       "      <td>-265.451994</td>\n",
       "      <td>-265.451050</td>\n",
       "      <td>-265.486153</td>\n",
       "      <td><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Cc1ccoc1</td>\n",
       "      <td>0.8398</td>\n",
       "      <td>51.11</td>\n",
       "      <td>-0.2183</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>512.5694</td>\n",
       "      <td>0.097541</td>\n",
       "      <td>19.399</td>\n",
       "      <td>-269.263476</td>\n",
       "      <td>-269.258130</td>\n",
       "      <td>-269.257186</td>\n",
       "      <td>-269.292093</td>\n",
       "      <td><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          smiles      mu  alpha    homo    lumo     gap        r2      zpve  \\\n",
       "200  Cc1cc[nH]c1  1.6978  55.32 -0.1982  0.0533  0.2515  528.9258  0.109903   \n",
       "201  Cc1c[nH]cn1  3.3147  51.32 -0.2157  0.0376  0.2533  500.6403  0.098598   \n",
       "202     Cc1ccoc1  0.8398  51.11 -0.2183  0.0250  0.2434  512.5694  0.097541   \n",
       "\n",
       "         cv          u0        u298        h298        g298  \\\n",
       "200  20.948 -249.395323 -249.389640 -249.388696 -249.424242   \n",
       "201  19.536 -265.457424 -265.451994 -265.451050 -265.486153   \n",
       "202  19.399 -269.263476 -269.258130 -269.257186 -269.292093   \n",
       "\n",
       "                                              Molecule  \n",
       "200  <img data-content=\"rdkit/molecule\" src=\"data:i...  \n",
       "201  <img data-content=\"rdkit/molecule\" src=\"data:i...  \n",
       "202  <img data-content=\"rdkit/molecule\" src=\"data:i...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# whole data\n",
    "dataset = pandas.read_csv('dataset/qm9.csv')\n",
    "# small dataset\n",
    "#dataset = pandas.read_csv('dataset/qm9.csv',skiprows=lambda i: i % 2 != 0 and i == 0,nrows=6000)\n",
    "PandasTools.AddMoleculeColumnToFrame(dataset,'smiles','Molecule')\n",
    "\n",
    "# Smiles Vectorizer\n",
    "smivec = SmilesVectorizer(pad=1, leftpad=True, canonical=False, augment=True)\n",
    "smivec.fit(dataset.Molecule.values, )\n",
    "\n",
    "# test dataset\n",
    "dataset[200:203]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of x_train: 66942 x_data 66943 y_train 66942 y_data 66943\n"
     ]
    }
   ],
   "source": [
    "# x_data, y_data are the data for Discriminator\n",
    "x_train, x_data, y_train, y_data = train_test_split(dataset[['smiles','Molecule']].values, dataset['mu'].values, test_size=0.5)\n",
    "x_train = pd.DataFrame(x_train, columns=['smiles','Molecule'])\n",
    "x_data = pd.DataFrame(x_data, columns=['smiles','Molecule'])\n",
    "\n",
    "print('length of x_train:',len(x_train),'x_data',len(x_data),'y_train', len(y_train), 'y_data', len(y_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > baseline 33499  <= baseline 33444\n",
      "number_of_data 66943 max_mu 25.2022 min_mu 0.0\n"
     ]
    }
   ],
   "source": [
    "max_mu = max(y_data)\n",
    "min_mu = min(y_data)\n",
    "number_of_data = len(y_data)\n",
    "\n",
    "number1 = len(y_data[y_data > baseline])\n",
    "number2 = len(y_data[y_data <= baseline])\n",
    "print(' > baseline', number1, ' <= baseline', number2)\n",
    "print(\"number_of_data\", number_of_data, \"max_mu\", max_mu, \"min_mu\", min_mu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 1., 0., 0., 3.])\n",
      "tensor([1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# functions to generate random data\n",
    "def generate_random_seed_G(size):\n",
    "    random_data = torch.randn(size)\n",
    "    return random_data\n",
    "\n",
    "\n",
    "def generate_random_value(size):\n",
    "    random_data = np.random.randint(0, baseline * 2,(1, size))\n",
    "    random_data = torch.FloatTensor(random_data)\n",
    "    return random_data.view(-1)\n",
    "\n",
    "def generate_random_label(size):\n",
    "    random_data = np.random.randint(0, 2,(1, size))\n",
    "    random_data = torch.FloatTensor(random_data)\n",
    "    return random_data.view(-1)\n",
    "\n",
    "# Fix a bug of view\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape,\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "print(generate_random_value(5))\n",
    "print(generate_random_label(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dataset[10] (array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0]], dtype=int8), 1.0, tensor([1.])) y_data 5.0233\n"
     ]
    }
   ],
   "source": [
    "# dataset for Generator, we 'Molecule' data will be used and actually ignore y_data in Generator, instead we use\n",
    "# random value, but keeping it simple, we shape one SMILESMolDataset class.\n",
    "data_dataset = SMILESMolDataset(x_data['Molecule'], y_data, smivec)\n",
    "print('data_dataset[10]', data_dataset[10], 'y_data', y_data[10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0]], dtype=int8),\n",
       " 1.0,\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dataset for Discriminator, the Discriminator will tell Generator the result is good/bad by model the train_dataset.\n",
    "train_dataset = SMILESMolDataset(x_train['Molecule'], y_train, smivec)\n",
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a random SMILES \n",
    "def generate_random_seed(size):\n",
    "    index_list = np.random.randint(1, number_of_data, (1, size))[0]\n",
    "    random_data = []\n",
    "    for i in index_list:\n",
    "          random_data.append( data_dataset[i] )\n",
    "    return random_data\n",
    "\n",
    "generate_random_seed(2)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will stop the epochs manually, so we set a large number let it keep running\n",
    "epochs = 5000\n",
    "\n",
    "# Smivec dimenstion, will pass to model\n",
    "dims = smivec.dims\n",
    "\n",
    "lstm_size = 128  # The size of the LSTM layer\n",
    "hidden_size = 128  # The size of the hidden non-linear layer\n",
    "dropout_rate = 0.50 # The dropout rate\n",
    "out_size = 1        # This is just a single task, so this will be one\n",
    "\n",
    "batch_size = 1   # The mini_batch size during training\n",
    "#batch_size = 128   # The mini_batch size during training\n",
    "G_input_size = 100 # The Generator input data size\n",
    "\n",
    "\n",
    "\n",
    "############################## major turning parameters ##############################\n",
    "#learning_rate_D = 0.003  # The Discriminator initial learning rate for the optimizer \n",
    "#learning_rate_G = 0.001  # The Generator initial learning rate for the optimizer\n",
    "\n",
    "\n",
    "#learning_rate_D = 0.003  # The Discriminator initial learning rate for the optimizer \n",
    "#learning_rate_G = 0.003  # The Generator initial learning rate for the optimizer\n",
    "\n",
    "\n",
    "# Accuracy    Run\n",
    "# 0.388     30000\n",
    "#learning_rate_D = 0.007  # The Discriminator initial learning rate for the optimizer \n",
    "#learning_rate_G = 0.005  # The Generator initial learning rate for the optimizer\n",
    "\n",
    "\n",
    "# D: 1000, G:2000\n",
    "# Accuracy    Run\n",
    "# 0.639     30000\n",
    "# 0.695     60000\n",
    "#learning_rate_D = 0.005  # The Discriminator initial learning rate for the optimizer \n",
    "#learning_rate_G = 0.005  # The Generator initial learning rate for the optimizer\n",
    "\n",
    "\n",
    "# Accuracy    Run\n",
    "# 0.350     60000\n",
    "#learning_rate_D = 0.05  # The Discriminator initial learning rate for the optimizer \n",
    "#learning_rate_G = 0.005  # The Generator initial learning rate for the optimizer\n",
    "\n",
    "# Accuracy    Run\n",
    "# 0.254     30000\n",
    "#learning_rate_D = 0.001  # The Discriminator initial learning rate for the optimizer \n",
    "#learning_rate_G = 0.005  # The Generator initial learning rate for the optimizer\n",
    "\n",
    "\n",
    "# D: 1000, G:2000\n",
    "# Accuracy    Run\n",
    "# 0.511     150000\n",
    "#learning_rate_D = 0.0005  # The Discriminator initial learning rate for the optimizer \n",
    "#learning_rate_G = 0.0005  # The Generator initial learning rate for the optimizer\n",
    "\n",
    "\n",
    "# D: 1000, G:2000\n",
    "# Accuracy    Run\n",
    "# 0.771       150000\n",
    "#             300000\n",
    "#learning_rate_D = 0.00075 # The Discriminator initial learning rate for the optimizer \n",
    "#learning_rate_G = 0.00075  # The Generator initial learning rate for the optimizer\n",
    "\n",
    "# D: 50000, G:50000\n",
    "# 0.517     1008,000 \n",
    "# 0.692     1500,000 \n",
    "#learning_rate_D = 0.00075 # The Discriminator initial learning rate for the optimizer \n",
    "#learning_rate_G = 0.00075  # The Generator initial learning rate for the optimizer\n",
    "\n",
    "\n",
    "#################################### some data share, some difference ######################################\n",
    "# Accuracy    Run\n",
    "# 0.657     60000\n",
    "#learning_rate_D = 0.00075  # The Discriminator initial learning rate for the optimizer \n",
    "#learning_rate_G = 0.00075  # The Generator initial learning rate for the optimizer\n",
    "\n",
    "\n",
    "# data: 4000 \n",
    "# real data: 4000\n",
    "# Accuracy       Run\n",
    "# 0.75     5,086,000\n",
    "learning_rate_D = 0.00075  # The Discriminator initial learning rate for the optimizer \n",
    "learning_rate_G = 0.00075  # The Generator initial learning rate for the optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # initialise parent pytorch class\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=number_tokens, hidden_size=lstm_size, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.fc1 = nn.Linear(lstm_size, hidden_size) # Output layer\n",
    "        self.activation = nn.ReLU() # Non-Linear ReLU Layer       \n",
    "        self.fc_out = nn.Linear(hidden_size, out_size) # Output layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)       \n",
    "        \n",
    "        # create loss function\n",
    "        self.loss_function = nn.MSELoss()\n",
    "\n",
    "        # create optimiser, simple stochastic gradient descent\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=learning_rate_D)\n",
    "        #self.lr_scheduler = ReduceLROnPlateau(self.optimiser, mode='min', factor=0.5, patience=50, \n",
    "        #          verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=1e-6, eps=1e-08)\n",
    "\n",
    "        # counter and accumulator for progress\n",
    "        self.counter = 0;\n",
    "        self.progress = []\n",
    "\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def forward(self, input_tensor, label_tensor):\n",
    "        # combine seed and label\n",
    "        \n",
    "        #print(\"input_tensor.shape\", input_tensor.shape, \"label_tensor.shape\", label_tensor.shape)\n",
    "        x = torch.cat((input_tensor, label_tensor), -1)\n",
    "        #print('after torch.cat', x.shape)\n",
    "        \n",
    "        \n",
    "        out, (h_n, c_n) = self.lstm(x) #LSTM network reads in one-hot-encoded SMILES, h_n is last output, out is for all timesteps\n",
    "        out = self.dropout(h_n) #Dropout\n",
    "        out = self.fc1(out) # Pass into the hidden layer\n",
    "        out = self.activation(out) # Use ReLU on hidden activation\n",
    "        out = self.dropout(out) # dropout\n",
    "        out = self.fc_out(out) # Use a linear layer for the output\n",
    "        out = torch.argmax(F.softmax(out, dim=0))\n",
    "\n",
    "        return out\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def train(self, inputs, label_tensor, targets):\n",
    "        # calculate the output of the network Discriminator\n",
    "        outputs = self.forward(inputs, label_tensor)\n",
    "        \n",
    "        if (outputs.shape != targets.shape):\n",
    "            print(\"Generator loss function issue: outputs.shape != targets.shape\", outputs.shape, targets.shape)\n",
    "\n",
    "        loss = self.loss_function(outputs, targets)\n",
    "\n",
    "        # increase counter and accumulate error every 10\n",
    "        self.counter += 1;\n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss.item())\n",
    "            pass\n",
    "        if (self.counter % 1000 == 0):\n",
    "            print(\"counter = \", self.counter)\n",
    "            pass\n",
    "\n",
    "        # zero gradients \n",
    "        self.optimiser.zero_grad()\n",
    "        # perform a backward pass\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        self.optimiser.step()\n",
    "\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # the plot to check convergent\n",
    "    def plot_progress(self):\n",
    "        dataframe = pandas.DataFrame(self.progress, columns=['loss'])\n",
    "        dataframe.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "from torch.utils.data import DataLoader\n",
    "data_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True, num_workers=4,drop_last=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter =  1000\n",
      "counter =  2000\n",
      "counter =  3000\n",
      "counter =  4000\n",
      "counter =  5000\n",
      "counter =  6000\n",
      "counter =  7000\n",
      "counter =  8000\n",
      "counter =  9000\n",
      "counter =  10000\n",
      "counter =  11000\n",
      "counter =  12000\n",
      "counter =  13000\n",
      "counter =  14000\n",
      "counter =  15000\n",
      "counter =  16000\n",
      "counter =  17000\n",
      "counter =  18000\n",
      "counter =  19000\n",
      "counter =  20000\n",
      "counter =  21000\n",
      "counter =  22000\n",
      "counter =  23000\n",
      "counter =  24000\n",
      "counter =  25000\n",
      "counter =  26000\n",
      "counter =  27000\n",
      "counter =  28000\n",
      "counter =  29000\n",
      "counter =  30000\n",
      "counter =  31000\n",
      "counter =  32000\n",
      "counter =  33000\n",
      "counter =  34000\n",
      "counter =  35000\n",
      "counter =  36000\n",
      "counter =  37000\n",
      "counter =  38000\n",
      "counter =  39000\n",
      "counter =  40000\n",
      "counter =  41000\n",
      "counter =  42000\n",
      "counter =  43000\n",
      "counter =  44000\n",
      "counter =  45000\n",
      "counter =  46000\n",
      "counter =  47000\n",
      "counter =  48000\n",
      "counter =  49000\n",
      "counter =  50000\n",
      "counter =  51000\n",
      "counter =  52000\n",
      "counter =  53000\n",
      "counter =  54000\n",
      "counter =  55000\n",
      "counter =  56000\n",
      "counter =  57000\n",
      "counter =  58000\n",
      "counter =  59000\n",
      "counter =  60000\n",
      "counter =  61000\n",
      "counter =  62000\n",
      "counter =  63000\n",
      "counter =  64000\n",
      "counter =  65000\n",
      "counter =  66000\n",
      "counter =  67000\n",
      "counter =  68000\n",
      "counter =  69000\n",
      "counter =  70000\n",
      "counter =  71000\n",
      "counter =  72000\n",
      "counter =  73000\n",
      "counter =  74000\n",
      "counter =  75000\n",
      "counter =  76000\n",
      "counter =  77000\n",
      "counter =  78000\n",
      "counter =  79000\n",
      "counter =  80000\n",
      "counter =  81000\n",
      "counter =  82000\n",
      "counter =  83000\n",
      "counter =  84000\n",
      "counter =  85000\n",
      "counter =  86000\n",
      "counter =  87000\n",
      "counter =  88000\n",
      "counter =  89000\n",
      "counter =  90000\n",
      "counter =  91000\n",
      "counter =  92000\n",
      "counter =  93000\n",
      "counter =  94000\n",
      "counter =  95000\n",
      "counter =  96000\n",
      "counter =  97000\n",
      "counter =  98000\n",
      "counter =  99000\n",
      "counter =  100000\n",
      "counter =  101000\n",
      "counter =  102000\n",
      "counter =  103000\n",
      "counter =  104000\n",
      "counter =  105000\n",
      "counter =  106000\n",
      "counter =  107000\n",
      "counter =  108000\n",
      "counter =  109000\n",
      "counter =  110000\n",
      "counter =  111000\n",
      "counter =  112000\n",
      "counter =  113000\n",
      "counter =  114000\n",
      "counter =  115000\n",
      "counter =  116000\n",
      "counter =  117000\n",
      "counter =  118000\n",
      "counter =  119000\n",
      "counter =  120000\n",
      "counter =  121000\n",
      "counter =  122000\n",
      "counter =  123000\n",
      "counter =  124000\n",
      "counter =  125000\n",
      "counter =  126000\n",
      "counter =  127000\n",
      "counter =  128000\n",
      "counter =  129000\n",
      "counter =  130000\n",
      "counter =  131000\n",
      "counter =  132000\n",
      "counter =  133000\n",
      "CPU times: user 7min 39s, sys: 32.3 s, total: 8min 11s\n",
      "Wall time: 8min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test discriminator to check the ability to separate real data from random noise\n",
    "\n",
    "\n",
    "D = Discriminator()\n",
    "D.to(device)\n",
    "\n",
    "for smiles,label, target in data_loader:\n",
    "    # real data\n",
    "    target = target.view(1).to(device)\n",
    "    #print('0.before change label.shape', label.shape, 'smiles', smiles.shape, 'target.shape', target.shape)\n",
    "    label = label.float().to(device)\n",
    "    label = label.view(batch_size, 1, 1).repeat(1, smiles.shape[1], 1)\n",
    "    \n",
    "    #print('1.before change label.shape', label.shape, 'smiles', smiles.shape)\n",
    "    D.train(smiles.to(device).float(), label, target)\n",
    "    \n",
    "    # fake data(the value is random)\n",
    "    fake_input = []\n",
    "    fake_label = []\n",
    "    for item in generate_random_seed(batch_size):\n",
    "        fake_input.append(item[0])\n",
    "        fake_label.append(item[1])\n",
    "    \n",
    "    #print('fake_label', fake_label)\n",
    "    target = torch.FloatTensor(fake_label).to(device)\n",
    "    fake_input = torch.FloatTensor(fake_input).to(device)\n",
    "    \n",
    "    fake_label = torch.FloatTensor(fake_label).to(device)\n",
    "#    #print('2.before change label.shape', fake_input.shape, 'fake_label', fake_label.shape)\n",
    "    fake_label = fake_label.view(batch_size, 1, 1).repeat(1, fake_input.shape[1], 1)\n",
    "    #print('fake_input.shape', fake_input.shape, 'fake_label.shape', fake_label.shape)\n",
    "    D.train(fake_input, fake_label, target)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]], device='cuda:0')\n",
      "result tensor([1.0000], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Test discriminator by real data \n",
    "i = 0\n",
    "for smiles,label,target in data_loader:\n",
    "    # real\n",
    "    label = label.float().to(device)\n",
    "    label = label.view(batch_size, 1, 1).repeat(1, smiles.shape[1], 1)\n",
    "    result = D.forward(smiles.to(device).float(), label)\n",
    "    print('label', label)\n",
    "    print('result',result)\n",
    "    \n",
    "    i += 1\n",
    "    if (i >= 1):\n",
    "        break\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake_label tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]], device='cuda:0')\n",
      "result tensor([1.5203e-07], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Test discriminator by fale data\n",
    "fake_input = []\n",
    "fake_label = []\n",
    "for item in generate_random_seed(batch_size):\n",
    "    fake_input.append(item[0])\n",
    "    fake_label.append(item[1])\n",
    "    \n",
    "#print('fake_label', fake_label)\n",
    "target = torch.FloatTensor(fake_label).view(1,len(fake_label),1).to(device)\n",
    "fake_input = torch.FloatTensor(fake_input).to(device)\n",
    "    \n",
    "fake_label = torch.FloatTensor(fake_label).to(device)\n",
    "#    #print('2.before change label.shape', fake_input.shape, 'fake_label', fake_label.shape)\n",
    "fake_label = fake_label.view(batch_size, 1, 1).repeat(1, fake_input.shape[1], 1)\n",
    "result = D.forward(fake_input, fake_label)\n",
    "#print('fake_input.shape', fake_input.shape, 'fake_label.shape', fake_label.shape)\n",
    "print('fake_label', fake_label)\n",
    "print('result', result) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator class\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        # initialise parent pytorch class\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = batch_size \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(G_input_size * 2, 200),\n",
    "            nn.LeakyReLU(0.02),\n",
    "            #nn.LayerNorm(200),\n",
    "            nn.Linear(200, number_of_data),\n",
    "            nn.Sigmoid()\n",
    "\n",
    "        )\n",
    "        \n",
    "        # create optimiser, simple stochastic gradient descent\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=learning_rate_G)\n",
    "        \n",
    "        # counter and accumulator for progress\n",
    "        self.counter = 0;\n",
    "        self.progress = []\n",
    "        self.stop = False\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def forward(self, seed_tensor, label_tensor):        \n",
    "        # combine seed and label\n",
    "        #print('Generator seed_tensor.shape', seed_tensor.shape, 'label_tensor', label_tensor.shape)\n",
    "        inputs = torch.cat((seed_tensor, label_tensor))\n",
    "        #print('after torch.cat', inputs.shape)\n",
    "        outputs = self.model(inputs)\n",
    "        #print('outputs', outputs)\n",
    "        return torch.argmax(F.softmax(outputs, dim=0))\n",
    "\n",
    "\n",
    "    def train(self, D, inputs, label_tensor, targets):\n",
    "        # calculate the output of the network\n",
    "        g_output = self.forward(inputs, label_tensor.repeat(G_input_size))\n",
    "        #print('g_output', g_output)\n",
    "\n",
    "        # we don't use the dataset generate label, we are using random value\n",
    "        g_smiles, _, _ = data_dataset[g_output]\n",
    "        \n",
    "        g_input = torch.FloatTensor(g_smiles).to(device)\n",
    "        g_input = g_input.reshape(1, g_input.shape[0], g_input.shape[1])\n",
    "        \n",
    "        g_label = label_tensor.repeat(1, g_input.shape[1], 1)\n",
    "        \n",
    "        # pass onto Discriminator\n",
    "        #print(\"G g_input:\", g_input.shape, \"G_label\", label_tensor.shape)\n",
    "        \n",
    "        d_output = D.forward(g_input, g_label)\n",
    "        \n",
    "        #print('d_output.shape', d_output.shape, 'targets.shape', targets.shape)\n",
    "        if (d_output.shape != targets.shape):\n",
    "            print(\"Generator loss function issue: d_output.shape != targets.shape\", d_output.shape, targets.shape)\n",
    "        \n",
    "        # calculate error\n",
    "        loss = D.loss_function(d_output, targets)\n",
    "\n",
    "        # increase counter and accumulate error every 10\n",
    "        self.counter += 1;\n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss.item())\n",
    "            pass\n",
    "        \n",
    "        # zero gradients, perform a backward pass, update weights\n",
    "        self.optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimiser.step()\n",
    "\n",
    "\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def get_smiles(self, label):\n",
    "        label_tensor = torch.zeros((G_input_size))\n",
    "        for i in range(G_input_size):\n",
    "            label_tensor[i] = label\n",
    "    \n",
    "        fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "        fake_label = torch.FloatTensor(label_tensor).to(device)\n",
    "        idx = G.forward(fake_input, fake_label).detach().cpu().numpy()\n",
    "        #print('idx', idx, 'fake_input', fake_input.shape, 'fake_label.shape', fake_label.shape,  'result.shape', result.shape)\n",
    "        \n",
    "        #idx = self.get_index(G.forward(fake_input, fake_label)).detach().cpu().numpy()\n",
    "    \n",
    "        #data['smiles'].iloc[idx]\n",
    "        return x_data['smiles'].iloc[idx]\n",
    "\n",
    "    \n",
    "    def plot_progress(self):\n",
    "        df = pandas.DataFrame(self.progress, columns=['loss'])\n",
    "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx tensor(28896, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0]], dtype=int8),\n",
       " 0.0,\n",
       " tensor([0.]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the generator output is of the right type and shape\n",
    "\n",
    "G = Generator(1)\n",
    "G.to(device)\n",
    "\n",
    "#fake = generate_random_seed()\n",
    "fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "fake_label = torch.FloatTensor(generate_random_value(G_input_size)).to(device)\n",
    "idx = G.forward(fake_input, fake_label)\n",
    "print('idx', idx)\n",
    "data_dataset[idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC1OC1C(CO)C=O'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.get_smiles(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1\n",
      "counter =  1000\n",
      "counter =  2000\n",
      "counter =  3000\n",
      "counter =  4000\n",
      "counter =  5000\n",
      "counter =  6000\n",
      "counter =  7000\n",
      "counter =  8000\n",
      "counter =  9000\n",
      "counter =  10000\n",
      "counter =  11000\n",
      "counter =  12000\n",
      "counter =  13000\n",
      "counter =  14000\n",
      "counter =  15000\n",
      "counter =  16000\n",
      "counter =  17000\n",
      "counter =  18000\n",
      "counter =  19000\n",
      "counter =  20000\n",
      "counter =  21000\n",
      "counter =  22000\n",
      "counter =  23000\n",
      "counter =  24000\n",
      "counter =  25000\n",
      "counter =  26000\n",
      "counter =  27000\n",
      "counter =  28000\n",
      "counter =  29000\n",
      "counter =  30000\n",
      "counter =  31000\n",
      "counter =  32000\n",
      "counter =  33000\n",
      "counter =  34000\n",
      "counter =  35000\n",
      "counter =  36000\n",
      "counter =  37000\n",
      "counter =  38000\n",
      "counter =  39000\n",
      "counter =  40000\n",
      "counter =  41000\n",
      "counter =  42000\n",
      "counter =  43000\n",
      "counter =  44000\n",
      "counter =  45000\n",
      "counter =  46000\n",
      "counter =  47000\n",
      "counter =  48000\n",
      "counter =  49000\n",
      "counter =  50000\n",
      "counter =  51000\n",
      "counter =  52000\n",
      "counter =  53000\n",
      "counter =  54000\n",
      "counter =  55000\n",
      "counter =  56000\n",
      "counter =  57000\n",
      "counter =  58000\n",
      "counter =  59000\n",
      "counter =  60000\n",
      "counter =  61000\n",
      "counter =  62000\n",
      "counter =  63000\n",
      "counter =  64000\n",
      "counter =  65000\n",
      "counter =  66000\n",
      "counter =  67000\n",
      "counter =  68000\n",
      "counter =  69000\n",
      "counter =  70000\n",
      "counter =  71000\n",
      "counter =  72000\n",
      "counter =  73000\n",
      "counter =  74000\n",
      "counter =  75000\n",
      "counter =  76000\n",
      "counter =  77000\n",
      "counter =  78000\n",
      "counter =  79000\n",
      "counter =  80000\n",
      "counter =  81000\n",
      "counter =  82000\n",
      "counter =  83000\n",
      "counter =  84000\n",
      "counter =  85000\n",
      "counter =  86000\n",
      "counter =  87000\n",
      "counter =  88000\n",
      "counter =  89000\n",
      "counter =  90000\n",
      "counter =  91000\n",
      "counter =  92000\n",
      "counter =  93000\n",
      "counter =  94000\n",
      "counter =  95000\n",
      "counter =  96000\n",
      "counter =  97000\n",
      "counter =  98000\n",
      "counter =  99000\n",
      "counter =  100000\n",
      "counter =  101000\n",
      "counter =  102000\n",
      "counter =  103000\n",
      "counter =  104000\n",
      "counter =  105000\n",
      "counter =  106000\n",
      "counter =  107000\n",
      "counter =  108000\n",
      "counter =  109000\n",
      "counter =  110000\n",
      "counter =  111000\n",
      "counter =  112000\n",
      "counter =  113000\n",
      "counter =  114000\n",
      "counter =  115000\n",
      "counter =  116000\n",
      "counter =  117000\n",
      "counter =  118000\n",
      "counter =  119000\n",
      "counter =  120000\n",
      "counter =  121000\n",
      "counter =  122000\n",
      "counter =  123000\n",
      "counter =  124000\n",
      "counter =  125000\n",
      "counter =  126000\n",
      "counter =  127000\n",
      "counter =  128000\n",
      "counter =  129000\n",
      "counter =  130000\n",
      "counter =  131000\n",
      "counter =  132000\n",
      "counter =  133000\n",
      "epoch =  2\n",
      "counter =  134000\n",
      "counter =  135000\n",
      "counter =  136000\n",
      "counter =  137000\n",
      "counter =  138000\n",
      "counter =  139000\n",
      "counter =  140000\n",
      "counter =  141000\n",
      "counter =  142000\n",
      "counter =  143000\n",
      "counter =  144000\n",
      "counter =  145000\n",
      "counter =  146000\n",
      "counter =  147000\n",
      "counter =  148000\n",
      "counter =  149000\n",
      "counter =  150000\n",
      "counter =  151000\n",
      "counter =  152000\n",
      "counter =  153000\n",
      "counter =  154000\n",
      "counter =  155000\n",
      "counter =  156000\n",
      "counter =  157000\n",
      "counter =  158000\n",
      "counter =  159000\n",
      "counter =  160000\n",
      "counter =  161000\n",
      "counter =  162000\n",
      "counter =  163000\n",
      "counter =  164000\n",
      "counter =  165000\n",
      "counter =  166000\n",
      "counter =  167000\n",
      "counter =  168000\n",
      "counter =  169000\n",
      "counter =  170000\n",
      "counter =  171000\n",
      "counter =  172000\n",
      "counter =  173000\n",
      "counter =  174000\n",
      "counter =  175000\n",
      "counter =  176000\n",
      "counter =  177000\n",
      "counter =  178000\n",
      "counter =  179000\n",
      "counter =  180000\n",
      "counter =  181000\n",
      "counter =  182000\n",
      "counter =  183000\n",
      "counter =  184000\n",
      "counter =  185000\n",
      "counter =  186000\n",
      "counter =  187000\n",
      "counter =  188000\n",
      "counter =  189000\n",
      "counter =  190000\n",
      "counter =  191000\n",
      "counter =  192000\n",
      "counter =  193000\n",
      "counter =  194000\n",
      "counter =  195000\n",
      "counter =  196000\n",
      "counter =  197000\n",
      "counter =  198000\n",
      "counter =  199000\n",
      "counter =  200000\n",
      "counter =  201000\n",
      "counter =  202000\n",
      "counter =  203000\n",
      "counter =  204000\n",
      "counter =  205000\n",
      "counter =  206000\n",
      "counter =  207000\n",
      "counter =  208000\n",
      "counter =  209000\n",
      "counter =  210000\n",
      "counter =  211000\n",
      "counter =  212000\n",
      "counter =  213000\n",
      "counter =  214000\n",
      "counter =  215000\n",
      "counter =  216000\n",
      "counter =  217000\n",
      "counter =  218000\n",
      "counter =  219000\n",
      "counter =  220000\n",
      "counter =  221000\n",
      "counter =  222000\n",
      "counter =  223000\n",
      "counter =  224000\n",
      "counter =  225000\n",
      "counter =  226000\n",
      "counter =  227000\n",
      "counter =  228000\n",
      "counter =  229000\n",
      "counter =  230000\n",
      "counter =  231000\n",
      "counter =  232000\n",
      "counter =  233000\n",
      "counter =  234000\n",
      "counter =  235000\n",
      "counter =  236000\n",
      "counter =  237000\n",
      "counter =  238000\n",
      "counter =  239000\n",
      "counter =  240000\n",
      "counter =  241000\n",
      "counter =  242000\n",
      "counter =  243000\n",
      "counter =  244000\n",
      "counter =  245000\n",
      "counter =  246000\n",
      "counter =  247000\n",
      "counter =  248000\n",
      "counter =  249000\n",
      "counter =  250000\n",
      "counter =  251000\n",
      "counter =  252000\n",
      "counter =  253000\n",
      "counter =  254000\n",
      "counter =  255000\n",
      "counter =  256000\n",
      "counter =  257000\n",
      "counter =  258000\n",
      "counter =  259000\n",
      "counter =  260000\n",
      "counter =  261000\n",
      "counter =  262000\n",
      "counter =  263000\n",
      "counter =  264000\n",
      "counter =  265000\n",
      "counter =  266000\n",
      "counter =  267000\n",
      "epoch =  3\n",
      "counter =  268000\n",
      "counter =  269000\n",
      "counter =  270000\n",
      "counter =  271000\n",
      "counter =  272000\n",
      "counter =  273000\n",
      "counter =  274000\n",
      "counter =  275000\n",
      "counter =  276000\n",
      "counter =  277000\n",
      "counter =  278000\n",
      "counter =  279000\n",
      "counter =  280000\n",
      "counter =  281000\n",
      "counter =  282000\n",
      "counter =  283000\n",
      "counter =  284000\n",
      "counter =  285000\n",
      "counter =  286000\n",
      "counter =  287000\n",
      "counter =  288000\n",
      "counter =  289000\n",
      "counter =  290000\n",
      "counter =  291000\n",
      "counter =  292000\n",
      "counter =  293000\n",
      "counter =  294000\n",
      "counter =  295000\n",
      "counter =  296000\n",
      "counter =  297000\n",
      "counter =  298000\n",
      "counter =  299000\n",
      "counter =  300000\n",
      "counter =  301000\n",
      "counter =  302000\n",
      "counter =  303000\n",
      "counter =  304000\n",
      "counter =  305000\n",
      "counter =  306000\n",
      "counter =  307000\n",
      "counter =  308000\n",
      "counter =  309000\n",
      "counter =  310000\n",
      "counter =  311000\n",
      "counter =  312000\n",
      "counter =  313000\n",
      "counter =  314000\n",
      "counter =  315000\n",
      "counter =  316000\n",
      "counter =  317000\n",
      "counter =  318000\n",
      "counter =  319000\n",
      "counter =  320000\n",
      "counter =  321000\n",
      "counter =  322000\n",
      "counter =  323000\n",
      "counter =  324000\n",
      "counter =  325000\n",
      "counter =  326000\n",
      "counter =  327000\n",
      "counter =  328000\n",
      "counter =  329000\n",
      "counter =  330000\n",
      "counter =  331000\n",
      "counter =  332000\n",
      "counter =  333000\n",
      "counter =  334000\n",
      "counter =  335000\n",
      "counter =  336000\n",
      "counter =  337000\n",
      "counter =  338000\n",
      "counter =  339000\n",
      "counter =  340000\n",
      "counter =  341000\n",
      "counter =  342000\n",
      "counter =  343000\n",
      "counter =  344000\n",
      "counter =  345000\n",
      "counter =  346000\n",
      "counter =  347000\n",
      "counter =  348000\n",
      "counter =  349000\n",
      "counter =  350000\n",
      "counter =  351000\n",
      "counter =  352000\n",
      "counter =  353000\n",
      "counter =  354000\n",
      "counter =  355000\n",
      "counter =  356000\n",
      "counter =  357000\n",
      "counter =  358000\n",
      "counter =  359000\n",
      "counter =  360000\n",
      "counter =  361000\n",
      "counter =  362000\n",
      "counter =  363000\n",
      "counter =  364000\n",
      "counter =  365000\n",
      "counter =  366000\n",
      "counter =  367000\n",
      "counter =  368000\n",
      "counter =  369000\n",
      "counter =  370000\n",
      "counter =  371000\n",
      "counter =  372000\n",
      "counter =  373000\n",
      "counter =  374000\n",
      "counter =  375000\n",
      "counter =  376000\n",
      "counter =  377000\n",
      "counter =  378000\n",
      "counter =  379000\n",
      "counter =  380000\n",
      "counter =  381000\n",
      "counter =  382000\n",
      "counter =  383000\n",
      "counter =  384000\n",
      "counter =  385000\n",
      "counter =  386000\n",
      "counter =  387000\n",
      "counter =  388000\n",
      "counter =  389000\n",
      "counter =  390000\n",
      "counter =  391000\n",
      "counter =  392000\n",
      "counter =  393000\n",
      "counter =  394000\n",
      "counter =  395000\n",
      "counter =  396000\n",
      "counter =  397000\n",
      "counter =  398000\n",
      "counter =  399000\n",
      "counter =  400000\n",
      "counter =  401000\n",
      "epoch =  4\n",
      "counter =  402000\n",
      "counter =  403000\n",
      "counter =  404000\n",
      "counter =  405000\n",
      "counter =  406000\n",
      "counter =  407000\n",
      "counter =  408000\n",
      "counter =  409000\n",
      "counter =  410000\n",
      "counter =  411000\n",
      "counter =  412000\n",
      "counter =  413000\n",
      "counter =  414000\n",
      "counter =  415000\n",
      "counter =  416000\n",
      "counter =  417000\n",
      "counter =  418000\n",
      "counter =  419000\n",
      "counter =  420000\n",
      "counter =  421000\n",
      "counter =  422000\n",
      "counter =  423000\n",
      "counter =  424000\n",
      "counter =  425000\n",
      "counter =  426000\n",
      "counter =  427000\n",
      "counter =  428000\n",
      "counter =  429000\n",
      "counter =  430000\n",
      "counter =  431000\n",
      "counter =  432000\n",
      "counter =  433000\n",
      "counter =  434000\n",
      "counter =  435000\n",
      "counter =  436000\n",
      "counter =  437000\n",
      "counter =  438000\n",
      "counter =  439000\n",
      "counter =  440000\n",
      "counter =  441000\n",
      "counter =  442000\n",
      "counter =  443000\n",
      "counter =  444000\n",
      "counter =  445000\n",
      "counter =  446000\n",
      "counter =  447000\n",
      "counter =  448000\n",
      "counter =  449000\n",
      "counter =  450000\n",
      "counter =  451000\n",
      "counter =  452000\n",
      "counter =  453000\n",
      "counter =  454000\n",
      "counter =  455000\n",
      "counter =  456000\n",
      "counter =  457000\n",
      "counter =  458000\n",
      "counter =  459000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter =  460000\n",
      "counter =  461000\n",
      "counter =  462000\n",
      "counter =  463000\n",
      "counter =  464000\n",
      "counter =  465000\n",
      "counter =  466000\n",
      "counter =  467000\n",
      "counter =  468000\n",
      "counter =  469000\n",
      "counter =  470000\n",
      "counter =  471000\n",
      "counter =  472000\n",
      "counter =  473000\n",
      "counter =  474000\n",
      "counter =  475000\n",
      "counter =  476000\n",
      "counter =  477000\n",
      "counter =  478000\n",
      "counter =  479000\n",
      "counter =  480000\n",
      "counter =  481000\n",
      "counter =  482000\n",
      "counter =  483000\n",
      "counter =  484000\n",
      "counter =  485000\n",
      "counter =  486000\n",
      "counter =  487000\n",
      "counter =  488000\n",
      "counter =  489000\n",
      "counter =  490000\n",
      "counter =  491000\n",
      "counter =  492000\n",
      "counter =  493000\n",
      "counter =  494000\n",
      "counter =  495000\n",
      "counter =  496000\n",
      "counter =  497000\n",
      "counter =  498000\n",
      "counter =  499000\n",
      "counter =  500000\n",
      "counter =  501000\n",
      "counter =  502000\n",
      "counter =  503000\n",
      "counter =  504000\n",
      "counter =  505000\n",
      "counter =  506000\n",
      "counter =  507000\n",
      "counter =  508000\n",
      "counter =  509000\n",
      "counter =  510000\n",
      "counter =  511000\n",
      "counter =  512000\n",
      "counter =  513000\n",
      "counter =  514000\n",
      "counter =  515000\n",
      "counter =  516000\n",
      "counter =  517000\n",
      "counter =  518000\n",
      "counter =  519000\n",
      "counter =  520000\n",
      "counter =  521000\n",
      "counter =  522000\n",
      "counter =  523000\n",
      "counter =  524000\n",
      "counter =  525000\n",
      "counter =  526000\n",
      "counter =  527000\n",
      "counter =  528000\n",
      "counter =  529000\n",
      "counter =  530000\n",
      "counter =  531000\n",
      "counter =  532000\n",
      "counter =  533000\n",
      "counter =  534000\n",
      "counter =  535000\n",
      "epoch =  5\n",
      "counter =  536000\n",
      "counter =  537000\n",
      "counter =  538000\n",
      "counter =  539000\n",
      "counter =  540000\n",
      "counter =  541000\n",
      "counter =  542000\n",
      "counter =  543000\n",
      "counter =  544000\n",
      "counter =  545000\n",
      "counter =  546000\n",
      "counter =  547000\n",
      "counter =  548000\n",
      "counter =  549000\n",
      "counter =  550000\n",
      "counter =  551000\n",
      "counter =  552000\n",
      "counter =  553000\n",
      "counter =  554000\n",
      "counter =  555000\n",
      "counter =  556000\n",
      "counter =  557000\n",
      "counter =  558000\n",
      "counter =  559000\n",
      "counter =  560000\n",
      "counter =  561000\n",
      "counter =  562000\n",
      "counter =  563000\n",
      "counter =  564000\n",
      "counter =  565000\n",
      "counter =  566000\n",
      "counter =  567000\n",
      "counter =  568000\n",
      "counter =  569000\n",
      "counter =  570000\n",
      "counter =  571000\n",
      "counter =  572000\n",
      "counter =  573000\n",
      "counter =  574000\n",
      "counter =  575000\n",
      "counter =  576000\n",
      "counter =  577000\n",
      "counter =  578000\n",
      "counter =  579000\n",
      "counter =  580000\n",
      "counter =  581000\n",
      "counter =  582000\n",
      "counter =  583000\n",
      "counter =  584000\n",
      "counter =  585000\n",
      "counter =  586000\n",
      "counter =  587000\n",
      "counter =  588000\n",
      "counter =  589000\n",
      "counter =  590000\n",
      "counter =  591000\n",
      "counter =  592000\n",
      "counter =  593000\n",
      "counter =  594000\n",
      "counter =  595000\n",
      "counter =  596000\n",
      "counter =  597000\n",
      "counter =  598000\n",
      "counter =  599000\n",
      "counter =  600000\n",
      "counter =  601000\n",
      "counter =  602000\n",
      "counter =  603000\n",
      "counter =  604000\n",
      "counter =  605000\n",
      "counter =  606000\n",
      "counter =  607000\n",
      "counter =  608000\n",
      "counter =  609000\n",
      "counter =  610000\n",
      "counter =  611000\n",
      "counter =  612000\n",
      "counter =  613000\n",
      "counter =  614000\n",
      "counter =  615000\n",
      "counter =  616000\n",
      "counter =  617000\n",
      "counter =  618000\n",
      "counter =  619000\n",
      "counter =  620000\n",
      "counter =  621000\n",
      "counter =  622000\n",
      "counter =  623000\n",
      "counter =  624000\n",
      "counter =  625000\n",
      "counter =  626000\n",
      "counter =  627000\n",
      "counter =  628000\n",
      "counter =  629000\n",
      "counter =  630000\n",
      "counter =  631000\n",
      "counter =  632000\n",
      "counter =  633000\n",
      "counter =  634000\n",
      "counter =  635000\n",
      "counter =  636000\n",
      "counter =  637000\n",
      "counter =  638000\n",
      "counter =  639000\n",
      "counter =  640000\n",
      "counter =  641000\n",
      "counter =  642000\n",
      "counter =  643000\n",
      "counter =  644000\n",
      "counter =  645000\n",
      "counter =  646000\n",
      "counter =  647000\n",
      "counter =  648000\n",
      "counter =  649000\n",
      "counter =  650000\n",
      "counter =  651000\n",
      "counter =  652000\n",
      "counter =  653000\n",
      "counter =  654000\n",
      "counter =  655000\n",
      "counter =  656000\n",
      "counter =  657000\n",
      "counter =  658000\n",
      "counter =  659000\n",
      "counter =  660000\n",
      "counter =  661000\n",
      "counter =  662000\n",
      "counter =  663000\n",
      "counter =  664000\n",
      "counter =  665000\n",
      "counter =  666000\n",
      "counter =  667000\n",
      "counter =  668000\n",
      "counter =  669000\n",
      "epoch =  6\n",
      "counter =  670000\n",
      "counter =  671000\n",
      "counter =  672000\n",
      "counter =  673000\n",
      "counter =  674000\n",
      "counter =  675000\n",
      "counter =  676000\n",
      "counter =  677000\n",
      "counter =  678000\n",
      "counter =  679000\n",
      "counter =  680000\n",
      "counter =  681000\n",
      "counter =  682000\n",
      "counter =  683000\n",
      "counter =  684000\n",
      "counter =  685000\n",
      "counter =  686000\n",
      "counter =  687000\n",
      "counter =  688000\n",
      "counter =  689000\n",
      "counter =  690000\n",
      "counter =  691000\n",
      "counter =  692000\n",
      "counter =  693000\n",
      "counter =  694000\n",
      "counter =  695000\n",
      "counter =  696000\n",
      "counter =  697000\n",
      "counter =  698000\n",
      "counter =  699000\n",
      "counter =  700000\n",
      "counter =  701000\n",
      "counter =  702000\n",
      "counter =  703000\n",
      "counter =  704000\n",
      "counter =  705000\n",
      "counter =  706000\n",
      "counter =  707000\n",
      "counter =  708000\n",
      "counter =  709000\n",
      "counter =  710000\n",
      "counter =  711000\n",
      "counter =  712000\n",
      "counter =  713000\n",
      "counter =  714000\n",
      "counter =  715000\n",
      "counter =  716000\n",
      "counter =  717000\n",
      "counter =  718000\n",
      "counter =  719000\n",
      "counter =  720000\n",
      "counter =  721000\n",
      "counter =  722000\n",
      "counter =  723000\n",
      "counter =  724000\n",
      "counter =  725000\n",
      "counter =  726000\n",
      "counter =  727000\n",
      "counter =  728000\n",
      "counter =  729000\n",
      "counter =  730000\n",
      "counter =  731000\n",
      "counter =  732000\n",
      "counter =  733000\n",
      "counter =  734000\n",
      "counter =  735000\n",
      "counter =  736000\n",
      "counter =  737000\n",
      "counter =  738000\n",
      "counter =  739000\n",
      "counter =  740000\n",
      "counter =  741000\n",
      "counter =  742000\n",
      "counter =  743000\n",
      "counter =  744000\n",
      "counter =  745000\n",
      "counter =  746000\n",
      "counter =  747000\n",
      "counter =  748000\n",
      "counter =  749000\n",
      "counter =  750000\n",
      "counter =  751000\n",
      "counter =  752000\n",
      "counter =  753000\n",
      "counter =  754000\n",
      "counter =  755000\n",
      "counter =  756000\n",
      "counter =  757000\n",
      "counter =  758000\n",
      "counter =  759000\n",
      "counter =  760000\n",
      "counter =  761000\n",
      "counter =  762000\n",
      "counter =  763000\n",
      "counter =  764000\n",
      "counter =  765000\n",
      "counter =  766000\n",
      "counter =  767000\n",
      "counter =  768000\n",
      "counter =  769000\n",
      "counter =  770000\n",
      "counter =  771000\n",
      "counter =  772000\n",
      "counter =  773000\n",
      "counter =  774000\n",
      "counter =  775000\n",
      "counter =  776000\n",
      "counter =  777000\n",
      "counter =  778000\n",
      "counter =  779000\n",
      "counter =  780000\n",
      "counter =  781000\n",
      "counter =  782000\n",
      "counter =  783000\n",
      "counter =  784000\n",
      "counter =  785000\n",
      "counter =  786000\n",
      "counter =  787000\n",
      "counter =  788000\n",
      "counter =  789000\n",
      "counter =  790000\n",
      "counter =  791000\n",
      "counter =  792000\n",
      "counter =  793000\n",
      "counter =  794000\n",
      "counter =  795000\n",
      "counter =  796000\n",
      "counter =  797000\n",
      "counter =  798000\n",
      "counter =  799000\n",
      "counter =  800000\n",
      "counter =  801000\n",
      "counter =  802000\n",
      "counter =  803000\n",
      "epoch =  7\n",
      "counter =  804000\n",
      "counter =  805000\n",
      "counter =  806000\n",
      "counter =  807000\n",
      "counter =  808000\n",
      "counter =  809000\n",
      "counter =  810000\n",
      "counter =  811000\n",
      "counter =  812000\n",
      "counter =  813000\n",
      "counter =  814000\n",
      "counter =  815000\n",
      "counter =  816000\n",
      "counter =  817000\n",
      "counter =  818000\n",
      "counter =  819000\n",
      "counter =  820000\n",
      "counter =  821000\n",
      "counter =  822000\n",
      "counter =  823000\n",
      "counter =  824000\n",
      "counter =  825000\n",
      "counter =  826000\n",
      "counter =  827000\n",
      "counter =  828000\n",
      "counter =  829000\n",
      "counter =  830000\n",
      "counter =  831000\n",
      "counter =  832000\n",
      "counter =  833000\n",
      "counter =  834000\n",
      "counter =  835000\n",
      "counter =  836000\n",
      "counter =  837000\n",
      "counter =  838000\n",
      "counter =  839000\n",
      "counter =  840000\n",
      "counter =  841000\n",
      "counter =  842000\n",
      "counter =  843000\n",
      "counter =  844000\n",
      "counter =  845000\n",
      "counter =  846000\n",
      "counter =  847000\n",
      "counter =  848000\n",
      "counter =  849000\n",
      "counter =  850000\n",
      "counter =  851000\n",
      "counter =  852000\n",
      "counter =  853000\n",
      "counter =  854000\n",
      "counter =  855000\n",
      "counter =  856000\n",
      "counter =  857000\n",
      "counter =  858000\n",
      "counter =  859000\n",
      "counter =  860000\n",
      "counter =  861000\n",
      "counter =  862000\n",
      "counter =  863000\n",
      "counter =  864000\n",
      "counter =  865000\n",
      "counter =  866000\n",
      "counter =  867000\n",
      "counter =  868000\n",
      "counter =  869000\n",
      "counter =  870000\n",
      "counter =  871000\n",
      "counter =  872000\n",
      "counter =  873000\n",
      "counter =  874000\n",
      "counter =  875000\n",
      "counter =  876000\n",
      "counter =  877000\n",
      "counter =  878000\n",
      "counter =  879000\n",
      "counter =  880000\n",
      "counter =  881000\n",
      "counter =  882000\n",
      "counter =  883000\n",
      "counter =  884000\n",
      "counter =  885000\n",
      "counter =  886000\n",
      "counter =  887000\n",
      "counter =  888000\n",
      "counter =  889000\n",
      "counter =  890000\n",
      "counter =  891000\n",
      "counter =  892000\n",
      "counter =  893000\n",
      "counter =  894000\n",
      "counter =  895000\n",
      "counter =  896000\n",
      "counter =  897000\n",
      "counter =  898000\n",
      "counter =  899000\n",
      "counter =  900000\n",
      "counter =  901000\n",
      "counter =  902000\n",
      "counter =  903000\n",
      "counter =  904000\n",
      "counter =  905000\n",
      "counter =  906000\n",
      "counter =  907000\n",
      "counter =  908000\n",
      "counter =  909000\n",
      "counter =  910000\n",
      "counter =  911000\n",
      "counter =  912000\n",
      "counter =  913000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter =  914000\n",
      "counter =  915000\n",
      "counter =  916000\n",
      "counter =  917000\n",
      "counter =  918000\n",
      "counter =  919000\n",
      "counter =  920000\n",
      "counter =  921000\n",
      "counter =  922000\n",
      "counter =  923000\n",
      "counter =  924000\n",
      "counter =  925000\n",
      "counter =  926000\n",
      "counter =  927000\n",
      "counter =  928000\n",
      "counter =  929000\n",
      "counter =  930000\n",
      "counter =  931000\n",
      "counter =  932000\n",
      "counter =  933000\n",
      "counter =  934000\n",
      "counter =  935000\n",
      "counter =  936000\n",
      "counter =  937000\n",
      "epoch =  8\n",
      "counter =  938000\n",
      "counter =  939000\n",
      "counter =  940000\n",
      "counter =  941000\n",
      "counter =  942000\n",
      "counter =  943000\n",
      "counter =  944000\n",
      "counter =  945000\n",
      "counter =  946000\n",
      "counter =  947000\n",
      "counter =  948000\n",
      "counter =  949000\n",
      "counter =  950000\n",
      "counter =  951000\n",
      "counter =  952000\n",
      "counter =  953000\n",
      "counter =  954000\n",
      "counter =  955000\n",
      "counter =  956000\n",
      "counter =  957000\n",
      "counter =  958000\n",
      "counter =  959000\n",
      "counter =  960000\n",
      "counter =  961000\n",
      "counter =  962000\n",
      "counter =  963000\n",
      "counter =  964000\n",
      "counter =  965000\n",
      "counter =  966000\n",
      "counter =  967000\n",
      "counter =  968000\n",
      "counter =  969000\n",
      "counter =  970000\n",
      "counter =  971000\n",
      "counter =  972000\n",
      "counter =  973000\n",
      "counter =  974000\n",
      "counter =  975000\n",
      "counter =  976000\n",
      "counter =  977000\n",
      "counter =  978000\n",
      "counter =  979000\n",
      "counter =  980000\n",
      "counter =  981000\n",
      "counter =  982000\n",
      "counter =  983000\n",
      "counter =  984000\n",
      "counter =  985000\n",
      "counter =  986000\n",
      "counter =  987000\n",
      "counter =  988000\n",
      "counter =  989000\n",
      "counter =  990000\n",
      "counter =  991000\n",
      "counter =  992000\n",
      "counter =  993000\n",
      "counter =  994000\n",
      "counter =  995000\n",
      "counter =  996000\n",
      "counter =  997000\n",
      "counter =  998000\n",
      "counter =  999000\n",
      "counter =  1000000\n",
      "counter =  1001000\n",
      "counter =  1002000\n",
      "counter =  1003000\n",
      "counter =  1004000\n",
      "counter =  1005000\n",
      "counter =  1006000\n",
      "counter =  1007000\n",
      "counter =  1008000\n",
      "counter =  1009000\n",
      "counter =  1010000\n",
      "counter =  1011000\n",
      "counter =  1012000\n",
      "counter =  1013000\n",
      "counter =  1014000\n",
      "counter =  1015000\n",
      "counter =  1016000\n",
      "counter =  1017000\n",
      "counter =  1018000\n",
      "counter =  1019000\n",
      "counter =  1020000\n",
      "counter =  1021000\n",
      "counter =  1022000\n",
      "counter =  1023000\n",
      "counter =  1024000\n",
      "counter =  1025000\n",
      "counter =  1026000\n",
      "counter =  1027000\n",
      "counter =  1028000\n",
      "counter =  1029000\n",
      "counter =  1030000\n",
      "counter =  1031000\n",
      "counter =  1032000\n",
      "counter =  1033000\n",
      "counter =  1034000\n",
      "counter =  1035000\n",
      "counter =  1036000\n",
      "counter =  1037000\n",
      "counter =  1038000\n",
      "counter =  1039000\n",
      "counter =  1040000\n",
      "counter =  1041000\n",
      "counter =  1042000\n",
      "counter =  1043000\n",
      "counter =  1044000\n",
      "counter =  1045000\n",
      "counter =  1046000\n",
      "counter =  1047000\n",
      "counter =  1048000\n",
      "counter =  1049000\n",
      "counter =  1050000\n",
      "counter =  1051000\n",
      "counter =  1052000\n",
      "counter =  1053000\n",
      "counter =  1054000\n",
      "counter =  1055000\n",
      "counter =  1056000\n",
      "counter =  1057000\n",
      "counter =  1058000\n",
      "counter =  1059000\n",
      "counter =  1060000\n",
      "counter =  1061000\n",
      "counter =  1062000\n",
      "counter =  1063000\n",
      "counter =  1064000\n",
      "counter =  1065000\n",
      "counter =  1066000\n",
      "counter =  1067000\n",
      "counter =  1068000\n",
      "counter =  1069000\n",
      "counter =  1070000\n",
      "counter =  1071000\n",
      "epoch =  9\n",
      "counter =  1072000\n",
      "counter =  1073000\n",
      "counter =  1074000\n",
      "counter =  1075000\n",
      "counter =  1076000\n",
      "counter =  1077000\n",
      "counter =  1078000\n",
      "counter =  1079000\n",
      "counter =  1080000\n",
      "counter =  1081000\n",
      "counter =  1082000\n",
      "counter =  1083000\n",
      "counter =  1084000\n",
      "counter =  1085000\n",
      "counter =  1086000\n",
      "counter =  1087000\n",
      "counter =  1088000\n",
      "counter =  1089000\n",
      "counter =  1090000\n",
      "counter =  1091000\n",
      "counter =  1092000\n",
      "counter =  1093000\n",
      "counter =  1094000\n",
      "counter =  1095000\n",
      "counter =  1096000\n",
      "counter =  1097000\n",
      "counter =  1098000\n",
      "counter =  1099000\n",
      "counter =  1100000\n",
      "counter =  1101000\n",
      "counter =  1102000\n",
      "counter =  1103000\n",
      "counter =  1104000\n",
      "counter =  1105000\n",
      "counter =  1106000\n",
      "counter =  1107000\n",
      "counter =  1108000\n",
      "counter =  1109000\n",
      "counter =  1110000\n",
      "counter =  1111000\n",
      "counter =  1112000\n",
      "counter =  1113000\n",
      "counter =  1114000\n",
      "counter =  1115000\n",
      "counter =  1116000\n",
      "counter =  1117000\n",
      "counter =  1118000\n",
      "counter =  1119000\n",
      "counter =  1120000\n",
      "counter =  1121000\n",
      "counter =  1122000\n",
      "counter =  1123000\n",
      "counter =  1124000\n",
      "counter =  1125000\n",
      "counter =  1126000\n",
      "counter =  1127000\n",
      "counter =  1128000\n",
      "counter =  1129000\n",
      "counter =  1130000\n",
      "counter =  1131000\n",
      "counter =  1132000\n",
      "counter =  1133000\n",
      "counter =  1134000\n",
      "counter =  1135000\n",
      "counter =  1136000\n",
      "counter =  1137000\n",
      "counter =  1138000\n",
      "counter =  1139000\n",
      "counter =  1140000\n",
      "counter =  1141000\n",
      "counter =  1142000\n",
      "counter =  1143000\n",
      "counter =  1144000\n",
      "counter =  1145000\n",
      "counter =  1146000\n",
      "counter =  1147000\n",
      "counter =  1148000\n",
      "counter =  1149000\n",
      "counter =  1150000\n",
      "counter =  1151000\n",
      "counter =  1152000\n",
      "counter =  1153000\n",
      "counter =  1154000\n",
      "counter =  1155000\n",
      "counter =  1156000\n",
      "counter =  1157000\n",
      "counter =  1158000\n",
      "counter =  1159000\n",
      "counter =  1160000\n",
      "counter =  1161000\n",
      "counter =  1162000\n",
      "counter =  1163000\n",
      "counter =  1164000\n",
      "counter =  1165000\n",
      "counter =  1166000\n",
      "counter =  1167000\n",
      "counter =  1168000\n",
      "counter =  1169000\n",
      "counter =  1170000\n",
      "counter =  1171000\n",
      "counter =  1172000\n",
      "counter =  1173000\n",
      "counter =  1174000\n",
      "counter =  1175000\n",
      "counter =  1176000\n",
      "counter =  1177000\n",
      "counter =  1178000\n",
      "counter =  1179000\n",
      "counter =  1180000\n",
      "counter =  1181000\n",
      "counter =  1182000\n",
      "counter =  1183000\n",
      "counter =  1184000\n",
      "counter =  1185000\n",
      "counter =  1186000\n",
      "counter =  1187000\n",
      "counter =  1188000\n",
      "counter =  1189000\n",
      "counter =  1190000\n",
      "counter =  1191000\n",
      "counter =  1192000\n",
      "counter =  1193000\n",
      "counter =  1194000\n",
      "counter =  1195000\n",
      "counter =  1196000\n",
      "counter =  1197000\n",
      "counter =  1198000\n",
      "counter =  1199000\n",
      "counter =  1200000\n",
      "counter =  1201000\n",
      "counter =  1202000\n",
      "counter =  1203000\n",
      "counter =  1204000\n",
      "epoch =  10\n",
      "counter =  1205000\n",
      "counter =  1206000\n",
      "counter =  1207000\n",
      "counter =  1208000\n",
      "counter =  1209000\n",
      "counter =  1210000\n",
      "counter =  1211000\n",
      "counter =  1212000\n",
      "counter =  1213000\n",
      "counter =  1214000\n",
      "counter =  1215000\n",
      "counter =  1216000\n",
      "counter =  1217000\n",
      "counter =  1218000\n",
      "counter =  1219000\n",
      "counter =  1220000\n",
      "counter =  1221000\n",
      "counter =  1222000\n",
      "counter =  1223000\n",
      "counter =  1224000\n",
      "counter =  1225000\n",
      "counter =  1226000\n",
      "counter =  1227000\n",
      "counter =  1228000\n",
      "counter =  1229000\n",
      "counter =  1230000\n",
      "counter =  1231000\n",
      "counter =  1232000\n",
      "counter =  1233000\n",
      "counter =  1234000\n",
      "counter =  1235000\n",
      "counter =  1236000\n",
      "counter =  1237000\n",
      "counter =  1238000\n",
      "counter =  1239000\n",
      "counter =  1240000\n",
      "counter =  1241000\n",
      "counter =  1242000\n",
      "counter =  1243000\n",
      "counter =  1244000\n",
      "counter =  1245000\n",
      "counter =  1246000\n",
      "counter =  1247000\n",
      "counter =  1248000\n",
      "counter =  1249000\n",
      "counter =  1250000\n",
      "counter =  1251000\n",
      "counter =  1252000\n",
      "counter =  1253000\n",
      "counter =  1254000\n",
      "counter =  1255000\n",
      "counter =  1256000\n",
      "counter =  1257000\n",
      "counter =  1258000\n",
      "counter =  1259000\n",
      "counter =  1260000\n",
      "counter =  1261000\n",
      "counter =  1262000\n",
      "counter =  1263000\n",
      "counter =  1264000\n",
      "counter =  1265000\n",
      "counter =  1266000\n",
      "counter =  1267000\n",
      "counter =  1268000\n",
      "counter =  1269000\n",
      "counter =  1270000\n",
      "counter =  1271000\n",
      "counter =  1272000\n",
      "counter =  1273000\n",
      "counter =  1274000\n",
      "counter =  1275000\n",
      "counter =  1276000\n",
      "counter =  1277000\n",
      "counter =  1278000\n",
      "counter =  1279000\n",
      "counter =  1280000\n",
      "counter =  1281000\n",
      "counter =  1282000\n",
      "counter =  1283000\n",
      "counter =  1284000\n",
      "counter =  1285000\n",
      "counter =  1286000\n",
      "counter =  1287000\n",
      "counter =  1288000\n",
      "counter =  1289000\n",
      "counter =  1290000\n",
      "counter =  1291000\n",
      "counter =  1292000\n",
      "counter =  1293000\n",
      "counter =  1294000\n",
      "counter =  1295000\n",
      "counter =  1296000\n",
      "counter =  1297000\n",
      "counter =  1298000\n",
      "counter =  1299000\n",
      "counter =  1300000\n",
      "counter =  1301000\n",
      "counter =  1302000\n",
      "counter =  1303000\n",
      "counter =  1304000\n",
      "counter =  1305000\n",
      "counter =  1306000\n",
      "counter =  1307000\n",
      "counter =  1308000\n",
      "counter =  1309000\n",
      "counter =  1310000\n",
      "counter =  1311000\n",
      "counter =  1312000\n",
      "counter =  1313000\n",
      "counter =  1314000\n",
      "counter =  1315000\n",
      "counter =  1316000\n",
      "counter =  1317000\n",
      "counter =  1318000\n",
      "counter =  1319000\n",
      "counter =  1320000\n",
      "counter =  1321000\n",
      "counter =  1322000\n",
      "counter =  1323000\n",
      "counter =  1324000\n",
      "counter =  1325000\n",
      "counter =  1326000\n",
      "counter =  1327000\n",
      "counter =  1328000\n",
      "counter =  1329000\n",
      "counter =  1330000\n",
      "counter =  1331000\n",
      "counter =  1332000\n",
      "counter =  1333000\n",
      "counter =  1334000\n",
      "counter =  1335000\n",
      "counter =  1336000\n",
      "counter =  1337000\n",
      "counter =  1338000\n",
      "epoch =  11\n",
      "counter =  1339000\n",
      "counter =  1340000\n",
      "counter =  1341000\n",
      "counter =  1342000\n",
      "counter =  1343000\n",
      "counter =  1344000\n",
      "counter =  1345000\n",
      "counter =  1346000\n",
      "counter =  1347000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter =  1348000\n",
      "counter =  1349000\n",
      "counter =  1350000\n",
      "counter =  1351000\n",
      "counter =  1352000\n",
      "counter =  1353000\n",
      "counter =  1354000\n",
      "counter =  1355000\n",
      "counter =  1356000\n",
      "counter =  1357000\n",
      "counter =  1358000\n",
      "counter =  1359000\n",
      "counter =  1360000\n",
      "counter =  1361000\n",
      "counter =  1362000\n",
      "counter =  1363000\n",
      "counter =  1364000\n",
      "counter =  1365000\n",
      "counter =  1366000\n",
      "counter =  1367000\n",
      "counter =  1368000\n",
      "counter =  1369000\n",
      "counter =  1370000\n",
      "counter =  1371000\n",
      "counter =  1372000\n",
      "counter =  1373000\n",
      "counter =  1374000\n",
      "counter =  1375000\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train Discriminator and Generator\n",
    "D = Discriminator()\n",
    "D.to(device)\n",
    "G = Generator(batch_size)\n",
    "G.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print (\"epoch = \", epoch + 1)\n",
    "\n",
    "    # train Discriminator and Generator\n",
    "    for smiles,label,target in data_loader:\n",
    "        #########################################################                   \n",
    "        # train discriminator on true\n",
    "        #########################################################   \n",
    "        target = torch.FloatTensor(torch.ones(smiles.shape[0])).to(device)\n",
    "        #print('0.before change label.shape', label.shape, 'smiles', smiles.shape, 'target.shape', target.shape)\n",
    "        label = label.float().to(device)\n",
    "        label = label.view(batch_size, 1, 1).repeat(1, smiles.shape[1], 1)\n",
    "    \n",
    "        #print('1.before change label.shape', label.shape, 'smiles', smiles.shape)\n",
    "        D.train(smiles.to(device).float(), label, target)\n",
    "        #########################################################                   \n",
    "        # train discriminator on false\n",
    "        # use detach() so gradients in G are not calculated\n",
    "        #########################################################      \n",
    "        # fake\n",
    "\n",
    "\n",
    "        fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "        fake_label = torch.FloatTensor(generate_random_label(1)).to(device)\n",
    "        idx = G.forward(fake_input, fake_label.repeat(G_input_size)).detach().cpu().numpy()\n",
    "        g_smiles, _, _ = data_dataset[idx]\n",
    "        \n",
    "        g_input = torch.FloatTensor(g_smiles).to(device)\n",
    "        g_input = g_input.reshape(1, g_input.shape[0], g_input.shape[1])\n",
    "        g_label = fake_label.repeat(1, g_input.shape[1], 1)\n",
    "        \n",
    "        target = torch.FloatTensor(torch.zeros(len(fake_label))).to(device)\n",
    "        #target = torch.FloatTensor([0.0]).to(device)\n",
    "        D.train(g_input, g_label, target)\n",
    "        \n",
    "        #fake_input = []\n",
    "        #fake_label = []\n",
    "        #for item in generate_random_seed(batch_size):\n",
    "        #    fake_input.append(item[0])\n",
    "        #    fake_label.append(item[1])\n",
    "    \n",
    "        #print('fake_label', fake_label)\n",
    "        #target = torch.FloatTensor(torch.zeros(len(fake_label))).to(device)\n",
    "        #fake_input = torch.FloatTensor(fake_input).to(device)\n",
    "        #fake_label = torch.FloatTensor(fake_label).to(device)\n",
    "        ##print('2.before change label.shape', fake_input.shape, 'fake_label', fake_label.shape)\n",
    "        #fake_label = fake_label.view(batch_size, 1, 1).repeat(1, fake_input.shape[1], 1)\n",
    "        #print('fake_input.shape', fake_input.shape, 'fake_label.shape', fake_label.shape)\n",
    "        #target = torch.FloatTensor([0.0]).to(device)\n",
    "        #D.train(fake_input, fake_label, target)\n",
    "\n",
    "        #########################################################                   \n",
    "        # train generator\n",
    "        #########################################################                   \n",
    "        fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "        fake_label = torch.FloatTensor(generate_random_label(1)).to(device)\n",
    "        #print('fake_label', fake_label)\n",
    "        #print('fake_label.shape', fake_label.shape)\n",
    "        #fake_label = fake_label.view(1,G_input_size,1)\n",
    "        target = torch.FloatTensor([0.0]).to(device)\n",
    "        G.train(D, fake_input, fake_label, target)\n",
    "        \n",
    "    pass\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9_dataset = pandas.read_csv('dataset/qm9.csv')\n",
    "accuracy = []\n",
    "number_of_verify = 1000\n",
    "for i in range(number_of_verify):\n",
    "    test_smiles = G.get_smiles(1.0)\n",
    "    real = qm9_dataset[qm9_dataset['smiles'] == test_smiles ]\n",
    "    #print('Test Result:', real.iat[0,0],real.iat[0,1], real.iat[0,1] > baseline)\n",
    "    accuracy.append(real.iat[0,1] > baseline)\n",
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2070], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.7550], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1016], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.6136], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.7818], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.9927], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.9886], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.9225], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.8235], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for smiles,label,target in data_loader:\n",
    "    # real\n",
    "    target = torch.FloatTensor([1.0]).view(1,1,1).repeat(1, smiles.shape[0] ,1).to(device)\n",
    "    label = label.float().to(device)\n",
    "    label = label.view(batch_size, 1, 1).repeat(1, smiles.shape[1], 1)\n",
    "    \n",
    "    #print(label)\n",
    "    print(D.forward(smiles.to(device).float(), label))\n",
    "    \n",
    "    i += 1\n",
    "    if (i >= 10):\n",
    "        break\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9829], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.6236], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.6694], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.9319], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.8997], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.7196], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.7257], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.9225], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.6987], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0.6428], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    fake_input = []\n",
    "    fake_label = []\n",
    "    for item in generate_random_seed(batch_size):\n",
    "        fake_input.append(item[0])\n",
    "        fake_label.append(item[1])\n",
    "    \n",
    "    \n",
    "    fake_input = torch.FloatTensor(fake_input).to(device)\n",
    "    \n",
    "    #fake_input = fake_input.reshape(1, fake_input.shape[0], fake_input.shape[1])\n",
    "    fake_label = torch.FloatTensor(fake_label).to(device)\n",
    "    #print('2.before change label.shape', fake_input.shape, 'fake_label', fake_label.shape)\n",
    "    fake_label = fake_label.view(batch_size, 1, 1).repeat(1, fake_input.shape[1], 1)\n",
    "    #print('fake_input.shape', fake_input.shape, 'fake_label.shape', fake_label.shape)\n",
    "    target = torch.FloatTensor([0.0]).view(1,1,1).repeat(1, fake_input.shape[0] ,1).to(device)\n",
    "    print(D.forward(fake_input, fake_label))\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result tensor(22600, device='cuda:0') idx 22600 fake_input torch.Size([100]) fake_label.shape torch.Size([100]) result.shape torch.Size([])\n",
      "CC1C2CC1(O)C2CO\n"
     ]
    }
   ],
   "source": [
    "fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "fake_label = torch.FloatTensor(generate_random_value(G_input_size)).to(device)\n",
    "result = G.forward(fake_input, fake_label).detach()\n",
    "idx = result.cpu().numpy()\n",
    "print('result', result, 'idx', idx, 'fake_input', fake_input.shape, 'fake_label.shape', fake_label.shape,  'result.shape', result.shape)\n",
    "        \n",
    "#idx = self.get_index(G.forward(fake_input, fake_label)).detach().cpu().numpy()\n",
    "print(x_data['smiles'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model to file: pre_train_model/GAN20G202104160537.sav\n",
      "save model to file: pre_train_model/GAN20D202104160537.sav\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now() \n",
    "date_time = now.strftime(\"%Y%m%d%H%M\")\n",
    "G_filename = 'pre_train_model/GAN20G' + date_time + '.sav'\n",
    "print('save model to file:', G_filename)\n",
    "pickle.dump(G, open(G_filename, 'wb'))\n",
    "\n",
    "D_filename = 'pre_train_model/GAN20D' + date_time + '.sav'\n",
    "print('save model to file:', D_filename)\n",
    "pickle.dump(D, open(D_filename, 'wb'))\n",
    "\n",
    "\n",
    "#G_model = pickle.load(open(G_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "def classification_metrics(Y_pred, Y_true):\n",
    "    acc = accuracy_score(Y_true, Y_pred)\n",
    "    # auc is not working here\n",
    "    # roc_auc_score - Only one class present in y_true \n",
    "    auc_ = None\n",
    "    '''\n",
    "    try:\n",
    "        auc_ = roc_auc_score(Y_true, Y_pred)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    '''\n",
    "    \n",
    "    precision = precision_score(Y_true, Y_pred, average='weighted')\n",
    "    recall = recall_score(Y_true, Y_pred, average='weighted')\n",
    "    f1score = f1_score(Y_true, Y_pred, average='weighted')\n",
    "    return acc, auc_, precision, recall, f1score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9_dataset = pandas.read_csv('dataset/qm9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.77\n",
      "auc_ None\n",
      "precision 1.0\n",
      "recall 0.77\n",
      "f1score 0.8700564971751412\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "prodict = []\n",
    "number_of_verify = 100\n",
    "for i in range(number_of_verify):\n",
    "    test_smiles = G.get_smiles(1.0)\n",
    "    real = qm9_dataset[qm9_dataset['smiles'] == test_smiles ]\n",
    "    #print('Test Result:', real.iat[0,0],real.iat[0,1], real.iat[0,1] > baseline)\n",
    "    y_true.append(float(real.iat[0,1] > baseline) )\n",
    "    prodict.append(1.0)\n",
    "\n",
    "acc, auc_, precision, recall, f1score = classification_metrics(y_true, prodict)\n",
    "print('acc', acc)\n",
    "print('auc_', auc_)\n",
    "print('precision', precision)\n",
    "print('recall', recall)\n",
    "print('f1score', f1score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
