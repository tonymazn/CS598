{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import PandasTools, AllChem\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import pandas, numpy, random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif torch.cuda.is_available():\\n    torch.set_default_tensor_type(torch.cuda.FloatTensor)\\n    print(\"using cuda:\", torch.cuda.get_device_name(0))\\n    pass\\n\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\ndevice\\n\\nfrom multiprocessing import set_start_method\\ntry:\\n    set_start_method(\\'spawn\\')\\nexcept RuntimeError:\\n    pass\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if CUDA is available, use GPU and set default tensor type to cuda\n",
    "\n",
    "'''\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    print(\"using cuda:\", torch.cuda.get_device_name(0))\n",
    "    pass\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "from multiprocessing import set_start_method\n",
    "try:\n",
    "    set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "    pass\n",
    "'''    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMILESMolDataset(Dataset):\n",
    "    def __init__(self, molecules, y, vectorizer):\n",
    "        self.molecules = molecules\n",
    "        self.y = y\n",
    "        self.vectorizer = vectorizer\n",
    "    def __len__(self):\n",
    "        return len(self.molecules)\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "             \n",
    "        mols = self.molecules[idx]\n",
    "         \n",
    "        #The vectorizer was written to work with batches, \n",
    "        #but PyTorch datasets unfortunately works with single samples\n",
    "        sample = self.vectorizer.transform([mols])[0]\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_data 133885 max_mu 29.5564 min_mu 0.0\n",
      "0         0.0000\n",
      "1         1.6256\n",
      "2         1.8511\n",
      "3         0.0000\n",
      "4         2.8937\n",
      "           ...  \n",
      "133880    1.6637\n",
      "133881    1.2976\n",
      "133882    1.2480\n",
      "133883    1.9576\n",
      "133884    0.8626\n",
      "Name: mu, Length: 133885, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "real_data = pandas.read_csv('dataset/qm9.csv')\n",
    "max_mu = max(real_data['mu'])\n",
    "min_mu = min(real_data['mu'])\n",
    "number_of_data = len(real_data)\n",
    "\n",
    "print(\"number_of_data\", number_of_data, \"max_mu\", max_mu, \"min_mu\", min_mu)\n",
    "#real_data.head(5)\n",
    "\n",
    "\n",
    "print(real_data['mu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>mu</th>\n",
       "      <th>alpha</th>\n",
       "      <th>homo</th>\n",
       "      <th>lumo</th>\n",
       "      <th>gap</th>\n",
       "      <th>r2</th>\n",
       "      <th>zpve</th>\n",
       "      <th>cv</th>\n",
       "      <th>u0</th>\n",
       "      <th>u298</th>\n",
       "      <th>h298</th>\n",
       "      <th>g298</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.21</td>\n",
       "      <td>-0.3877</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>35.3641</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>6.469</td>\n",
       "      <td>-40.478930</td>\n",
       "      <td>-40.476062</td>\n",
       "      <td>-40.475117</td>\n",
       "      <td>-40.498597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>1.6256</td>\n",
       "      <td>9.46</td>\n",
       "      <td>-0.2570</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>26.1563</td>\n",
       "      <td>0.034358</td>\n",
       "      <td>6.316</td>\n",
       "      <td>-56.525887</td>\n",
       "      <td>-56.523026</td>\n",
       "      <td>-56.522082</td>\n",
       "      <td>-56.544961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>1.8511</td>\n",
       "      <td>6.31</td>\n",
       "      <td>-0.2928</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.3615</td>\n",
       "      <td>19.0002</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>6.002</td>\n",
       "      <td>-76.404702</td>\n",
       "      <td>-76.401867</td>\n",
       "      <td>-76.400922</td>\n",
       "      <td>-76.422349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C#C</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.28</td>\n",
       "      <td>-0.2845</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>59.5248</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>8.574</td>\n",
       "      <td>-77.308427</td>\n",
       "      <td>-77.305527</td>\n",
       "      <td>-77.304583</td>\n",
       "      <td>-77.327429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C#N</td>\n",
       "      <td>2.8937</td>\n",
       "      <td>12.99</td>\n",
       "      <td>-0.3604</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>48.7476</td>\n",
       "      <td>0.016601</td>\n",
       "      <td>6.278</td>\n",
       "      <td>-93.411888</td>\n",
       "      <td>-93.409370</td>\n",
       "      <td>-93.408425</td>\n",
       "      <td>-93.431246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  smiles      mu  alpha    homo    lumo     gap       r2      zpve     cv  \\\n",
       "0      C  0.0000  13.21 -0.3877  0.1171  0.5048  35.3641  0.044749  6.469   \n",
       "1      N  1.6256   9.46 -0.2570  0.0829  0.3399  26.1563  0.034358  6.316   \n",
       "2      O  1.8511   6.31 -0.2928  0.0687  0.3615  19.0002  0.021375  6.002   \n",
       "3    C#C  0.0000  16.28 -0.2845  0.0506  0.3351  59.5248  0.026841  8.574   \n",
       "4    C#N  2.8937  12.99 -0.3604  0.0191  0.3796  48.7476  0.016601  6.278   \n",
       "\n",
       "          u0       u298       h298       g298  \n",
       "0 -40.478930 -40.476062 -40.475117 -40.498597  \n",
       "1 -56.525887 -56.523026 -56.522082 -56.544961  \n",
       "2 -76.404702 -76.401867 -76.400922 -76.422349  \n",
       "3 -77.308427 -77.305527 -77.304583 -77.327429  \n",
       "4 -93.411888 -93.409370 -93.408425 -93.431246  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv('dataset/qm9.csv')\n",
    "#pandas.read_csv('dataset/GDB13_Subset-ABCDEFGH.smi', header=None, names=[\"smiles\"])\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>Molecule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  smiles                                           Molecule\n",
       "0      C  <img data-content=\"rdkit/molecule\" src=\"data:i..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PandasTools.AddMoleculeColumnToFrame(data,'smiles','Molecule')\n",
    "data = data[0:number_of_data]\n",
    "data[[\"smiles\",\"Molecule\"]].head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC=O'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['smiles'].iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>mu</th>\n",
       "      <th>alpha</th>\n",
       "      <th>homo</th>\n",
       "      <th>lumo</th>\n",
       "      <th>gap</th>\n",
       "      <th>r2</th>\n",
       "      <th>zpve</th>\n",
       "      <th>cv</th>\n",
       "      <th>u0</th>\n",
       "      <th>u298</th>\n",
       "      <th>h298</th>\n",
       "      <th>g298</th>\n",
       "      <th>Molecule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.21</td>\n",
       "      <td>-0.3877</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>35.3641</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>6.469</td>\n",
       "      <td>-40.47893</td>\n",
       "      <td>-40.476062</td>\n",
       "      <td>-40.475117</td>\n",
       "      <td>-40.498597</td>\n",
       "      <td><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  smiles   mu  alpha    homo    lumo     gap       r2      zpve     cv  \\\n",
       "0      C  0.0  13.21 -0.3877  0.1171  0.5048  35.3641  0.044749  6.469   \n",
       "\n",
       "         u0       u298       h298       g298  \\\n",
       "0 -40.47893 -40.476062 -40.475117 -40.498597   \n",
       "\n",
       "                                            Molecule  \n",
       "0  <img data-content=\"rdkit/molecule\" src=\"data:i...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data1 = real_data\n",
    "PandasTools.AddMoleculeColumnToFrame(real_data1,'smiles','Molecule')\n",
    "real_data1[[\"smiles\",\"Molecule\"]].head(1)\n",
    "real_data['Molecule'] = real_data1[['Molecule']]\n",
    "real_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from molvecgen.vectorizers import SmilesVectorizer\n",
    "\n",
    "smivec = SmilesVectorizer(pad=1, leftpad=True, canonical=False, augment=True)\n",
    "smivec.fit(real_data.Molecule.values, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "smivec_data = SmilesVectorizer(pad=1, leftpad=True, canonical=False, augment=True)\n",
    "smivec_data.fit(data.Molecule.values, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.6500,  5.9000,  1.9600, 22.2000,  5.0000])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# functions to generate random data\n",
    "\n",
    "def generate_random_seed_G(size):\n",
    "    random_data = torch.randn(size)\n",
    "    return random_data\n",
    "\n",
    "\n",
    "def generate_random_value(size):\n",
    "    random_data = np.round(np.random.randint(int(min_mu), int(max_mu * 100), (1, size))/100,4)\n",
    "    random_data = torch.FloatTensor(random_data)\n",
    "    #random_data = torch.round((torch.randn(size) * 10000) / 100)\n",
    "    #round(random.uniform(min_alpha, max_alpha),2)\n",
    "    return random_data.view(-1)\n",
    "\n",
    "generate_random_value(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_train) 133885 y_train[1] 9.46\n"
     ]
    }
   ],
   "source": [
    "y = real_data.mu.values.reshape((-1,1))\n",
    "X = real_data.Molecule.values\n",
    "\n",
    "#Normalizing output using standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = X\n",
    "y_train = real_data['alpha']\n",
    "#scaler.fit_transform(y)\n",
    "\n",
    "print('len(X_train)',len(X_train),'y_train[1]', y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dataset[10] (array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0]], dtype=int8), 1) data_y tensor([1.9800])\n"
     ]
    }
   ],
   "source": [
    "data_y = generate_random_value(number_of_data).reshape((-1,1))\n",
    "data_X = data.Molecule.values\n",
    "scaler = StandardScaler()\n",
    "#data_y = scaler.fit_transform(data_y)\n",
    "data_dataset = SMILESMolDataset(data_X, data_y, smivec_data)\n",
    "print('data_dataset[10]', data_dataset[10], 'data_y', data_y[10] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset[10] (array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0]], dtype=int8), 25) len(train_dataset[10][0]) 35\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SMILESMolDataset(X_train, y_train, smivec)\n",
    "train_dataset[10]\n",
    "print('train_dataset[10]', train_dataset[10], 'len(train_dataset[10][0])', len(train_dataset[10][0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a random SMILES from the GDB13_Subset\n",
    "def generate_random_seed(size):\n",
    "    index_list = np.random.randint(1, number_of_data, (1, size))[0]\n",
    "    random_data = []\n",
    "    for i in index_list:\n",
    "          random_data.append( data_dataset[i] )\n",
    "    #random_data = data_dataset[10]\n",
    "    return random_data\n",
    "\n",
    "generate_random_seed(2)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "dims = smivec.dims\n",
    "lstm_size = 128  # The size of the LSTM layer\n",
    "hidden_size = 128  # The size of the hidden non-linear layer\n",
    "dropout_rate = 0.50 # The dropout rate\n",
    "out_size = 1        # This is just a single task, so this will be one\n",
    "batch_size = 128   # The mini_batch size during training\n",
    "#batch_size = 1   # The mini_batch size during training\n",
    "G_input_size = 100 # The Generator input data size\n",
    "learning_rate_D = 0.003  # The Discriminator initial learning rate for the optimizer \n",
    "learning_rate_G = 0.001  # The Generator initial learning rate for the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator class\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # initialise parent pytorch class\n",
    "        super().__init__()\n",
    "        \n",
    "        length = dims[0] \n",
    "        number_tokens = dims[1] + 1  # add the label layer\n",
    "        #print('LSTM input_size', number_tokens)\n",
    "         \n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=number_tokens, hidden_size=lstm_size, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.fc1 = nn.Linear(lstm_size, hidden_size) # Output layer\n",
    "        self.activation = nn.ReLU() # Non-Linear ReLU Layer       \n",
    "        self.fc_out = nn.Linear(hidden_size, out_size) # Output layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)       \n",
    "        \n",
    "        # create loss function\n",
    "        self.loss_function = nn.MSELoss()\n",
    "\n",
    "        # create optimiser, simple stochastic gradient descent\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=learning_rate_D)\n",
    "        #self.lr_scheduler = ReduceLROnPlateau(self.optimiser, mode='min', factor=0.5, patience=50, \n",
    "        #          verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=1e-6, eps=1e-08)\n",
    "\n",
    "        # counter and accumulator for progress\n",
    "        self.counter = 0;\n",
    "        self.progress = []\n",
    "\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def forward(self, input_tensor, label_tensor):\n",
    "        # combine seed and label\n",
    "        \n",
    "        #print(\"input_tensor.shape\", input_tensor.shape, \"label_tensor.shape\", label_tensor.shape)\n",
    "        x = torch.cat((input_tensor, label_tensor), -1)\n",
    "        #print('after torch.cat', x.shape)\n",
    "        \n",
    "        \n",
    "        out, (h_n, c_n) = self.lstm(x) #LSTM network reads in one-hot-encoded SMILES, h_n is last output, out is for all timesteps\n",
    "        out = self.dropout(h_n) #Dropout\n",
    "        out = self.fc1(out) # Pass into the hidden layer\n",
    "        out = self.activation(out) # Use ReLU on hidden activation\n",
    "        out = self.dropout(out) # dropout\n",
    "        out = self.fc_out(out) # Use a linear layer for the output\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def train(self, inputs, label_tensor, targets):\n",
    "        # calculate the output of the network Discriminator\n",
    "        outputs = self.forward(inputs, label_tensor)\n",
    "        \n",
    "        \n",
    "        #print('outputs', outputs)\n",
    "        #print('targets', targets)\n",
    "        # calculate loss\n",
    "        #outputs = outputs.view(-1)\n",
    "        #targets = targets.view(-1)\n",
    "        #print('outputs.shape', outputs.shape, 'targets.shape',targets.shape)\n",
    "        \n",
    "        if (outputs.shape != targets.shape):\n",
    "            print(\"Generator loss function issue: outputs.shape != targets.shape\", outputs.shape, targets.shape)\n",
    "\n",
    "        loss = self.loss_function(outputs, targets)\n",
    "\n",
    "        # increase counter and accumulate error every 10\n",
    "        self.counter += 1;\n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss.item())\n",
    "            pass\n",
    "        if (self.counter % 1000 == 0):\n",
    "            print(\"counter = \", self.counter)\n",
    "            pass\n",
    "\n",
    "        # zero gradients, perform a backward pass, update weights\n",
    "        self.optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimiser.step()\n",
    "\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def plot_progress(self):\n",
    "        df = pandas.DataFrame(self.progress, columns=['loss'])\n",
    "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "data_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True, num_workers=4,drop_last=True )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter =  1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-31104559b53b>\u001b[0m in \u001b[0;36mgenerate_random_seed\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrandom_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           \u001b[0mrandom_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdata_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#random_data = data_dataset[10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrandom_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-70da5bd3fa48>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#The vectorizer was written to work with batches,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#but PyTorch datasets unfortunately works with single samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/molvecgen/vectorizers.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, mols, augment, canonical)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mmol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomize_mol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMolToSmiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcanonical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misomericSmiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misomericSmiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/molvecgen/vectorizers.py\u001b[0m in \u001b[0;36mrandomize_mol\u001b[0;34m(self, mol)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrandomize_mol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;34m\"\"\"Performs a randomization of the atom order of an RDKit molecule\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNumAtoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRenumberAtoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test discriminator can separate real data from random noise\n",
    "\n",
    "\n",
    "D = Discriminator()\n",
    "D.to(device)\n",
    "\n",
    "for smiles,label in data_loader:\n",
    "    # real\n",
    "    target = torch.FloatTensor([1.0]).view(1,1,1).repeat(1, smiles.shape[0] ,1).to(device)\n",
    "    #print('0.before change label.shape', label.shape, 'smiles', smiles.shape)\n",
    "    label = label.float().to(device)\n",
    "    label = label.view(batch_size, 1, 1).repeat(1, smiles.shape[1], 1)\n",
    "    #print('1.before change label.shape', label.shape, 'smiles', smiles.shape)\n",
    "    D.train(smiles.to(device).float(), label, target)\n",
    "    \n",
    "    # fake\n",
    "    fake_input = []\n",
    "    fake_label = []\n",
    "    for finput, label in generate_random_seed(batch_size):\n",
    "        fake_input.append(finput)\n",
    "        fake_label.append(label)\n",
    "    \n",
    "    \n",
    "    fake_input = torch.FloatTensor(fake_input).to(device)\n",
    "    \n",
    "    #fake_input = fake_input.reshape(1, fake_input.shape[0], fake_input.shape[1])\n",
    "    fake_label = torch.FloatTensor(fake_label).to(device)\n",
    "    #print('2.before change label.shape', fake_input.shape, 'fake_label', fake_label.shape)\n",
    "    fake_label = fake_label.view(batch_size, 1, 1).repeat(1, fake_input.shape[1], 1)\n",
    "    #fake_label.unsqueeze(1).repeat(1, fake_input.shape[1], 1)\n",
    "    #print('fake_input.shape', fake_input.shape, 'fake_label.shape', fake_label.shape)\n",
    "    target = torch.FloatTensor([0.0]).view(1,1,1).repeat(1, fake_input.shape[0] ,1).to(device)\n",
    "    D.train(fake_input, fake_label, target)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8916],\n",
      "         [1.0806],\n",
      "         [0.9335],\n",
      "         [0.8548],\n",
      "         [0.9606],\n",
      "         [1.0207],\n",
      "         [1.0125],\n",
      "         [0.8104],\n",
      "         [0.8963],\n",
      "         [1.0322],\n",
      "         [0.8586],\n",
      "         [0.9098],\n",
      "         [0.9737],\n",
      "         [0.9896],\n",
      "         [0.9341],\n",
      "         [0.8862],\n",
      "         [1.1121],\n",
      "         [1.0339],\n",
      "         [1.0832],\n",
      "         [1.0155],\n",
      "         [1.0494],\n",
      "         [1.0148],\n",
      "         [0.8850],\n",
      "         [1.0414],\n",
      "         [1.0068],\n",
      "         [0.9914],\n",
      "         [1.1001],\n",
      "         [1.2402],\n",
      "         [1.0311],\n",
      "         [0.9234],\n",
      "         [1.0123],\n",
      "         [0.9688],\n",
      "         [1.0920],\n",
      "         [0.9693],\n",
      "         [0.9960],\n",
      "         [1.0463],\n",
      "         [0.9451],\n",
      "         [0.7333],\n",
      "         [1.0107],\n",
      "         [1.0893],\n",
      "         [0.8623],\n",
      "         [0.8412],\n",
      "         [1.0657],\n",
      "         [0.9654],\n",
      "         [0.8982],\n",
      "         [0.9847],\n",
      "         [1.0536],\n",
      "         [0.9589],\n",
      "         [1.0065],\n",
      "         [0.9510],\n",
      "         [1.1867],\n",
      "         [1.0196],\n",
      "         [1.1399],\n",
      "         [0.8997],\n",
      "         [1.1083],\n",
      "         [0.8997],\n",
      "         [1.0192],\n",
      "         [0.9406],\n",
      "         [0.9697],\n",
      "         [0.9593],\n",
      "         [0.9237],\n",
      "         [1.0386],\n",
      "         [1.1379],\n",
      "         [0.9890],\n",
      "         [0.8947],\n",
      "         [0.9722],\n",
      "         [1.1732],\n",
      "         [0.9458],\n",
      "         [0.9095],\n",
      "         [0.9332],\n",
      "         [0.9747],\n",
      "         [1.1263],\n",
      "         [0.9720],\n",
      "         [1.1111],\n",
      "         [1.0515],\n",
      "         [1.0099],\n",
      "         [0.8652],\n",
      "         [1.1105],\n",
      "         [1.0668],\n",
      "         [0.8475],\n",
      "         [0.9761],\n",
      "         [0.9212],\n",
      "         [1.0734],\n",
      "         [0.9124],\n",
      "         [1.0852],\n",
      "         [1.0219],\n",
      "         [1.0092],\n",
      "         [1.1720],\n",
      "         [1.0503],\n",
      "         [0.9683],\n",
      "         [1.0190],\n",
      "         [0.9658],\n",
      "         [0.9572],\n",
      "         [0.9401],\n",
      "         [0.9602],\n",
      "         [0.8877],\n",
      "         [0.9068],\n",
      "         [0.8683],\n",
      "         [1.0366],\n",
      "         [1.1103],\n",
      "         [1.0560],\n",
      "         [1.0322],\n",
      "         [1.0174],\n",
      "         [0.8095],\n",
      "         [0.8589],\n",
      "         [0.9025],\n",
      "         [0.9212],\n",
      "         [1.0484],\n",
      "         [1.0681],\n",
      "         [1.0435],\n",
      "         [1.0641],\n",
      "         [0.9973],\n",
      "         [1.0159],\n",
      "         [0.9175],\n",
      "         [1.0411],\n",
      "         [0.9044],\n",
      "         [0.9971],\n",
      "         [1.0994],\n",
      "         [1.0040],\n",
      "         [0.9005],\n",
      "         [0.9995],\n",
      "         [1.0141],\n",
      "         [1.0342],\n",
      "         [0.9294],\n",
      "         [0.8838],\n",
      "         [1.1148],\n",
      "         [0.9448],\n",
      "         [0.9884]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[[0.8704],\n",
      "         [0.8962],\n",
      "         [1.0404],\n",
      "         [1.2595],\n",
      "         [0.9885],\n",
      "         [0.9709],\n",
      "         [1.2235],\n",
      "         [0.9765],\n",
      "         [1.0581],\n",
      "         [1.0056],\n",
      "         [0.9235],\n",
      "         [1.0135],\n",
      "         [1.0762],\n",
      "         [0.9452],\n",
      "         [1.0292],\n",
      "         [1.0478],\n",
      "         [1.0254],\n",
      "         [0.9298],\n",
      "         [1.0373],\n",
      "         [0.9224],\n",
      "         [0.9481],\n",
      "         [1.0022],\n",
      "         [1.1146],\n",
      "         [1.0292],\n",
      "         [1.0695],\n",
      "         [1.0813],\n",
      "         [1.1713],\n",
      "         [1.0508],\n",
      "         [1.1085],\n",
      "         [0.9285],\n",
      "         [0.9594],\n",
      "         [1.1133],\n",
      "         [0.9344],\n",
      "         [0.9555],\n",
      "         [1.0548],\n",
      "         [0.8154],\n",
      "         [1.0304],\n",
      "         [0.9619],\n",
      "         [1.1778],\n",
      "         [1.0447],\n",
      "         [1.0236],\n",
      "         [0.9131],\n",
      "         [0.9470],\n",
      "         [0.9891],\n",
      "         [1.0058],\n",
      "         [0.8991],\n",
      "         [1.0314],\n",
      "         [1.0032],\n",
      "         [1.0458],\n",
      "         [1.0625],\n",
      "         [1.1128],\n",
      "         [0.9556],\n",
      "         [1.0422],\n",
      "         [1.0493],\n",
      "         [0.9855],\n",
      "         [0.8726],\n",
      "         [0.7952],\n",
      "         [1.0644],\n",
      "         [1.1030],\n",
      "         [1.0361],\n",
      "         [1.0949],\n",
      "         [0.9667],\n",
      "         [0.9876],\n",
      "         [0.9714],\n",
      "         [1.0652],\n",
      "         [1.0872],\n",
      "         [1.0710],\n",
      "         [1.1943],\n",
      "         [0.9847],\n",
      "         [0.8420],\n",
      "         [1.0483],\n",
      "         [1.2035],\n",
      "         [0.8741],\n",
      "         [0.9093],\n",
      "         [1.0727],\n",
      "         [0.9513],\n",
      "         [0.9990],\n",
      "         [1.1280],\n",
      "         [0.8003],\n",
      "         [1.0293],\n",
      "         [0.8812],\n",
      "         [0.9040],\n",
      "         [0.8239],\n",
      "         [0.9280],\n",
      "         [1.1723],\n",
      "         [0.9828],\n",
      "         [1.0550],\n",
      "         [0.9643],\n",
      "         [1.0297],\n",
      "         [0.9468],\n",
      "         [1.0426],\n",
      "         [1.0740],\n",
      "         [0.9189],\n",
      "         [1.0162],\n",
      "         [0.9624],\n",
      "         [0.8396],\n",
      "         [0.8785],\n",
      "         [0.9474],\n",
      "         [0.8974],\n",
      "         [1.0147],\n",
      "         [1.1423],\n",
      "         [1.0471],\n",
      "         [0.8738],\n",
      "         [0.8903],\n",
      "         [0.9684],\n",
      "         [1.0390],\n",
      "         [1.0029],\n",
      "         [1.0457],\n",
      "         [0.9775],\n",
      "         [1.0468],\n",
      "         [0.8347],\n",
      "         [1.0747],\n",
      "         [1.0552],\n",
      "         [0.9491],\n",
      "         [0.8913],\n",
      "         [1.0430],\n",
      "         [0.9965],\n",
      "         [0.9056],\n",
      "         [0.8429],\n",
      "         [1.0206],\n",
      "         [0.9074],\n",
      "         [0.9122],\n",
      "         [0.9642],\n",
      "         [0.8961],\n",
      "         [0.9036],\n",
      "         [0.9600],\n",
      "         [0.8834],\n",
      "         [0.9157]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[[1.0956],\n",
      "         [1.0637],\n",
      "         [0.9590],\n",
      "         [1.1621],\n",
      "         [0.9956],\n",
      "         [0.9614],\n",
      "         [1.0467],\n",
      "         [0.9728],\n",
      "         [0.9639],\n",
      "         [1.0043],\n",
      "         [1.0344],\n",
      "         [1.0683],\n",
      "         [0.9833],\n",
      "         [1.0317],\n",
      "         [1.0785],\n",
      "         [1.0348],\n",
      "         [0.9801],\n",
      "         [1.2284],\n",
      "         [1.1021],\n",
      "         [0.9577],\n",
      "         [1.0379],\n",
      "         [1.0352],\n",
      "         [0.9349],\n",
      "         [0.8694],\n",
      "         [1.1800],\n",
      "         [0.9290],\n",
      "         [1.0792],\n",
      "         [1.0125],\n",
      "         [1.0863],\n",
      "         [1.0274],\n",
      "         [1.0478],\n",
      "         [1.0640],\n",
      "         [0.8787],\n",
      "         [1.0991],\n",
      "         [0.9278],\n",
      "         [1.0334],\n",
      "         [1.1091],\n",
      "         [1.0390],\n",
      "         [0.9707],\n",
      "         [0.8277],\n",
      "         [0.9627],\n",
      "         [1.0486],\n",
      "         [1.0120],\n",
      "         [0.9864],\n",
      "         [1.1031],\n",
      "         [1.1583],\n",
      "         [1.0534],\n",
      "         [1.0580],\n",
      "         [0.9653],\n",
      "         [0.9816],\n",
      "         [0.9260],\n",
      "         [0.9856],\n",
      "         [1.0627],\n",
      "         [0.8987],\n",
      "         [0.9626],\n",
      "         [1.0804],\n",
      "         [1.0095],\n",
      "         [1.0897],\n",
      "         [0.8167],\n",
      "         [1.0062],\n",
      "         [0.9279],\n",
      "         [0.9846],\n",
      "         [1.1445],\n",
      "         [0.9861],\n",
      "         [0.8478],\n",
      "         [1.0237],\n",
      "         [0.8092],\n",
      "         [0.8924],\n",
      "         [0.9556],\n",
      "         [0.9507],\n",
      "         [1.0610],\n",
      "         [1.0351],\n",
      "         [1.0131],\n",
      "         [0.8335],\n",
      "         [0.8595],\n",
      "         [0.8759],\n",
      "         [1.1019],\n",
      "         [0.9793],\n",
      "         [1.0294],\n",
      "         [0.9419],\n",
      "         [1.0137],\n",
      "         [1.1186],\n",
      "         [1.1524],\n",
      "         [0.9383],\n",
      "         [0.9301],\n",
      "         [0.8550],\n",
      "         [0.8397],\n",
      "         [0.8887],\n",
      "         [1.0491],\n",
      "         [0.9365],\n",
      "         [1.1195],\n",
      "         [1.0247],\n",
      "         [1.1643],\n",
      "         [0.9030],\n",
      "         [0.8697],\n",
      "         [0.8942],\n",
      "         [0.9134],\n",
      "         [0.9743],\n",
      "         [0.9900],\n",
      "         [1.1532],\n",
      "         [0.9721],\n",
      "         [1.1293],\n",
      "         [0.9545],\n",
      "         [0.9548],\n",
      "         [1.2000],\n",
      "         [0.9630],\n",
      "         [1.0613],\n",
      "         [0.7826],\n",
      "         [0.8281],\n",
      "         [0.9257],\n",
      "         [0.9632],\n",
      "         [0.8779],\n",
      "         [1.0815],\n",
      "         [1.0968],\n",
      "         [0.8703],\n",
      "         [0.9506],\n",
      "         [0.9545],\n",
      "         [1.0467],\n",
      "         [0.9833],\n",
      "         [1.0136],\n",
      "         [0.8627],\n",
      "         [0.9537],\n",
      "         [1.0472],\n",
      "         [1.0289],\n",
      "         [1.0899],\n",
      "         [0.8820],\n",
      "         [1.0076],\n",
      "         [1.0575]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[[1.0700],\n",
      "         [1.0607],\n",
      "         [0.9212],\n",
      "         [1.0742],\n",
      "         [1.1339],\n",
      "         [1.0561],\n",
      "         [1.0272],\n",
      "         [0.9427],\n",
      "         [0.9570],\n",
      "         [0.9243],\n",
      "         [0.9319],\n",
      "         [0.9324],\n",
      "         [0.9960],\n",
      "         [1.0099],\n",
      "         [0.9407],\n",
      "         [1.0137],\n",
      "         [0.9463],\n",
      "         [0.9266],\n",
      "         [0.7953],\n",
      "         [1.1503],\n",
      "         [0.9919],\n",
      "         [1.1271],\n",
      "         [0.9998],\n",
      "         [0.9556],\n",
      "         [0.9775],\n",
      "         [0.9477],\n",
      "         [1.0490],\n",
      "         [1.0417],\n",
      "         [1.0074],\n",
      "         [0.9113],\n",
      "         [0.9164],\n",
      "         [0.9883],\n",
      "         [0.8969],\n",
      "         [1.0172],\n",
      "         [1.0897],\n",
      "         [0.8429],\n",
      "         [0.9189],\n",
      "         [1.1351],\n",
      "         [0.9716],\n",
      "         [0.9102],\n",
      "         [1.0397],\n",
      "         [0.9283],\n",
      "         [0.9908],\n",
      "         [0.8713],\n",
      "         [0.9775],\n",
      "         [1.0669],\n",
      "         [1.0201],\n",
      "         [0.9724],\n",
      "         [0.8908],\n",
      "         [0.9438],\n",
      "         [1.0776],\n",
      "         [0.9349],\n",
      "         [0.9076],\n",
      "         [0.8913],\n",
      "         [1.0631],\n",
      "         [0.9944],\n",
      "         [0.8102],\n",
      "         [1.1873],\n",
      "         [0.9720],\n",
      "         [1.0506],\n",
      "         [0.9159],\n",
      "         [0.9362],\n",
      "         [0.9924],\n",
      "         [0.9836],\n",
      "         [0.9728],\n",
      "         [1.0456],\n",
      "         [0.9559],\n",
      "         [0.9114],\n",
      "         [0.9799],\n",
      "         [1.0211],\n",
      "         [1.0498],\n",
      "         [1.0257],\n",
      "         [1.1435],\n",
      "         [1.1235],\n",
      "         [1.1173],\n",
      "         [1.0036],\n",
      "         [1.0173],\n",
      "         [1.0574],\n",
      "         [1.0039],\n",
      "         [1.0501],\n",
      "         [1.1745],\n",
      "         [0.8820],\n",
      "         [0.9408],\n",
      "         [1.0821],\n",
      "         [1.0740],\n",
      "         [1.0898],\n",
      "         [1.1236],\n",
      "         [1.0360],\n",
      "         [1.0138],\n",
      "         [1.1010],\n",
      "         [0.9520],\n",
      "         [1.0084],\n",
      "         [1.0520],\n",
      "         [0.9784],\n",
      "         [1.0764],\n",
      "         [0.9747],\n",
      "         [1.0783],\n",
      "         [0.9041],\n",
      "         [0.9727],\n",
      "         [0.9846],\n",
      "         [1.0202],\n",
      "         [1.0389],\n",
      "         [0.8790],\n",
      "         [0.9089],\n",
      "         [1.0373],\n",
      "         [0.8948],\n",
      "         [0.8541],\n",
      "         [1.1147],\n",
      "         [1.0383],\n",
      "         [1.0753],\n",
      "         [1.0420],\n",
      "         [1.0107],\n",
      "         [1.0543],\n",
      "         [1.0327],\n",
      "         [1.1110],\n",
      "         [0.9277],\n",
      "         [0.9771],\n",
      "         [1.0394],\n",
      "         [1.2630],\n",
      "         [1.1104],\n",
      "         [0.9067],\n",
      "         [1.0094],\n",
      "         [1.0523],\n",
      "         [0.9483],\n",
      "         [1.0363],\n",
      "         [1.0382],\n",
      "         [0.9341],\n",
      "         [0.9692]]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "for smiles,label in data_loader:\n",
    "    # real\n",
    "    target = torch.FloatTensor([1.0]).view(1,1,1).repeat(1, smiles.shape[0] ,1).to(device)\n",
    "    label = label.float().to(device)\n",
    "    label = label.view(batch_size, 1, 1).repeat(1, smiles.shape[1], 1)\n",
    "    print(D.forward(smiles.to(device).float(), label))\n",
    "    \n",
    "    i += 1\n",
    "    if (i >= 4):\n",
    "        break\n",
    "    pass\n",
    "\n",
    "for i in range(4):\n",
    "    fake_input = []\n",
    "    fake_label = []\n",
    "    for finput, label in generate_random_seed(batch_size):\n",
    "        fake_input.append(finput)\n",
    "        fake_label.append(label)\n",
    "    \n",
    "    \n",
    "    fake_input = torch.FloatTensor(fake_input).to(device)\n",
    "    \n",
    "    #fake_input = fake_input.reshape(1, fake_input.shape[0], fake_input.shape[1])\n",
    "    fake_label = torch.FloatTensor(fake_label).to(device)\n",
    "    #print('2.before change label.shape', fake_input.shape, 'fake_label', fake_label.shape)\n",
    "    fake_label = fake_label.view(batch_size, 1, 1).repeat(1, fake_input.shape[1], 1)\n",
    "    #print('fake_input.shape', fake_input.shape, 'fake_label.shape', fake_label.shape)\n",
    "    target = torch.FloatTensor([0.0]).view(1,1,1).repeat(1, fake_input.shape[0] ,1).to(device)\n",
    "    D.forward(fake_input, fake_label)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator class\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        # initialise parent pytorch class\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = batch_size \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(G_input_size * 2, 200),\n",
    "            nn.LeakyReLU(0.02),\n",
    "            #nn.LayerNorm(200),\n",
    "            nn.Linear(200, number_of_data)\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # create optimiser, simple stochastic gradient descent\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=learning_rate_G)\n",
    "        \n",
    "        # counter and accumulator for progress\n",
    "        self.counter = 0;\n",
    "        self.progress = []\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def forward(self, seed_tensor, label_tensor):        \n",
    "        # combine seed and label\n",
    "        #print('seed_tensor.shape', seed_tensor.shape, 'label_tensor', label_tensor.shape)\n",
    "        inputs = torch.cat((seed_tensor, label_tensor))\n",
    "        #print('after torch.cat', inputs.shape)\n",
    "        outputs = self.model(inputs)\n",
    "        #print('outputs', outputs)\n",
    "        return torch.argmax(F.softmax(outputs, dim=0))\n",
    "\n",
    "\n",
    "    def train(self, D, inputs, label_tensor, targets):\n",
    "        # calculate the output of the network\n",
    "        g_output = self.forward(inputs, label_tensor)\n",
    "\n",
    "        g_data = data_dataset[g_output]\n",
    "        \n",
    "        g_input = torch.FloatTensor(g_data[0]).to(device)\n",
    "        g_input = g_input.reshape(1, g_input.shape[0], g_input.shape[1])\n",
    "        g_label = torch.FloatTensor(g_data[1]).to(device)\n",
    "        g_label = g_label.unsqueeze(1).repeat(1, g_input.shape[1], 1)\n",
    "        if (self.counter % 1000 == 0):\n",
    "            print('g_output', g_output, 'g_data[1]', g_data[1])        \n",
    "        \n",
    "        # pass onto Discriminator\n",
    "        d_output = D.forward(g_input, g_label)\n",
    "        \n",
    "        #print('d_output.shape', d_output.shape, 'targets.shape', targets.shape)\n",
    "        if (d_output.shape != targets.shape):\n",
    "            print(\"Generator loss function issue: d_output.shape != targets.shape\", d_output.shape, targets.shape)\n",
    "        \n",
    "        # calculate error\n",
    "        loss = D.loss_function(d_output, targets)\n",
    "\n",
    "        # increase counter and accumulate error every 10\n",
    "        self.counter += 1;\n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss.item())\n",
    "            pass\n",
    "\n",
    "        # zero gradients, perform a backward pass, update weights\n",
    "        self.optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimiser.step()\n",
    "\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def get_smiles(self, label):\n",
    "        #fake_input = torch.FloatTensor(generate_random_seed_G(batch_size)).to(device)\n",
    "        #fake_label = torch.FloatTensor([label]).to(device)\n",
    "        \n",
    "        fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "        fake_label = torch.FloatTensor(generate_random_value(G_input_size)).to(device)\n",
    "        idx = self.forward(fake_input, fake_label).detach().cpu().numpy()\n",
    "        #print('idx', idx, 'fake_input', fake_input.shape, 'fake_label.shape', fake_label.shape,  'result.shape', result.shape)\n",
    "        \n",
    "        #idx = self.get_index(G.forward(fake_input, fake_label)).detach().cpu().numpy()\n",
    "        return data['smiles'].iloc[idx]\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def plot_progress(self):\n",
    "        df = pandas.DataFrame(self.progress, columns=['loss'])\n",
    "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx tensor(21139, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0]], dtype=int8),\n",
       " 15)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the generator output is of the right type and shape\n",
    "\n",
    "G = Generator(1)\n",
    "G.to(device)\n",
    "\n",
    "#fake = generate_random_seed()\n",
    "fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "fake_label = torch.FloatTensor(generate_random_value(G_input_size)).to(device)\n",
    "idx = G.forward(fake_input, fake_label)\n",
    "print('idx', idx)\n",
    "data_dataset[idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCOC(=O)NC1CC1'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.get_smiles(-12.2323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Got 21 and 1 (The offending index is 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-7fb9ed74ab34>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inputs, label_tensor, targets)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# calculate the output of the network Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-7fb9ed74ab34>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, label_tensor)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#print(\"input_tensor.shape\", input_tensor.shape, \"label_tensor.shape\", label_tensor.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;31m#print('after torch.cat', x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Got 21 and 1 (The offending index is 0)"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "D = Discriminator()\n",
    "D.to(device)\n",
    "G = Generator(batch_size)\n",
    "G.to(device)\n",
    "\n",
    "# train Discriminator and Generator\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print (\"epoch = \", epoch + 1)\n",
    "\n",
    "    # train Discriminator and Generator\n",
    "    for smiles,label in data_loader:\n",
    "        #########################################################                   \n",
    "        # train discriminator on true\n",
    "        #########################################################                   \n",
    "        target = torch.FloatTensor([1.0]).view(1,1,1).repeat(1, smiles.shape[0] ,1).to(device)\n",
    "        #print('1.before change label.shape', label.shape, 'smiles', smiles.shape)\n",
    "        label = label.float().to(device)\n",
    "        label = label.view(batch_size, 1, 1).repeat(1, smiles.shape[1], 1)\n",
    "        D.train(smiles.to(device).float(), label, target)\n",
    "        \n",
    "        \n",
    "        #########################################################                   \n",
    "        # train discriminator on false\n",
    "        # use detach() so gradients in G are not calculated\n",
    "        #########################################################                   \n",
    "        fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "        fake_label = torch.FloatTensor(generate_random_value(G_input_size)).to(device)\n",
    "        data_inx = G.forward(fake_input, fake_label).detach()\n",
    "        #print(\"data_inx\", data_inx)\n",
    "\n",
    "        fake = data_dataset[data_inx]\n",
    "        #print('fake', fake)\n",
    "        \n",
    "        fake_input = torch.FloatTensor(fake[0]).to(device)\n",
    "        fake_input = fake_input.reshape(1, fake_input.shape[0], fake_input.shape[1])\n",
    "        fake_label = torch.FloatTensor(fake[1]).to(device)\n",
    "        #print('fake_label.shape', fake_label.shape)\n",
    "        \n",
    "        fake_label = fake_label.view(fake_label.shape[0], 1, 1).repeat(1, fake_input.shape[1], 1)\n",
    "        target = torch.FloatTensor([0.0]).view(1,1,1).repeat(1, fake_input.shape[0] ,1).to(device)\n",
    "        D.train(fake_input, fake_label, target )\n",
    "\n",
    "        \n",
    "        #########################################################                   \n",
    "        # train generator\n",
    "        #########################################################                   \n",
    "        fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "        fake_label = torch.FloatTensor(generate_random_value(G_input_size)).to(device)\n",
    "        #fake_label = fake_label.unsqueeze(1).repeat(1, fake_input.shape[1], 1)\n",
    "        target = torch.FloatTensor([0.0]).view(1,1,1).to(device)\n",
    "        G.train(D, fake_input, fake_label, target)\n",
    "        \n",
    "    pass\n",
    "    \n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "G.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9822],\n",
      "         [1.0225],\n",
      "         [0.9932],\n",
      "         [1.0915],\n",
      "         [1.0380],\n",
      "         [0.8382],\n",
      "         [1.0040],\n",
      "         [0.9727],\n",
      "         [1.1051],\n",
      "         [0.9329],\n",
      "         [0.9708],\n",
      "         [0.9263],\n",
      "         [0.9099],\n",
      "         [0.6865],\n",
      "         [0.9419],\n",
      "         [0.8972],\n",
      "         [0.9458],\n",
      "         [0.9224],\n",
      "         [0.9017],\n",
      "         [0.9162],\n",
      "         [1.1107],\n",
      "         [0.9834],\n",
      "         [1.0468],\n",
      "         [0.9882],\n",
      "         [1.1864],\n",
      "         [0.9131],\n",
      "         [0.7678],\n",
      "         [1.0688],\n",
      "         [0.8212],\n",
      "         [0.9260],\n",
      "         [0.8728],\n",
      "         [0.9501],\n",
      "         [1.3666],\n",
      "         [1.0841],\n",
      "         [1.0651],\n",
      "         [0.7742],\n",
      "         [0.8229],\n",
      "         [0.9955],\n",
      "         [0.9776],\n",
      "         [1.1073],\n",
      "         [0.8616],\n",
      "         [1.1918],\n",
      "         [1.1941],\n",
      "         [1.1006],\n",
      "         [1.1178],\n",
      "         [0.8936],\n",
      "         [1.1159],\n",
      "         [0.9908],\n",
      "         [1.0101],\n",
      "         [0.9311],\n",
      "         [0.8397],\n",
      "         [1.0343],\n",
      "         [0.9930],\n",
      "         [0.9933],\n",
      "         [0.9399],\n",
      "         [0.9329],\n",
      "         [1.1759],\n",
      "         [0.9923],\n",
      "         [0.9874],\n",
      "         [1.0775],\n",
      "         [1.0812],\n",
      "         [0.9319],\n",
      "         [1.1674],\n",
      "         [0.9737],\n",
      "         [1.0545],\n",
      "         [1.1946],\n",
      "         [0.9624],\n",
      "         [0.9344],\n",
      "         [0.9925],\n",
      "         [0.8222],\n",
      "         [1.3023],\n",
      "         [0.9484],\n",
      "         [1.0702],\n",
      "         [0.9316],\n",
      "         [0.9405],\n",
      "         [0.7498],\n",
      "         [1.0781],\n",
      "         [1.0466],\n",
      "         [1.0458],\n",
      "         [1.0353],\n",
      "         [1.0045],\n",
      "         [0.9045],\n",
      "         [1.0553],\n",
      "         [1.0593],\n",
      "         [0.8339],\n",
      "         [1.0983],\n",
      "         [0.9327],\n",
      "         [1.0424],\n",
      "         [0.8276],\n",
      "         [1.0032],\n",
      "         [1.2087],\n",
      "         [0.7568],\n",
      "         [1.2547],\n",
      "         [0.8366],\n",
      "         [0.8399],\n",
      "         [0.8914],\n",
      "         [0.9496],\n",
      "         [1.0890],\n",
      "         [1.0213],\n",
      "         [0.9241],\n",
      "         [1.1136],\n",
      "         [1.1439],\n",
      "         [1.0709],\n",
      "         [1.0326],\n",
      "         [0.9431],\n",
      "         [1.0738],\n",
      "         [0.9242],\n",
      "         [1.0931],\n",
      "         [1.2680],\n",
      "         [0.9488],\n",
      "         [1.1075],\n",
      "         [0.9277],\n",
      "         [0.8883],\n",
      "         [1.1135],\n",
      "         [1.0366],\n",
      "         [0.9654],\n",
      "         [1.0482],\n",
      "         [1.0863],\n",
      "         [1.0787],\n",
      "         [1.0278],\n",
      "         [1.0327],\n",
      "         [1.1027],\n",
      "         [0.9067],\n",
      "         [0.9723],\n",
      "         [0.8739],\n",
      "         [1.0533],\n",
      "         [0.9243],\n",
      "         [1.0185]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[[1.0493],\n",
      "         [1.1764],\n",
      "         [0.8251],\n",
      "         [1.1279],\n",
      "         [1.0088],\n",
      "         [1.0803],\n",
      "         [1.1771],\n",
      "         [0.8798],\n",
      "         [1.0915],\n",
      "         [0.9090],\n",
      "         [1.0103],\n",
      "         [1.1051],\n",
      "         [0.9127],\n",
      "         [0.9629],\n",
      "         [1.2195],\n",
      "         [0.8887],\n",
      "         [1.1548],\n",
      "         [1.0198],\n",
      "         [0.9183],\n",
      "         [1.0263],\n",
      "         [1.0243],\n",
      "         [0.8811],\n",
      "         [1.0403],\n",
      "         [1.2526],\n",
      "         [0.8183],\n",
      "         [1.0136],\n",
      "         [0.9007],\n",
      "         [1.1396],\n",
      "         [0.9119],\n",
      "         [1.1148],\n",
      "         [1.1137],\n",
      "         [0.9458],\n",
      "         [1.0801],\n",
      "         [1.0797],\n",
      "         [0.9036],\n",
      "         [0.8993],\n",
      "         [0.8093],\n",
      "         [0.8555],\n",
      "         [1.0502],\n",
      "         [1.0397],\n",
      "         [1.1415],\n",
      "         [1.1921],\n",
      "         [1.0324],\n",
      "         [1.0755],\n",
      "         [0.8285],\n",
      "         [1.2009],\n",
      "         [1.0100],\n",
      "         [1.1280],\n",
      "         [0.9201],\n",
      "         [0.9408],\n",
      "         [1.1239],\n",
      "         [1.0433],\n",
      "         [1.1427],\n",
      "         [0.8983],\n",
      "         [0.7664],\n",
      "         [0.9341],\n",
      "         [0.8203],\n",
      "         [0.7559],\n",
      "         [1.0664],\n",
      "         [1.0811],\n",
      "         [1.0207],\n",
      "         [0.9482],\n",
      "         [1.0227],\n",
      "         [1.1736],\n",
      "         [1.0574],\n",
      "         [0.8403],\n",
      "         [0.9102],\n",
      "         [1.0852],\n",
      "         [1.0505],\n",
      "         [0.6681],\n",
      "         [0.9006],\n",
      "         [1.0391],\n",
      "         [0.9952],\n",
      "         [0.9166],\n",
      "         [0.9515],\n",
      "         [0.9768],\n",
      "         [0.9469],\n",
      "         [0.8463],\n",
      "         [1.0121],\n",
      "         [0.9608],\n",
      "         [0.8895],\n",
      "         [0.9631],\n",
      "         [1.0102],\n",
      "         [1.1137],\n",
      "         [0.9675],\n",
      "         [0.9074],\n",
      "         [0.9584],\n",
      "         [1.0984],\n",
      "         [1.1216],\n",
      "         [1.0504],\n",
      "         [0.8278],\n",
      "         [1.2030],\n",
      "         [0.8563],\n",
      "         [1.1281],\n",
      "         [0.9658],\n",
      "         [0.8330],\n",
      "         [1.0438],\n",
      "         [1.1289],\n",
      "         [1.1767],\n",
      "         [0.8491],\n",
      "         [1.0573],\n",
      "         [0.9564],\n",
      "         [0.9163],\n",
      "         [1.0279],\n",
      "         [1.0168],\n",
      "         [0.9465],\n",
      "         [1.0092],\n",
      "         [1.1467],\n",
      "         [1.0573],\n",
      "         [1.1231],\n",
      "         [0.9412],\n",
      "         [0.8225],\n",
      "         [0.9360],\n",
      "         [0.9418],\n",
      "         [0.9165],\n",
      "         [1.0292],\n",
      "         [1.0247],\n",
      "         [0.9880],\n",
      "         [0.9309],\n",
      "         [0.9827],\n",
      "         [1.0307],\n",
      "         [0.9375],\n",
      "         [0.8969],\n",
      "         [1.1656],\n",
      "         [0.9640],\n",
      "         [0.8608],\n",
      "         [1.1804],\n",
      "         [0.9766]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[[0.9008],\n",
      "         [0.8128],\n",
      "         [0.9024],\n",
      "         [1.0341],\n",
      "         [0.8091],\n",
      "         [1.1003],\n",
      "         [0.9494],\n",
      "         [0.9964],\n",
      "         [1.1400],\n",
      "         [1.0613],\n",
      "         [1.1271],\n",
      "         [1.0878],\n",
      "         [0.8371],\n",
      "         [1.0646],\n",
      "         [0.9334],\n",
      "         [0.9883],\n",
      "         [1.0965],\n",
      "         [1.3005],\n",
      "         [0.9353],\n",
      "         [0.9296],\n",
      "         [1.1862],\n",
      "         [0.9775],\n",
      "         [1.0275],\n",
      "         [1.0476],\n",
      "         [1.0508],\n",
      "         [0.9892],\n",
      "         [0.9824],\n",
      "         [0.7958],\n",
      "         [0.8306],\n",
      "         [1.1585],\n",
      "         [0.9136],\n",
      "         [1.1191],\n",
      "         [1.1435],\n",
      "         [1.0864],\n",
      "         [0.8441],\n",
      "         [1.0440],\n",
      "         [1.0128],\n",
      "         [0.7384],\n",
      "         [0.9340],\n",
      "         [0.9143],\n",
      "         [1.0814],\n",
      "         [0.7939],\n",
      "         [0.7938],\n",
      "         [1.1021],\n",
      "         [1.0241],\n",
      "         [0.9270],\n",
      "         [1.1629],\n",
      "         [0.9419],\n",
      "         [0.8446],\n",
      "         [1.0691],\n",
      "         [1.0890],\n",
      "         [1.0373],\n",
      "         [1.0727],\n",
      "         [0.9448],\n",
      "         [0.8455],\n",
      "         [1.1332],\n",
      "         [0.9409],\n",
      "         [0.9541],\n",
      "         [0.9554],\n",
      "         [0.9583],\n",
      "         [0.8923],\n",
      "         [0.8900],\n",
      "         [1.0805],\n",
      "         [1.1150],\n",
      "         [0.8535],\n",
      "         [1.0458],\n",
      "         [1.0202],\n",
      "         [1.1195],\n",
      "         [0.9042],\n",
      "         [1.2552],\n",
      "         [1.0024],\n",
      "         [1.0300],\n",
      "         [0.8911],\n",
      "         [1.0208],\n",
      "         [0.9820],\n",
      "         [0.8899],\n",
      "         [1.0293],\n",
      "         [1.0300],\n",
      "         [0.7623],\n",
      "         [0.9912],\n",
      "         [0.9534],\n",
      "         [1.1005],\n",
      "         [1.0964],\n",
      "         [1.0255],\n",
      "         [0.9748],\n",
      "         [0.9100],\n",
      "         [1.0168],\n",
      "         [0.9766],\n",
      "         [1.0568],\n",
      "         [0.9962],\n",
      "         [0.7176],\n",
      "         [1.0068],\n",
      "         [0.8763],\n",
      "         [0.8604],\n",
      "         [0.9252],\n",
      "         [0.9072],\n",
      "         [0.9005],\n",
      "         [1.0615],\n",
      "         [1.1807],\n",
      "         [0.9188],\n",
      "         [0.8788],\n",
      "         [1.0130],\n",
      "         [0.9676],\n",
      "         [0.9376],\n",
      "         [1.1602],\n",
      "         [1.1455],\n",
      "         [0.9650],\n",
      "         [0.8126],\n",
      "         [0.9435],\n",
      "         [0.9760],\n",
      "         [0.9931],\n",
      "         [1.1112],\n",
      "         [1.0000],\n",
      "         [0.8936],\n",
      "         [1.1179],\n",
      "         [1.1079],\n",
      "         [1.0177],\n",
      "         [0.6988],\n",
      "         [0.7707],\n",
      "         [1.0339],\n",
      "         [0.8450],\n",
      "         [1.1057],\n",
      "         [1.0696],\n",
      "         [1.1017],\n",
      "         [0.9192],\n",
      "         [1.0833],\n",
      "         [0.9669],\n",
      "         [1.1423]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[[0.9836],\n",
      "         [0.8551],\n",
      "         [0.8832],\n",
      "         [1.0106],\n",
      "         [1.1481],\n",
      "         [1.1559],\n",
      "         [1.1086],\n",
      "         [0.8887],\n",
      "         [0.8412],\n",
      "         [1.0638],\n",
      "         [0.9541],\n",
      "         [0.9871],\n",
      "         [0.9765],\n",
      "         [0.8902],\n",
      "         [0.8530],\n",
      "         [1.0276],\n",
      "         [0.9711],\n",
      "         [0.7150],\n",
      "         [0.8577],\n",
      "         [1.0577],\n",
      "         [1.0228],\n",
      "         [1.0436],\n",
      "         [0.9499],\n",
      "         [0.9908],\n",
      "         [1.1552],\n",
      "         [0.9983],\n",
      "         [1.0770],\n",
      "         [0.9355],\n",
      "         [1.0440],\n",
      "         [1.1434],\n",
      "         [0.8133],\n",
      "         [0.9597],\n",
      "         [1.1469],\n",
      "         [1.0891],\n",
      "         [0.9932],\n",
      "         [0.8331],\n",
      "         [0.8809],\n",
      "         [0.9924],\n",
      "         [0.8907],\n",
      "         [0.9632],\n",
      "         [1.0673],\n",
      "         [1.0323],\n",
      "         [0.9366],\n",
      "         [0.9895],\n",
      "         [0.8559],\n",
      "         [1.0422],\n",
      "         [0.9334],\n",
      "         [0.8796],\n",
      "         [0.9325],\n",
      "         [0.9628],\n",
      "         [1.0276],\n",
      "         [1.0661],\n",
      "         [0.9970],\n",
      "         [1.0817],\n",
      "         [1.1484],\n",
      "         [0.7389],\n",
      "         [0.9715],\n",
      "         [0.9753],\n",
      "         [1.0462],\n",
      "         [0.8315],\n",
      "         [0.9972],\n",
      "         [0.9895],\n",
      "         [1.0334],\n",
      "         [0.8509],\n",
      "         [0.8598],\n",
      "         [0.9638],\n",
      "         [0.9911],\n",
      "         [1.1237],\n",
      "         [1.0897],\n",
      "         [1.1204],\n",
      "         [0.8712],\n",
      "         [1.0960],\n",
      "         [0.9602],\n",
      "         [1.1307],\n",
      "         [0.8047],\n",
      "         [0.9732],\n",
      "         [0.8543],\n",
      "         [1.2336],\n",
      "         [0.8580],\n",
      "         [1.1081],\n",
      "         [0.9842],\n",
      "         [1.1759],\n",
      "         [0.9187],\n",
      "         [0.9344],\n",
      "         [1.0219],\n",
      "         [0.8608],\n",
      "         [0.9438],\n",
      "         [0.9925],\n",
      "         [0.9397],\n",
      "         [0.9626],\n",
      "         [1.0680],\n",
      "         [0.9440],\n",
      "         [1.0963],\n",
      "         [1.1674],\n",
      "         [1.0100],\n",
      "         [1.0017],\n",
      "         [0.9367],\n",
      "         [0.9833],\n",
      "         [1.0477],\n",
      "         [1.0692],\n",
      "         [0.8490],\n",
      "         [0.9577],\n",
      "         [0.8112],\n",
      "         [1.0346],\n",
      "         [1.0815],\n",
      "         [0.9837],\n",
      "         [1.1367],\n",
      "         [0.8162],\n",
      "         [1.1079],\n",
      "         [0.8556],\n",
      "         [0.9838],\n",
      "         [0.8713],\n",
      "         [1.2001],\n",
      "         [0.9673],\n",
      "         [1.1059],\n",
      "         [0.9767],\n",
      "         [1.1331],\n",
      "         [0.8238],\n",
      "         [1.0332],\n",
      "         [1.0405],\n",
      "         [0.8271],\n",
      "         [1.0592],\n",
      "         [1.1607],\n",
      "         [0.8684],\n",
      "         [0.8270],\n",
      "         [0.9348],\n",
      "         [0.9653],\n",
      "         [0.8980]]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for smiles,label in data_loader:\n",
    "    # real\n",
    "    target = torch.FloatTensor([1.0]).view(1,1,1).repeat(1, smiles.shape[0] ,1).to(device)\n",
    "    label = label.float().to(device)\n",
    "    label = label.view(batch_size, 1, 1).repeat(1, smiles.shape[1], 1)\n",
    "    print(D.forward(smiles.to(device).float(), label))\n",
    "    \n",
    "    i += 1\n",
    "    if (i >= 4):\n",
    "        break\n",
    "    pass\n",
    "\n",
    "for i in range(4):\n",
    "    fake_input = []\n",
    "    fake_label = []\n",
    "    for finput, label in generate_random_seed(batch_size):\n",
    "        fake_input.append(finput)\n",
    "        fake_label.append(label)\n",
    "    \n",
    "    \n",
    "    fake_input = torch.FloatTensor(fake_input).to(device)\n",
    "    \n",
    "    #fake_input = fake_input.reshape(1, fake_input.shape[0], fake_input.shape[1])\n",
    "    fake_label = torch.FloatTensor(fake_label).to(device)\n",
    "    #print('2.before change label.shape', fake_input.shape, 'fake_label', fake_label.shape)\n",
    "    fake_label = fake_label.view(batch_size, 1, 1).repeat(1, fake_input.shape[1], 1)\n",
    "    #print('fake_input.shape', fake_input.shape, 'fake_label.shape', fake_label.shape)\n",
    "    target = torch.FloatTensor([0.0]).view(1,1,1).repeat(1, fake_input.shape[0] ,1).to(device)\n",
    "    D.forward(fake_input, fake_label)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result tensor(112361, device='cuda:0') idx 112361 fake_input torch.Size([100]) fake_label.shape torch.Size([100]) result.shape torch.Size([])\n",
      "CCC1NC(=N)NC1=O\n"
     ]
    }
   ],
   "source": [
    "fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "fake_label = torch.FloatTensor(generate_random_value(G_input_size)).to(device)\n",
    "result = G.forward(fake_input, fake_label).detach()\n",
    "idx = result.cpu().numpy()\n",
    "print('result', result, 'idx', idx, 'fake_input', fake_input.shape, 'fake_label.shape', fake_label.shape,  'result.shape', result.shape)\n",
    "        \n",
    "#idx = self.get_index(G.forward(fake_input, fake_label)).detach().cpu().numpy()\n",
    "print(data['smiles'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN1CC11C=CNC1=O\n",
      "CC1C2CC3CC1(O)C23\n",
      "C1C2COC3CC(C3)N12\n",
      "CC1C2CC3CC1(O)C23\n",
      "CC1OCC2CC=CC12\n",
      "COC=Nc1cocn1\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "C(CO)C#CC(=O)C#N\n",
      "C(CO)C#CC(=O)C#N\n",
      "CC1C2CC3CC1(O)C23\n",
      "CC1C2CC3CC1(O)C23\n",
      "Cc1c(onc1NC)C\n",
      "C(CO)C#CC(=O)C#N\n",
      "Cc1c(onc1NC)C\n",
      "CC1C2CC3CC1(O)C23\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "CC12C3CC1C1(CC1)N23\n",
      "CC12C3CC1C1(CC1)N23\n",
      "Cc1c(onc1NC)C\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "CC12C3CC1C1(CC1)N23\n",
      "Cc1c(onc1NC)C\n",
      "C(CO)C#CC(=O)C#N\n",
      "[O-]N=C(C#N)C1C[NH2+]C1\n",
      "CC12C3CC1C1(CC1)N23\n",
      "CC1C2CC3CC1(O)C23\n",
      "CC1C2CC3CC1(O)C23\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "Cc1c(onc1NC)C\n",
      "CCc1ccoc1OC\n",
      "CC1C2CC3CC1(O)C23\n",
      "CCC1CC2CC(=O)C12\n",
      "COCCC12CC(C1)C2\n",
      "C1C2COC3CC(C3)N12\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "CN=C1OC(C#N)C1N\n",
      "C(CO)C#CC(=O)C#N\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "CC1C2CC3CC1(O)C23\n",
      "COC=Nc1cocn1\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "C(CO)C#CC(=O)C#N\n",
      "Cc1c(onc1NC)C\n",
      "C(=N)Nc1[nH]nc(n1)N\n",
      "CC1C2CC3CC1(O)C23\n",
      "Cc1c(onc1NC)C\n",
      "Cc1c(onc1NC)C\n",
      "COC=Nc1cocn1\n",
      "C(CO)C#CC(=O)C#N\n",
      "C(CO)C#CC(=O)C#N\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "C(CO)C#CC(=O)C#N\n",
      "C(CO)C#CC(=O)C#N\n",
      "CC12C3CC1C1(CC1)N23\n",
      "N=C1NC(=CN=C1)C#N\n",
      "CC1=CC(=O)C2CC1C2\n",
      "Cc1c(onc1NC)C\n",
      "C(CO)C#CC(=O)C#N\n",
      "C(CO)C#CC(=O)C#N\n",
      "CC#CC(CO)(CO)O\n",
      "CC1C2CC3CC1(O)C23\n",
      "C(CO)C#CC(=O)C#N\n",
      "CC1OC2C1C2(O)CO\n",
      "CC12C3CC1C1(CC1)N23\n",
      "Cc1c(onc1NC)C\n",
      "CC1C2CC3CC1(O)C23\n",
      "CC1OC2C1C2(O)CO\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "Cc1c(onc1NC)C\n",
      "CC12C3CC1C1(CC1)N23\n",
      "NC(=O)CC1CC(=O)O1\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "CN=C1ON=NC(F)=C1\n",
      "CC1C2CC3CC1(O)C23\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "c1nc(=O)c(c(o1)F)F\n",
      "CC(CO)C1C2COC12\n",
      "CC12C3CC1C1(CC1)N23\n",
      "COC12CC1(C)NC2=N\n",
      "OC1(C=O)C2OC1C=C2\n",
      "CC(CO)C1C2COC12\n",
      "C1C2COC3CC(C3)N12\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "CC12C3CC1C1(CC1)N23\n",
      "Cc1c(onc1NC)C\n",
      "C(CO)C#CC(=O)C#N\n",
      "C1C2COC3CC(C3)N12\n",
      "CC1C(=N)OC11CC1\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "CCC(=O)CC(C)(C)O\n",
      "CC1C2CC3CC1(O)C23\n",
      "C(CO)C#CC(=O)C#N\n",
      "CNc1c(oc(=O)[nH]1)O\n",
      "CC1C2CC3CC1(O)C23\n",
      "CC1=N[N-]C(N)=[NH+]C1=N\n",
      "C1C2COC3CC(C3)N12\n",
      "CC12C3CC1C1(CC1)N23\n",
      "C(CO)C#CC(=O)C#N\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(G.get_smiles(5.1411))\n",
    "#CC1CC1,41.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COC1CCOCC=C1\n",
      "CC(=O)NCCC#N\n",
      "COC1CCOCC=C1\n",
      "CC1(C=O)C2CCCC12\n",
      "CC1CC1N1N=CC=N1\n",
      "COC1CCOCC=C1\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(C)CC1CC(=O)C1\n",
      "CC1(C=O)C2CCCC12\n",
      "CC1C2CC3C(N23)C1=O\n",
      "C#Cc1cnc(cn1)F\n",
      "COC1C2NC1C2O\n",
      "CC1CC1N=C(N)C=O\n",
      "OC12CNC1C=CC2=O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC(O)C(=O)C#CC=O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "O=CC1NC(=O)C1C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "CN1C2C3OC2(C#N)C13\n",
      "COC1CCOCC=C1\n",
      "CC1CC1N=C(N)C=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "COC1CC(=O)CC1O\n",
      "OC12CC(C1)C1OC21\n",
      "CC(=O)NCCC#N\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1C2CC=CC12O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "COC1CCOCC=C1\n",
      "COC1CCOCC=C1\n",
      "c1coc2c1CCC2=O\n",
      "O=C1CCOC(C1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(=O)NCCC#N\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CCC1=CC(CC1)C=O\n",
      "COC1CCOCC=C1\n",
      "Cc1cnc(nn1)C#C\n",
      "CC1OCC2CCC12O\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1COC(C)(O1)C#C\n",
      "CCC1(NC1C=O)C=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(O)C(=O)C#CC=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "O=C1CCOC(C1)C#C\n",
      "COC1CCOCC=C1\n",
      "CC1C2CN1C21CC1O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "C(=O)c1c([nH]nc1O)N\n",
      "CC1C2C(O)C2(O)C1O\n",
      "[O-]C(=O)C[NH2+]C1CCC1\n",
      "CC1OCC2CCC12O\n",
      "COC1CCOCC=C1\n",
      "O=CC1NC(=O)C1C#C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "OC1CCC1C1(O)CC1\n",
      "CC1CC1N=C(N)C=O\n",
      "COC1CCOCC=C1\n",
      "O=CC1C2OC=NC12\n",
      "CC#CC#CC(C)(C)O\n",
      "OC(C#N)C1COC=N1\n",
      "COC1CCOCC=C1\n",
      "O=C1CCOC(C1)C#C\n",
      "ON=C1C(O)COC1=N\n",
      "CC1C2CN1C21CC1O\n",
      "NC(=O)NC1CCC1O\n",
      "CC1(C=O)C2CCCC12\n",
      "OC(C#N)C1COC=N1\n",
      "CC1COC(C)(O1)C#C\n",
      "O=CC1NC(=O)C1C#C\n",
      "N#CCC1CC=CC1\n",
      "CC1COC(C)(O1)C#C\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1C2CN1C21CC1O\n",
      "CC1COC(C)(O1)C#C\n",
      "COC1CCOCC=C1\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1COC(C)(O1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "OC12CNC1C=CC2=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2CC3C(N23)C1=O\n",
      "C#Cc1cnc(cn1)F\n",
      "CC1C2C(O)C2(O)C1O\n",
      "C#Cc1cnc(cn1)F\n",
      "COC1CCOCC=C1\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(G.get_smiles(1.9354))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OC12CC(C1)C1OC21\n",
      "CC1C2NC2C1C#C\n",
      "CC(=O)C(CO)CO\n",
      "CNC(CN)C#N\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CCOCC1=CCOC1\n",
      "N#CC1C=CC2CN12\n",
      "COC1CCOCC=C1\n",
      "CC1COC(C)(O1)C#C\n",
      "CC(=O)NCCC#N\n",
      "CC1C2C(O)C2(O)C1O\n",
      "COC1CCOCC=C1\n",
      "CC1=CN(CC1=NO)C\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "COC=NC1CCC1C\n",
      "CC1CC1N=C(N)C=O\n",
      "COC1CCOCC=C1\n",
      "CC1(C=O)C2CCCC12\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1C2C(O)C2(O)C1O\n",
      "COC1CCOCC=C1\n",
      "CC1CC1N=C(N)C=O\n",
      "O=C1CCOC(C1)C#C\n",
      "OC12CNC1C=CC2=O\n",
      "CC1C2C(O)C2(O)C1O\n",
      "N=C1OC2CC(C2)C1=O\n",
      "CC1CC1N=C(N)C=O\n",
      "Cc1cnc(nn1)C#C\n",
      "OC1CCC1C1(O)CC1\n",
      "O=C1CCOC(C1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "OC1C(C=O)C11COC1\n",
      "CNC(=N)C(=O)CC#C\n",
      "C#Cc1cnc(cn1)F\n",
      "COC1CCOCC=C1\n",
      "CCN1CC1CC(N)=O\n",
      "[NH3+]C(CC#C)C([O-])=O\n",
      "CC1CC1N=C(N)C=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CCN1CC1CC(N)=O\n",
      "COC1CCOCC=C1\n",
      "C1C2C1C13CC4C1C2C34\n",
      "CCC1(NC1C=O)C=O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "OC1CC2OC=NC12\n",
      "CC1C2C(O)C2(O)C1O\n",
      "COC1CCOCC=C1\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC1COC(C)(O1)C#C\n",
      "CCC(C=O)C#CCO\n",
      "CC1=NCC2CC2CO1\n",
      "[NH3+]C(CC#C)C([O-])=O\n",
      "NC1=NC(COC1)C=O\n",
      "O=CC1NC(=O)C1C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "COC1CCOCC=C1\n",
      "CC1COC(C)(O1)C#C\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CNC(=N)C(=O)CC#C\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "COC1CCOCC=C1\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1CC1N=C(N)C=O\n",
      "COC1CC(=O)CC1O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1(C)C2CCC=CC12\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC1C2C(O)C2(O)C1O\n",
      "Cc1c(ocn1)N(=O)=O\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC1CC1N=C(N)C=O\n",
      "OC(C#N)C1COC=N1\n",
      "COC1CCOCC=C1\n",
      "CC1C2CC3C(N23)C1=O\n",
      "OCC1NC2C1OC2=N\n",
      "C1CC11OCCC11CN1\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "COC1CC(=O)CC1O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "O=C1CCOC(C1)C#C\n",
      "C1C2C1C13CC4C1C2C34\n",
      "C#Cc1cnc(cn1)F\n",
      "COC1CCOCC=C1\n",
      "OC12CNC1C=CC2=O\n",
      "CCC(=O)NC(=N)CO\n",
      "COC1CCOCC=C1\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC(C)CC1CC(=O)C1\n",
      "CC(=O)C(CO)CO\n",
      "COC1CCOCC=C1\n",
      "CC1C2C(O)C2(O)C1O\n",
      "COC1CCOCC=C1\n",
      "CC1C2C(O)C2(O)C1O\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(G.get_smiles(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC1(C)C2N3CC3C12O\n",
      "CNC(=N)C(=O)CC#C\n",
      "CC1(C=O)C2CCCC12\n",
      "O=C1CCOC(C1)C#C\n",
      "OC12CC(C1)OCOC2\n",
      "CC1(C=O)C2CCCC12\n",
      "CCC12OC1C(C)C2C\n",
      "COC1CCOCC=C1\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1C2CC3C(N23)C1=O\n",
      "C#Cc1cnc(cn1)F\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(=O)NCCC#N\n",
      "O=C1CCOC(C1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(=O)NCCC#N\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC(=O)NCCC#N\n",
      "O=C1CCOC(C1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "COC(=O)CC1NC1C\n",
      "CC1COC(C)(O1)C#C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "COC1CCOCC=C1\n",
      "O=C1CCOC(C1)C#C\n",
      "COC1CCOCC=C1\n",
      "CCOC=NCCC#N\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CNC(=N)C(=O)CC#C\n",
      "O=C1CCOC(C1)C#C\n",
      "CN1C2C3OC2(C#N)C13\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1COC(C)(O1)C#C\n",
      "COC1CCOCC=C1\n",
      "O=C1CCOC(C1)C#C\n",
      "COC1CCOCC=C1\n",
      "CC1CC1N=C(N)C=O\n",
      "c1cnc(cc1N)O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "O=C1CCOC(C1)C#C\n",
      "O=CC1NC(=O)C1C#C\n",
      "CC(=O)C(CO)CO\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "O=CC1NC(=O)C1C#C\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "O=C1CCOC(C1)C#C\n",
      "OC12CNC1C=CC2=O\n",
      "CC1CCC(=O)C=C1\n",
      "O=C1CCOC(C1)C#C\n",
      "CNC(=N)C(=O)CC#C\n",
      "CC(=O)NCCC#N\n",
      "NC(=O)NC1CCC1O\n",
      "OC1CC(O)C(C1)C=O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1OCC2CCC12O\n",
      "C1OC2COCC2=C1\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CN1C2C3OC2(C#N)C13\n",
      "CC1COC(C)(O1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "COC1CCOCC=C1\n",
      "CC1(C=O)C2CCCC12\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1(C=O)C2CCCC12\n",
      "OC12C3CC(C13)C21CO1\n",
      "CC1(C=O)C2CCCC12\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC1CC1N=C(N)C=O\n",
      "CC(=O)NCCC#N\n",
      "COC1CC(=O)CC1O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC(=O)NCCC#N\n",
      "COC1CNC11COC1\n",
      "N#CC1(CCO1)C1CO1\n",
      "O=C1CCOC(C1)C#C\n",
      "CCC1(NC1C=O)C=O\n",
      "CC1OCC2CCC12O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC(=O)NCCC#N\n",
      "CC1OCC2CCC12O\n",
      "CC1COC(C)(O1)C#C\n",
      "OC(C#N)C1COC=N1\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "OC12CNC1C=CC2=O\n",
      "CN=c1oc(no1)C#C\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC1(C=O)C2CCCC12\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC1OCC2CCC12O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CCC12CC3C(C1O)N23\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2C(O)C2(O)C1O\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(G.get_smiles(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model to file: pre_train_model/GAN13G202104121727.sav\n",
      "save model to file: pre_train_model/GAN13G202104121727.sav\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now() \n",
    "date_time = now.strftime(\"%Y%m%d%H%M\")\n",
    "G_filename = 'pre_train_model/GAN13G' + date_time + '.sav'\n",
    "print('save model to file:', G_filename)\n",
    "pickle.dump(G, open(G_filename, 'wb'))\n",
    "\n",
    "D_filename = 'pre_train_model/GAN13D' + date_time + '.sav'\n",
    "print('save model to file:', G_filename)\n",
    "pickle.dump(D, open(D_filename, 'wb'))\n",
    "\n",
    "\n",
    "#G_model = pickle.load(open(G_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
