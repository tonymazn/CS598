{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import PandasTools, AllChem\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import pandas, numpy, random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif torch.cuda.is_available():\\n    torch.set_default_tensor_type(torch.cuda.FloatTensor)\\n    print(\"using cuda:\", torch.cuda.get_device_name(0))\\n    pass\\n\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\ndevice\\n\\nfrom multiprocessing import set_start_method\\ntry:\\n    set_start_method(\\'spawn\\')\\nexcept RuntimeError:\\n    pass\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if CUDA is available, use GPU and set default tensor type to cuda\n",
    "\n",
    "'''\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    print(\"using cuda:\", torch.cuda.get_device_name(0))\n",
    "    pass\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "from multiprocessing import set_start_method\n",
    "try:\n",
    "    set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "    pass\n",
    "'''    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMILESMolDataset(Dataset):\n",
    "    def __init__(self, molecules, y, vectorizer):\n",
    "        self.molecules = molecules\n",
    "        self.y = y\n",
    "        self.vectorizer = vectorizer\n",
    "    def __len__(self):\n",
    "        return len(self.molecules)\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "             \n",
    "        mols = self.molecules[idx]\n",
    "         \n",
    "        #The vectorizer was written to work with batches, \n",
    "        #but PyTorch datasets unfortunately works with single samples\n",
    "        sample = self.vectorizer.transform([mols])[0]\n",
    "        index = int(self.y[idx])\n",
    "        if (index > max_label_dim):\n",
    "            print(\"dataload index\", index)\n",
    "        \n",
    "        label = torch.zeros((max_label_dim))\n",
    "        label[index] = 1.0\n",
    "        \n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_data 133885 max_mu 29.5564 min_mu 0.0\n",
      "0         0.0000\n",
      "1         1.6256\n",
      "2         1.8511\n",
      "3         0.0000\n",
      "4         2.8937\n",
      "           ...  \n",
      "133880    1.6637\n",
      "133881    1.2976\n",
      "133882    1.2480\n",
      "133883    1.9576\n",
      "133884    0.8626\n",
      "Name: mu, Length: 133885, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "real_data = pandas.read_csv('dataset/qm9.csv')\n",
    "max_mu = max(real_data['mu'])\n",
    "min_mu = min(real_data['mu'])\n",
    "number_of_data = len(real_data)\n",
    "\n",
    "print(\"number_of_data\", number_of_data, \"max_mu\", max_mu, \"min_mu\", min_mu)\n",
    "#real_data.head(5)\n",
    "\n",
    "\n",
    "print(real_data['mu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>mu</th>\n",
       "      <th>alpha</th>\n",
       "      <th>homo</th>\n",
       "      <th>lumo</th>\n",
       "      <th>gap</th>\n",
       "      <th>r2</th>\n",
       "      <th>zpve</th>\n",
       "      <th>cv</th>\n",
       "      <th>u0</th>\n",
       "      <th>u298</th>\n",
       "      <th>h298</th>\n",
       "      <th>g298</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.21</td>\n",
       "      <td>-0.3877</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>35.3641</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>6.469</td>\n",
       "      <td>-40.478930</td>\n",
       "      <td>-40.476062</td>\n",
       "      <td>-40.475117</td>\n",
       "      <td>-40.498597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>1.6256</td>\n",
       "      <td>9.46</td>\n",
       "      <td>-0.2570</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>26.1563</td>\n",
       "      <td>0.034358</td>\n",
       "      <td>6.316</td>\n",
       "      <td>-56.525887</td>\n",
       "      <td>-56.523026</td>\n",
       "      <td>-56.522082</td>\n",
       "      <td>-56.544961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>1.8511</td>\n",
       "      <td>6.31</td>\n",
       "      <td>-0.2928</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.3615</td>\n",
       "      <td>19.0002</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>6.002</td>\n",
       "      <td>-76.404702</td>\n",
       "      <td>-76.401867</td>\n",
       "      <td>-76.400922</td>\n",
       "      <td>-76.422349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C#C</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.28</td>\n",
       "      <td>-0.2845</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>59.5248</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>8.574</td>\n",
       "      <td>-77.308427</td>\n",
       "      <td>-77.305527</td>\n",
       "      <td>-77.304583</td>\n",
       "      <td>-77.327429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C#N</td>\n",
       "      <td>2.8937</td>\n",
       "      <td>12.99</td>\n",
       "      <td>-0.3604</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>48.7476</td>\n",
       "      <td>0.016601</td>\n",
       "      <td>6.278</td>\n",
       "      <td>-93.411888</td>\n",
       "      <td>-93.409370</td>\n",
       "      <td>-93.408425</td>\n",
       "      <td>-93.431246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  smiles      mu  alpha    homo    lumo     gap       r2      zpve     cv  \\\n",
       "0      C  0.0000  13.21 -0.3877  0.1171  0.5048  35.3641  0.044749  6.469   \n",
       "1      N  1.6256   9.46 -0.2570  0.0829  0.3399  26.1563  0.034358  6.316   \n",
       "2      O  1.8511   6.31 -0.2928  0.0687  0.3615  19.0002  0.021375  6.002   \n",
       "3    C#C  0.0000  16.28 -0.2845  0.0506  0.3351  59.5248  0.026841  8.574   \n",
       "4    C#N  2.8937  12.99 -0.3604  0.0191  0.3796  48.7476  0.016601  6.278   \n",
       "\n",
       "          u0       u298       h298       g298  \n",
       "0 -40.478930 -40.476062 -40.475117 -40.498597  \n",
       "1 -56.525887 -56.523026 -56.522082 -56.544961  \n",
       "2 -76.404702 -76.401867 -76.400922 -76.422349  \n",
       "3 -77.308427 -77.305527 -77.304583 -77.327429  \n",
       "4 -93.411888 -93.409370 -93.408425 -93.431246  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv('dataset/qm9.csv')\n",
    "#pandas.read_csv('dataset/GDB13_Subset-ABCDEFGH.smi', header=None, names=[\"smiles\"])\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>Molecule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  smiles                                           Molecule\n",
       "0      C  <img data-content=\"rdkit/molecule\" src=\"data:i..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PandasTools.AddMoleculeColumnToFrame(data,'smiles','Molecule')\n",
    "data = data[0:number_of_data]\n",
    "data[[\"smiles\",\"Molecule\"]].head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC=O'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['smiles'].iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>mu</th>\n",
       "      <th>alpha</th>\n",
       "      <th>homo</th>\n",
       "      <th>lumo</th>\n",
       "      <th>gap</th>\n",
       "      <th>r2</th>\n",
       "      <th>zpve</th>\n",
       "      <th>cv</th>\n",
       "      <th>u0</th>\n",
       "      <th>u298</th>\n",
       "      <th>h298</th>\n",
       "      <th>g298</th>\n",
       "      <th>Molecule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.21</td>\n",
       "      <td>-0.3877</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>35.3641</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>6.469</td>\n",
       "      <td>-40.47893</td>\n",
       "      <td>-40.476062</td>\n",
       "      <td>-40.475117</td>\n",
       "      <td>-40.498597</td>\n",
       "      <td><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  smiles   mu  alpha    homo    lumo     gap       r2      zpve     cv  \\\n",
       "0      C  0.0  13.21 -0.3877  0.1171  0.5048  35.3641  0.044749  6.469   \n",
       "\n",
       "         u0       u298       h298       g298  \\\n",
       "0 -40.47893 -40.476062 -40.475117 -40.498597   \n",
       "\n",
       "                                            Molecule  \n",
       "0  <img data-content=\"rdkit/molecule\" src=\"data:i...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data1 = real_data\n",
    "PandasTools.AddMoleculeColumnToFrame(real_data1,'smiles','Molecule')\n",
    "real_data1[[\"smiles\",\"Molecule\"]].head(1)\n",
    "real_data['Molecule'] = real_data1[['Molecule']]\n",
    "real_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from molvecgen.vectorizers import SmilesVectorizer\n",
    "\n",
    "smivec = SmilesVectorizer(pad=1, leftpad=True, canonical=False, augment=True)\n",
    "smivec.fit(real_data.Molecule.values, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smivec_data = SmilesVectorizer(pad=1, leftpad=True, canonical=False, augment=True)\n",
    "smivec_data.fit(data.Molecule.values, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([12.5100,  9.8900, 20.9200,  6.1600, 20.1300])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# functions to generate random data\n",
    "\n",
    "def generate_random_seed_G(size):\n",
    "    random_data = torch.randn(size)\n",
    "    return random_data\n",
    "\n",
    "\n",
    "def generate_random_value(size):\n",
    "    random_data = np.round(np.random.randint(int(min_mu), int(max_mu * 100), (1, size))/100,4)\n",
    "    random_data = torch.FloatTensor(random_data)\n",
    "    #random_data = torch.round((torch.randn(size) * 10000) / 100)\n",
    "    #round(random.uniform(min_alpha, max_alpha),2)\n",
    "    return random_data.view(-1)\n",
    "\n",
    "def generate_random_one_hot(size):\n",
    "    label_tensor = torch.zeros((size))\n",
    "    random_idx = random.randint(0,size-1)\n",
    "    label_tensor[random_idx] = 1.0\n",
    "    return label_tensor\n",
    "\n",
    "print(generate_random_one_hot(29))\n",
    "generate_random_value(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_train) 133885 y_train[1] 9.46\n"
     ]
    }
   ],
   "source": [
    "y = real_data.mu.values.reshape((-1,1))\n",
    "X = real_data.Molecule.values\n",
    "\n",
    "#Normalizing output using standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = X\n",
    "y_train = real_data['alpha']\n",
    "#scaler.fit_transform(y)\n",
    "\n",
    "print('len(X_train)',len(X_train),'y_train[1]', y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dataset[10] (array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0]], dtype=int8), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])) data_y tensor([0.7500])\n"
     ]
    }
   ],
   "source": [
    "data_y = generate_random_value(number_of_data).reshape((-1,1))\n",
    "data_X = data.Molecule.values\n",
    "scaler = StandardScaler()\n",
    "#data_y = scaler.fit_transform(data_y)\n",
    "data_dataset = SMILESMolDataset(data_X, data_y, smivec_data)\n",
    "print('data_dataset[10]', data_dataset[10], 'data_y', data_y[10] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset[10] (array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0]], dtype=int8), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])) len(train_dataset[10][0]) 35\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SMILESMolDataset(X_train, y_train, smivec)\n",
    "train_dataset[10]\n",
    "print('train_dataset[10]', train_dataset[10], 'len(train_dataset[10][0])', len(train_dataset[10][0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a random SMILES from the GDB13_Subset\n",
    "def generate_random_seed(size):\n",
    "    index_list = np.random.randint(1, number_of_data, (1, size))[0]\n",
    "    random_data = []\n",
    "    for i in index_list:\n",
    "          random_data.append( data_dataset[i] )\n",
    "    #random_data = data_dataset[10]\n",
    "    return random_data\n",
    "\n",
    "generate_random_seed(2)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "dims = smivec.dims\n",
    "lstm_size = 128  # The size of the LSTM layer\n",
    "hidden_size = 128  # The size of the hidden non-linear layer\n",
    "dropout_rate = 0.50 # The dropout rate\n",
    "out_size = 1        # This is just a single task, so this will be one\n",
    "batch_size = 128   # The mini_batch size during training\n",
    "#batch_size = 1   # The mini_batch size during training\n",
    "G_input_size = 100 # The Generator input data size\n",
    "learning_rate_D = 0.003  # The Discriminator initial learning rate for the optimizer \n",
    "learning_rate_G = 0.001  # The Generator initial learning rate for the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator class\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # initialise parent pytorch class\n",
    "        super().__init__()\n",
    "        \n",
    "        length = dims[0] \n",
    "        number_tokens = dims[1] + 1  # add the label layer\n",
    "        #print('LSTM input_size', number_tokens)\n",
    "         \n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=number_tokens, hidden_size=lstm_size, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        self.fc1 = nn.Linear(lstm_size, hidden_size) # Output layer\n",
    "        self.activation = nn.ReLU() # Non-Linear ReLU Layer       \n",
    "        self.fc_out = nn.Linear(hidden_size, out_size) # Output layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)       \n",
    "        \n",
    "        # create loss function\n",
    "        self.loss_function = nn.MSELoss()\n",
    "\n",
    "        # create optimiser, simple stochastic gradient descent\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=learning_rate_D)\n",
    "        #self.lr_scheduler = ReduceLROnPlateau(self.optimiser, mode='min', factor=0.5, patience=50, \n",
    "        #          verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=1e-6, eps=1e-08)\n",
    "\n",
    "        # counter and accumulator for progress\n",
    "        self.counter = 0;\n",
    "        self.progress = []\n",
    "\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def forward(self, input_tensor, label_tensor):\n",
    "        # combine seed and label\n",
    "        \n",
    "        print(\"input_tensor.shape\", input_tensor.shape, \"label_tensor.shape\", label_tensor.shape)\n",
    "        x = torch.cat((input_tensor, label_tensor), -1)\n",
    "        print('after torch.cat', x.shape)\n",
    "        \n",
    "        \n",
    "        out, (h_n, c_n) = self.lstm(x) #LSTM network reads in one-hot-encoded SMILES, h_n is last output, out is for all timesteps\n",
    "        out = self.dropout(h_n) #Dropout\n",
    "        out = self.fc1(out) # Pass into the hidden layer\n",
    "        out = self.activation(out) # Use ReLU on hidden activation\n",
    "        out = self.dropout(out) # dropout\n",
    "        out = self.fc_out(out) # Use a linear layer for the output\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def train(self, inputs, label_tensor, targets):\n",
    "        # calculate the output of the network Discriminator\n",
    "        outputs = self.forward(inputs, label_tensor)\n",
    "        \n",
    "        \n",
    "        #print('outputs', outputs)\n",
    "        #print('targets', targets)\n",
    "        # calculate loss\n",
    "        #outputs = outputs.view(-1)\n",
    "        #targets = targets.view(-1)\n",
    "        #print('outputs.shape', outputs.shape, 'targets.shape',targets.shape)\n",
    "        \n",
    "        if (outputs.shape != targets.shape):\n",
    "            print(\"Generator loss function issue: outputs.shape != targets.shape\", outputs.shape, targets.shape)\n",
    "\n",
    "        loss = self.loss_function(outputs, targets)\n",
    "\n",
    "        # increase counter and accumulate error every 10\n",
    "        self.counter += 1;\n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss.item())\n",
    "            pass\n",
    "        if (self.counter % 1000 == 0):\n",
    "            print(\"counter = \", self.counter)\n",
    "            pass\n",
    "\n",
    "        # zero gradients, perform a backward pass, update weights\n",
    "        self.optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimiser.step()\n",
    "\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def plot_progress(self):\n",
    "        df = pandas.DataFrame(self.progress, columns=['loss'])\n",
    "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "data_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True, num_workers=4,drop_last=True )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.before change, label.shape torch.Size([128, 100]) smiles torch.Size([128, 35, 24])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[128, 1, 1]' is invalid for input of size 12800",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[128, 1, 1]' is invalid for input of size 12800"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test discriminator can separate real data from random noise\n",
    "\n",
    "\n",
    "D = Discriminator()\n",
    "D.to(device)\n",
    "\n",
    "for smiles,label in data_loader:\n",
    "    # real\n",
    "    target = torch.FloatTensor([1.0]).view(1,1,1).repeat(1, smiles.shape[0] ,1).to(device)\n",
    "    print('0.before change, label.shape', label.shape, 'smiles', smiles.shape)\n",
    "    label = label.float().to(device)\n",
    "    label = label.view(batch_size, 1, 1).repeat(1, smiles.shape[1], 1)\n",
    "    #print('1.before change label.shape', label.shape, 'smiles', smiles.shape)\n",
    "    D.train(smiles.to(device).float(), label, target)\n",
    "    \n",
    "    '''\n",
    "    # fake\n",
    "    fake_input = []\n",
    "    fake_label = []\n",
    "    for finput, label in generate_random_seed(batch_size):\n",
    "        fake_input.append(finput)\n",
    "        fake_label.append(label)\n",
    "    \n",
    "    \n",
    "    fake_input = torch.FloatTensor(fake_input).to(device)\n",
    "    \n",
    "    #fake_input = fake_input.reshape(1, fake_input.shape[0], fake_input.shape[1])\n",
    "    fake_label = torch.FloatTensor(fake_label).to(device)\n",
    "    #print('2.before change label.shape', fake_input.shape, 'fake_label', fake_label.shape)\n",
    "    fake_label = fake_label.view(batch_size, 1, 1).repeat(1, fake_input.shape[1], 1)\n",
    "    #fake_label.unsqueeze(1).repeat(1, fake_input.shape[1], 1)\n",
    "    #print('fake_input.shape', fake_input.shape, 'fake_label.shape', fake_label.shape)\n",
    "    target = torch.FloatTensor([0.0]).view(1,1,1).repeat(1, fake_input.shape[0] ,1).to(device)\n",
    "    D.train(fake_input, fake_label, target)\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1c3e52c80cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-314136b4cf8a>\u001b[0m in \u001b[0;36mplot_progress\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplot_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/__init__.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ax\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left_ax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# no non-numeric frames or series allowed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no numeric data to plot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# GH25587: cast ExtensionArray of pandas (IntegerArray, etc.) to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataload index 55\n",
      "dataload index 61\n",
      "dataload index 80\n",
      "dataload index 72\n",
      "dataload index 82\n",
      "dataload index 71\n",
      "dataload index 77\n",
      "dataload index 73\n",
      "dataload index 76\n",
      "dataload index 74\n",
      "dataload index 63\n",
      "dataload index 82\n",
      "dataload index 75\n",
      "dataload index 76\n",
      "dataload index 78\n",
      "dataload index 74\n",
      "dataload index 71\n",
      "dataload index 74\n",
      "dataload index 79\n",
      "dataload index 71\n",
      "dataload index 76\n",
      "dataload index 64\n",
      "dataload index 81\n",
      "dataload index 65\n",
      "dataload index 82\n",
      "dataload index 72\n",
      "dataload index 74\n",
      "dataload index 75\n",
      "dataload index 75\n",
      "dataload index 68\n",
      "dataload index 62\n",
      "dataload index 69\n",
      "dataload index 65\n",
      "dataload index 80\n",
      "dataload index 73\n",
      "dataload index 77\n",
      "dataload index 66\n",
      "dataload index 63\n",
      "dataload index 63\n",
      "dataload index 49\n",
      "dataload index 75\n",
      "dataload index 83\n",
      "dataload index 69\n",
      "dataload index 84\n",
      "dataload index 74\n",
      "dataload index 84\n",
      "dataload index 71\n",
      "dataload index 84\n",
      "dataload index 85\n",
      "dataload index 70\n",
      "dataload index 84\n",
      "dataload index 87\n",
      "dataload index 66\n",
      "dataload index 96\n",
      "dataload index 68\n",
      "dataload index 79\n",
      "dataload index 98\n",
      "dataload index 74\n",
      "dataload index 78\n",
      "dataload index 79\n",
      "dataload index 79\n",
      "dataload index 60\n",
      "dataload index 76\n",
      "dataload index 75\n",
      "dataload index 91\n",
      "dataload index 80\n",
      "dataload index 79\n",
      "dataload index 64\n",
      "dataload index 73\n",
      "dataload index 71\n",
      "dataload index 84\n",
      "dataload index 77\n",
      "dataload index 82\n",
      "dataload index 69\n",
      "dataload index 57\n",
      "dataload index 79\n",
      "dataload index 86\n",
      "dataload index 83\n",
      "dataload index 80\n",
      "dataload index 70\n",
      "dataload index 85\n",
      "dataload index 61\n",
      "dataload index 71\n",
      "dataload index 70\n",
      "dataload index 75\n",
      "dataload index 72\n",
      "dataload index 78\n",
      "dataload index 79\n",
      "dataload index 84\n",
      "dataload index 66\n",
      "dataload index 60\n",
      "dataload index 61\n",
      "dataload index 59\n",
      "dataload index 82\n",
      "dataload index 80\n",
      "dataload index 93\n",
      "dataload index 68\n",
      "dataload index 83\n",
      "dataload index 76\n",
      "dataload index 79\n",
      "dataload index 67\n",
      "dataload index 79\n",
      "dataload index 68\n",
      "dataload index 66\n",
      "dataload index 72\n",
      "dataload index 78\n",
      "dataload index 77\n",
      "dataload index 74\n",
      "dataload index 79\n",
      "dataload index 75\n",
      "dataload index 75\n",
      "dataload index 78\n",
      "dataload index 78\n",
      "dataload index 81\n",
      "dataload index 80\n",
      "dataload index 80\n",
      "dataload index 72\n",
      "dataload index 68\n",
      "dataload index 86\n",
      "dataload index 64\n",
      "dataload index 65\n",
      "dataload index 72\n",
      "dataload index 79\n",
      "dataload index 67\n",
      "dataload index 77\n",
      "dataload index 72\n",
      "dataload index 84\n",
      "dataload index 79\n",
      "dataload index 71\n",
      "dataload index 69\n",
      "dataload index 85\n",
      "dataload index 73\n",
      "dataload index 86\n",
      "dataload index 72\n",
      "dataload index 68\n",
      "dataload index 72\n",
      "dataload index 76\n",
      "dataload index 81\n",
      "dataload index 78\n",
      "dataload index 79\n",
      "dataload index 83\n",
      "dataload index 65\n",
      "dataload index 86\n",
      "dataload index 76\n",
      "dataload index 59\n",
      "dataload index 71\n",
      "dataload index 76\n",
      "dataload index 74\n",
      "dataload index 76\n",
      "dataload index 71\n",
      "dataload index 89\n",
      "dataload index 66\n",
      "dataload index 71\n",
      "dataload index 81\n",
      "dataload index 78\n",
      "dataload index 62\n",
      "dataload index 89\n",
      "dataload index 68\n",
      "dataload index 79\n",
      "dataload index 89\n",
      "dataload index 74\n",
      "dataload index 70\n",
      "dataload index 78\n",
      "dataload index 69\n",
      "dataload index 72\n",
      "dataload index 76\n",
      "dataload index 68\n",
      "dataload index 66\n",
      "dataload index 67\n",
      "dataload index 64\n",
      "dataload index 76\n",
      "dataload index 67\n",
      "dataload index 79\n",
      "dataload index 76\n",
      "dataload index 78\n",
      "dataload index 82\n",
      "dataload index 81\n",
      "dataload index 70\n",
      "dataload index 84\n",
      "dataload index 67\n",
      "dataload index 74\n",
      "dataload index 75\n",
      "dataload index 77\n",
      "dataload index 74\n",
      "dataload index 69\n",
      "dataload index 78\n",
      "dataload index 73\n",
      "dataload index 85\n",
      "dataload index 63\n",
      "dataload index 78\n",
      "dataload index 65\n",
      "dataload index 86\n",
      "dataload index 75\n",
      "dataload index 79\n",
      "dataload index 71\n",
      "dataload index 73\n",
      "dataload index 71\n",
      "dataload index 83\n",
      "dataload index 68\n",
      "dataload index 74\n",
      "dataload index 68\n",
      "dataload index 97\n",
      "dataload index 71\n",
      "dataload index 74\n",
      "dataload index 81\n",
      "dataload index 71\n",
      "dataload index 68\n",
      "dataload index 75\n",
      "dataload index 83\n",
      "dataload index 50\n",
      "dataload index 66\n",
      "dataload index 87\n",
      "dataload index 55\n",
      "dataload index 81\n",
      "dataload index 66\n",
      "dataload index 87\n",
      "dataload index 82\n",
      "dataload index 76\n",
      "dataload index 81\n",
      "dataload index 51\n",
      "dataload index 76\n",
      "dataload index 82\n",
      "dataload index 78\n",
      "dataload index 72\n",
      "dataload index 57\n",
      "dataload index 85\n",
      "dataload index 83\n",
      "dataload index 71\n",
      "dataload index 84\n",
      "dataload index 72\n",
      "dataload index 83\n",
      "dataload index 84\n",
      "dataload index 84\n",
      "dataload index 60\n",
      "dataload index 76\n",
      "dataload index 72\n",
      "dataload index 62\n",
      "dataload index 71\n",
      "dataload index 68\n",
      "dataload index 70\n",
      "dataload index 73\n",
      "dataload index 75\n",
      "dataload index 72\n",
      "dataload index 78\n",
      "dataload index 54\n",
      "dataload index 70\n",
      "dataload index 85\n",
      "dataload index 64\n",
      "dataload index 65\n",
      "dataload index 79\n",
      "dataload index 70\n",
      "dataload index 83\n",
      "dataload index 64\n",
      "dataload index 64\n",
      "dataload index 79\n",
      "dataload index 80\n",
      "dataload index 72\n",
      "dataload index 59\n",
      "dataload index 90\n",
      "dataload index 77\n",
      "dataload index 75\n",
      "dataload index 81\n",
      "dataload index 77\n",
      "dataload index 68\n",
      "dataload index 74\n",
      "dataload index 74\n",
      "dataload index 52\n",
      "dataload index 76\n",
      "dataload index 79\n",
      "dataload index 72\n",
      "dataload index 77\n",
      "dataload index 80\n",
      "dataload index 37\n",
      "dataload index 87\n",
      "dataload index 72\n",
      "dataload index 79\n",
      "dataload index 81\n",
      "dataload index 67\n",
      "dataload index 80\n",
      "dataload index 84\n",
      "dataload index 82\n",
      "dataload index 73\n",
      "dataload index 83\n",
      "dataload index 71\n",
      "dataload index 76\n",
      "dataload index 75\n",
      "dataload index 77\n",
      "dataload index 82\n",
      "dataload index 80\n",
      "dataload index 80\n",
      "dataload index 93\n",
      "dataload index 67\n",
      "dataload index 71\n",
      "dataload index 80\n",
      "dataload index 78\n",
      "dataload index 80\n",
      "dataload index 78\n",
      "dataload index 72\n",
      "dataload index 57\n",
      "dataload index 74\n",
      "dataload index 55\n",
      "dataload index 76\n",
      "dataload index 64\n",
      "dataload index 79\n",
      "dataload index 71\n",
      "dataload index 77\n",
      "dataload index 60\n",
      "dataload index 79\n",
      "dataload index 71\n",
      "dataload index 70\n",
      "dataload index 83\n",
      "dataload index 76\n",
      "dataload index 84\n",
      "dataload index 79\n",
      "dataload index 72\n",
      "dataload index 75\n",
      "dataload index 74\n",
      "dataload index 71\n",
      "dataload index 62\n",
      "dataload index 75\n",
      "dataload index 77\n",
      "dataload index 59\n",
      "dataload index 75\n",
      "dataload index 73\n",
      "dataload index 75\n",
      "dataload index 76\n",
      "dataload index 59\n",
      "dataload index 79\n",
      "dataload index 74\n",
      "dataload index 89\n",
      "dataload index 88\n",
      "dataload index 73\n",
      "dataload index 75\n",
      "dataload index 63\n",
      "dataload index 89\n",
      "dataload index 89\n",
      "dataload index 70\n",
      "dataload index 85\n",
      "dataload index 75\n",
      "dataload index 71\n",
      "dataload index 75\n",
      "dataload index 75\n",
      "dataload index 57\n",
      "dataload index 84\n",
      "dataload index 78\n",
      "dataload index 68\n",
      "dataload index 72\n",
      "dataload index 70\n",
      "dataload index 82\n",
      "dataload index 77\n",
      "dataload index 72\n",
      "dataload index 82\n",
      "dataload index 61\n",
      "dataload index 78\n",
      "dataload index 82\n",
      "dataload index 74\n",
      "dataload index 81\n",
      "dataload index 75\n",
      "dataload index 78\n",
      "dataload index 67\n",
      "dataload index 74\n",
      "dataload index 67\n",
      "dataload index 76\n",
      "dataload index 87\n",
      "dataload index 80\n",
      "dataload index 83\n",
      "dataload index 79\n",
      "dataload index 59\n",
      "dataload index 71\n",
      "dataload index 82\n",
      "dataload index 70\n",
      "dataload index 84\n",
      "dataload index 86\n",
      "dataload index 87\n",
      "dataload index 72\n",
      "dataload index 84\n",
      "dataload index 80\n",
      "dataload index 64\n",
      "dataload index 72\n",
      "dataload index 75\n",
      "dataload index 75\n",
      "dataload index 67\n",
      "dataload index 62\n",
      "dataload index 80\n",
      "dataload index 71\n",
      "dataload index 72\n",
      "dataload index 79\n",
      "dataload index 74\n",
      "dataload index 81\n",
      "dataload index 80\n",
      "dataload index 89\n",
      "dataload index 76\n",
      "dataload index 73\n",
      "dataload index 87\n",
      "dataload index 80\n",
      "dataload index 68\n",
      "dataload index 77\n",
      "dataload index 54\n",
      "dataload index 68\n",
      "dataload index 78\n",
      "dataload index 75\n",
      "dataload index 83\n",
      "dataload index 54\n",
      "dataload index 52\n",
      "dataload index 65\n",
      "dataload index 89\n",
      "dataload index 67\n",
      "dataload index 85\n",
      "dataload index 91\n",
      "dataload index 61\n",
      "dataload index 82\n",
      "dataload index 76\n",
      "dataload index 71\n",
      "dataload index 79\n",
      "dataload index 80\n",
      "dataload index 80\n",
      "dataload index 82\n",
      "dataload index 89\n",
      "dataload index 82\n",
      "dataload index 66\n",
      "dataload index 81\n",
      "dataload index 78\n",
      "dataload index 79\n",
      "dataload index 77\n",
      "dataload index 81\n",
      "dataload index 93\n",
      "dataload index 71\n",
      "dataload index 81\n",
      "dataload index 74\n",
      "dataload index 82\n",
      "dataload index 73\n",
      "dataload index 81\n",
      "dataload index 79\n",
      "dataload index 63\n",
      "dataload index 80\n",
      "dataload index 74\n",
      "dataload index 72\n",
      "dataload index 87\n",
      "dataload index 81\n",
      "dataload index 80\n",
      "dataload index 66\n",
      "dataload index 69\n",
      "dataload index 58\n",
      "dataload index 74\n",
      "dataload index 82\n",
      "dataload index 72\n",
      "dataload index 72\n",
      "dataload index 68\n",
      "dataload index 50\n",
      "dataload index 68\n",
      "dataload index 76\n",
      "dataload index 84\n",
      "dataload index 73\n",
      "dataload index 75\n",
      "dataload index 78\n",
      "dataload index 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataload index 81\n",
      "dataload index 78\n",
      "dataload index 67\n",
      "dataload index 74\n",
      "dataload index 77\n",
      "dataload index 80\n",
      "dataload index 77\n",
      "dataload index 61\n",
      "dataload index 76\n",
      "dataload index 89\n",
      "dataload index 80\n",
      "dataload index 74\n",
      "dataload index 74\n",
      "dataload index 80\n",
      "dataload index 74\n",
      "dataload index 90\n",
      "dataload index 83\n",
      "dataload index 69\n",
      "dataload index 62\n",
      "dataload index 65\n",
      "dataload index 72\n",
      "dataload index 71\n",
      "dataload index 77\n",
      "dataload index 60\n",
      "dataload index 70\n",
      "dataload index 58\n",
      "dataload index 78\n",
      "dataload index 72\n",
      "dataload index 76\n",
      "dataload index 78\n",
      "dataload index 75\n",
      "dataload index 80\n",
      "dataload index 75\n",
      "dataload index 72\n",
      "dataload index 96\n",
      "dataload index 85\n",
      "dataload index 78\n",
      "dataload index 77\n",
      "dataload index 73\n",
      "dataload index 64\n",
      "dataload index 77\n",
      "dataload index 78\n",
      "dataload index 73\n",
      "dataload index 79\n",
      "dataload index 69\n",
      "dataload index 76\n",
      "dataload index 93\n",
      "dataload index 40\n",
      "dataload index 66\n",
      "dataload index 82\n",
      "dataload index 67\n",
      "dataload index 83\n",
      "dataload index 74\n",
      "dataload index 70\n",
      "dataload index 83\n",
      "dataload index 75\n",
      "dataload index 79\n",
      "dataload index 75\n",
      "dataload index 80\n",
      "dataload index 69\n",
      "dataload index 74\n",
      "dataload index 71\n",
      "dataload index 60\n",
      "dataload index 76\n",
      "dataload index 71\n",
      "dataload index 67\n",
      "dataload index 59\n",
      "dataload index 89\n",
      "dataload index 82\n",
      "dataload index 82\n",
      "dataload index 77\n",
      "dataload index 75\n",
      "dataload index 85\n",
      "dataload index 73\n",
      "dataload index 77\n",
      "dataload index 78\n",
      "dataload index 67\n",
      "dataload index 74\n",
      "dataload index 71\n",
      "dataload index 44\n",
      "dataload index 80\n",
      "dataload index 68\n",
      "dataload index 68\n",
      "dataload index 81\n",
      "dataload index 64\n",
      "dataload index 84\n",
      "dataload index 78\n",
      "dataload index 89\n",
      "dataload index 67\n",
      "dataload index 88\n",
      "dataload index 67\n",
      "dataload index 77\n",
      "dataload index 80\n",
      "dataload index 75\n",
      "dataload index 79\n",
      "dataload index 79\n",
      "dataload index 75\n",
      "dataload index 50\n",
      "dataload index 59\n",
      "dataload index 74\n",
      "dataload index 77\n",
      "dataload index 72\n",
      "dataload index 77\n",
      "dataload index 70\n",
      "dataload index 72\n",
      "dataload index 77\n",
      "dataload index 83\n",
      "dataload index 86\n",
      "dataload index 81\n",
      "dataload index 65\n",
      "dataload index 79\n",
      "dataload index 70\n",
      "dataload index 68\n",
      "dataload index 83\n",
      "dataload index 75\n",
      "dataload index 90\n",
      "dataload index 71\n",
      "dataload index 74\n",
      "dataload index 87\n",
      "dataload index 73\n",
      "dataload index 77\n",
      "dataload index 79\n",
      "dataload index 70\n",
      "dataload index 68\n",
      "dataload index 73\n",
      "dataload index 80\n",
      "dataload index 77\n",
      "dataload index 75\n",
      "dataload index 74\n",
      "dataload index 70\n",
      "dataload index 65\n",
      "dataload index 77\n",
      "dataload index 80\n",
      "dataload index 56\n",
      "dataload index 58\n",
      "dataload index 87\n",
      "dataload index 76\n",
      "dataload index 78\n",
      "dataload index 82\n",
      "dataload index 67\n",
      "dataload index 75\n",
      "dataload index 77\n",
      "dataload index 76\n",
      "dataload index 79\n",
      "dataload index 75\n",
      "dataload index 82\n",
      "dataload index 78\n",
      "dataload index 52\n",
      "dataload index 94\n",
      "dataload index 75\n",
      "dataload index 90\n",
      "dataload index 75\n",
      "dataload index 74\n",
      "dataload index 91\n",
      "dataload index 70\n",
      "dataload index 61\n",
      "dataload index 68\n",
      "dataload index 70\n",
      "dataload index 68\n",
      "dataload index 90\n",
      "dataload index 78\n",
      "dataload index 87\n",
      "dataload index 73\n",
      "dataload index 85\n",
      "dataload index 74\n",
      "dataload index 82\n",
      "dataload index 57\n",
      "dataload index 68\n",
      "dataload index 72\n",
      "dataload index 82\n",
      "dataload index 73\n",
      "dataload index 75\n",
      "dataload index 81\n",
      "dataload index 85\n",
      "dataload index 70\n",
      "dataload index 82\n",
      "dataload index 71\n",
      "dataload index 76\n",
      "dataload index 66\n",
      "dataload index 82\n",
      "dataload index 64\n",
      "dataload index 56\n",
      "dataload index 74\n",
      "dataload index 66\n",
      "dataload index 81\n",
      "dataload index 69\n",
      "dataload index 75\n",
      "dataload index 72\n",
      "dataload index 71\n",
      "dataload index 67\n",
      "dataload index 61\n",
      "dataload index 84\n",
      "dataload index 80\n",
      "dataload index 83\n",
      "dataload index 70\n",
      "dataload index 64\n",
      "dataload index 70\n",
      "dataload index 66\n",
      "dataload index 73\n",
      "dataload index 67\n",
      "dataload index 83\n",
      "dataload index 82\n",
      "dataload index 76\n",
      "dataload index 76\n",
      "dataload index 76\n",
      "dataload index 77\n",
      "dataload index 80\n",
      "dataload index 79\n",
      "dataload index 81\n",
      "dataload index 68\n",
      "dataload index 80\n",
      "dataload index 81\n",
      "dataload index 66\n",
      "dataload index 68\n",
      "dataload index 56\n",
      "dataload index 75\n",
      "dataload index 79\n",
      "dataload index 71\n",
      "dataload index 84\n",
      "dataload index 76\n",
      "dataload index 59\n",
      "dataload index 57\n",
      "dataload index 71\n",
      "dataload index 83\n",
      "dataload index 80\n",
      "dataload index 80\n",
      "dataload index 82\n",
      "dataload index 79\n",
      "dataload index 70\n",
      "dataload index 65\n",
      "dataload index 91\n",
      "dataload index 84\n",
      "dataload index 72\n",
      "dataload index 77\n",
      "dataload index 70\n",
      "dataload index 66\n",
      "dataload index 79\n",
      "dataload index 72\n",
      "dataload index 72\n",
      "dataload index 70\n",
      "dataload index 69\n",
      "dataload index 82\n",
      "dataload index 73\n",
      "dataload index 82\n",
      "dataload index 78\n",
      "dataload index 83\n",
      "dataload index 77\n",
      "dataload index 87\n",
      "dataload index 52\n",
      "dataload index 59\n",
      "dataload index 72\n",
      "dataload index 67\n",
      "dataload index 49\n",
      "dataload index 81\n",
      "dataload index 72\n",
      "dataload index 74\n",
      "dataload index 76\n",
      "dataload index 58\n",
      "dataload index 77\n",
      "dataload index 77\n",
      "dataload index 87\n",
      "dataload index 65\n",
      "dataload index 65\n",
      "dataload index 57\n",
      "dataload index 87\n",
      "dataload index 66\n",
      "dataload index 81\n",
      "dataload index 92\n",
      "dataload index 89\n",
      "dataload index 78\n",
      "dataload index 66\n",
      "dataload index 82\n",
      "dataload index 73\n",
      "dataload index 89\n",
      "dataload index 74\n",
      "dataload index 79\n",
      "dataload index 73\n",
      "dataload index 84\n",
      "dataload index 84\n",
      "dataload index 80\n",
      "dataload index 77\n",
      "dataload index 72\n",
      "dataload index 63\n",
      "dataload index 67\n",
      "dataload index 81\n",
      "dataload index 72\n",
      "dataload index 56\n",
      "dataload index 65\n",
      "dataload index 74\n",
      "dataload index 74\n",
      "dataload index 79\n",
      "dataload index 71\n",
      "dataload index 78\n",
      "dataload index 66\n",
      "dataload index 78\n",
      "dataload index 71\n",
      "dataload index 74\n",
      "dataload index 76\n",
      "dataload index 84\n",
      "dataload index 75\n",
      "dataload index 72\n",
      "dataload index 72\n",
      "dataload index 83\n",
      "dataload index 79\n",
      "dataload index 80\n",
      "dataload index 68\n",
      "dataload index 93\n",
      "dataload index 84\n",
      "dataload index 78\n",
      "dataload index 74\n",
      "dataload index 72\n",
      "dataload index 79\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[128, 1, 1]' is invalid for input of size 12800",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d5a787c033d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[128, 1, 1]' is invalid for input of size 12800"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "for smiles,label in data_loader:\n",
    "    # real\n",
    "    target = torch.FloatTensor([1.0]).view(1,1,1).repeat(1, smiles.shape[0] ,1).to(device)\n",
    "    label = label.float().to(device)\n",
    "    label = label.view(batch_size, 1, 1).repeat(1, smiles.shape[1], 1)\n",
    "    print(D.forward(smiles.to(device).float(), label))\n",
    "    \n",
    "    i += 1\n",
    "    if (i >= 4):\n",
    "        break\n",
    "    pass\n",
    "\n",
    "for i in range(4):\n",
    "    fake_input = []\n",
    "    fake_label = []\n",
    "    for finput, label in generate_random_seed(batch_size):\n",
    "        fake_input.append(finput)\n",
    "        fake_label.append(label)\n",
    "    \n",
    "    \n",
    "    fake_input = torch.FloatTensor(fake_input).to(device)\n",
    "    \n",
    "    #fake_input = fake_input.reshape(1, fake_input.shape[0], fake_input.shape[1])\n",
    "    fake_label = torch.FloatTensor(fake_label).to(device)\n",
    "    #print('2.before change label.shape', fake_input.shape, 'fake_label', fake_label.shape)\n",
    "    fake_label = fake_label.view(batch_size, 1, 1).repeat(1, fake_input.shape[1], 1)\n",
    "    #print('fake_input.shape', fake_input.shape, 'fake_label.shape', fake_label.shape)\n",
    "    target = torch.FloatTensor([0.0]).view(1,1,1).repeat(1, fake_input.shape[0] ,1).to(device)\n",
    "    D.forward(fake_input, fake_label)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator class\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        # initialise parent pytorch class\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = batch_size \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(G_input_size * 2, 200),\n",
    "            nn.LeakyReLU(0.02),\n",
    "            #nn.LayerNorm(200),\n",
    "            nn.Linear(200, number_of_data)\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # create optimiser, simple stochastic gradient descent\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=learning_rate_G)\n",
    "        \n",
    "        # counter and accumulator for progress\n",
    "        self.counter = 0;\n",
    "        self.progress = []\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def forward(self, seed_tensor, label_tensor):        \n",
    "        # combine seed and label\n",
    "        #print('seed_tensor.shape', seed_tensor.shape, 'label_tensor', label_tensor.shape)\n",
    "        inputs = torch.cat((seed_tensor, label_tensor))\n",
    "        #print('after torch.cat', inputs.shape)\n",
    "        outputs = self.model(inputs)\n",
    "        #print('outputs', outputs)\n",
    "        return torch.argmax(F.softmax(outputs, dim=0))\n",
    "\n",
    "\n",
    "    def train(self, D, inputs, label_tensor, targets):\n",
    "        # calculate the output of the network\n",
    "        g_output = self.forward(inputs, label_tensor)\n",
    "\n",
    "        g_data = data_dataset[g_output]\n",
    "        \n",
    "        g_input = torch.FloatTensor(g_data[0]).to(device)\n",
    "        g_input = g_input.reshape(1, g_input.shape[0], g_input.shape[1])\n",
    "        g_label = torch.FloatTensor(g_data[1]).to(device)\n",
    "        g_label = g_label.unsqueeze(1).repeat(1, g_input.shape[1], 1)\n",
    "        if (self.counter % 1000 == 0):\n",
    "            print('g_output', g_output, 'g_data[1]', g_data[1])        \n",
    "        \n",
    "        # pass onto Discriminator\n",
    "        d_output = D.forward(g_input, g_label)\n",
    "        \n",
    "        #print('d_output.shape', d_output.shape, 'targets.shape', targets.shape)\n",
    "        if (d_output.shape != targets.shape):\n",
    "            print(\"Generator loss function issue: d_output.shape != targets.shape\", d_output.shape, targets.shape)\n",
    "        \n",
    "        # calculate error\n",
    "        loss = D.loss_function(d_output, targets)\n",
    "\n",
    "        # increase counter and accumulate error every 10\n",
    "        self.counter += 1;\n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss.item())\n",
    "            pass\n",
    "\n",
    "        # zero gradients, perform a backward pass, update weights\n",
    "        self.optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimiser.step()\n",
    "\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def get_smiles(self, label):\n",
    "        #fake_input = torch.FloatTensor(generate_random_seed_G(batch_size)).to(device)\n",
    "        #fake_label = torch.FloatTensor([label]).to(device)\n",
    "        \n",
    "        fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "        fake_label = torch.FloatTensor(generate_random_value(G_input_size)).to(device)\n",
    "        idx = self.forward(fake_input, fake_label).detach().cpu().numpy()\n",
    "        #print('idx', idx, 'fake_input', fake_input.shape, 'fake_label.shape', fake_label.shape,  'result.shape', result.shape)\n",
    "        \n",
    "        #idx = self.get_index(G.forward(fake_input, fake_label)).detach().cpu().numpy()\n",
    "        return data['smiles'].iloc[idx]\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def plot_progress(self):\n",
    "        df = pandas.DataFrame(self.progress, columns=['loss'])\n",
    "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx tensor(29411, device='cuda:0')\n",
      "dataload index 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0]], dtype=int8),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the generator output is of the right type and shape\n",
    "\n",
    "G = Generator(1)\n",
    "G.to(device)\n",
    "\n",
    "#fake = generate_random_seed()\n",
    "fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "fake_label = torch.FloatTensor(generate_random_value(G_input_size)).to(device)\n",
    "idx = G.forward(fake_input, fake_label)\n",
    "print('idx', idx)\n",
    "data_dataset[idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC12CC3C1CC(O)C23'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.get_smiles(-12.2323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1\n",
      "dataload index 78\n",
      "dataload index 67\n",
      "dataload index 64\n",
      "dataload index 76\n",
      "dataload index 77\n",
      "dataload index 83\n",
      "dataload index 65\n",
      "dataload index 81\n",
      "dataload index 81\n",
      "dataload index 80\n",
      "dataload index 76\n",
      "dataload index 72\n",
      "dataload index 82\n",
      "dataload index 74\n",
      "dataload index 77\n",
      "dataload index 73\n",
      "dataload index 70\n",
      "dataload index 76\n",
      "dataload index 71\n",
      "dataload index 89\n",
      "dataload index 86\n",
      "dataload index 73\n",
      "dataload index 65\n",
      "dataload index 70\n",
      "dataload index 95\n",
      "dataload index 66\n",
      "dataload index 74\n",
      "dataload index 78\n",
      "dataload index 64\n",
      "dataload index 77\n",
      "dataload index 65\n",
      "dataload index 82\n",
      "dataload index 67\n",
      "dataload index 82\n",
      "dataload index 86\n",
      "dataload index 63\n",
      "dataload index 71\n",
      "dataload index 85\n",
      "dataload index 65\n",
      "dataload index 72\n",
      "dataload index 60\n",
      "dataload index 73\n",
      "dataload index 71\n",
      "dataload index 84\n",
      "dataload index 77\n",
      "dataload index 72\n",
      "dataload index 75\n",
      "dataload index 82\n",
      "dataload index 81\n",
      "dataload index 76\n",
      "dataload index 94\n",
      "dataload index 78\n",
      "dataload index 78\n",
      "dataload index 80\n",
      "dataload index 66\n",
      "dataload index 79\n",
      "dataload index 77\n",
      "dataload index 75\n",
      "dataload index 86\n",
      "dataload index 77\n",
      "dataload index 70\n",
      "dataload index 78\n",
      "dataload index 76\n",
      "dataload index 85\n",
      "dataload index 78\n",
      "dataload index 76\n",
      "dataload index 74\n",
      "dataload index 72\n",
      "dataload index 71\n",
      "dataload index 81\n",
      "dataload index 82\n",
      "dataload index 83\n",
      "dataload index 69\n",
      "dataload index 72\n",
      "dataload index 68\n",
      "dataload index 69\n",
      "dataload index 78\n",
      "dataload index 57\n",
      "dataload index 63\n",
      "dataload index 68\n",
      "dataload index 61\n",
      "dataload index 74\n",
      "dataload index 83\n",
      "dataload index 72\n",
      "dataload index 81\n",
      "dataload index 78\n",
      "dataload index 78\n",
      "dataload index 72\n",
      "dataload index 86\n",
      "dataload index 68\n",
      "dataload index 63\n",
      "dataload index 81\n",
      "dataload index 67\n",
      "dataload index 69\n",
      "dataload index 85\n",
      "dataload index 77\n",
      "dataload index 74\n",
      "dataload index 75\n",
      "dataload index 90\n",
      "dataload index 66\n",
      "dataload index 78\n",
      "dataload index 78\n",
      "dataload index 71\n",
      "dataload index 80\n",
      "dataload index 85\n",
      "dataload index 81\n",
      "dataload index 66\n",
      "dataload index 73\n",
      "dataload index 68\n",
      "dataload index 68\n",
      "dataload index 95\n",
      "dataload index 90\n",
      "dataload index 84\n",
      "dataload index 79\n",
      "dataload index 63\n",
      "dataload index 82\n",
      "dataload index 73\n",
      "dataload index 84\n",
      "dataload index 83\n",
      "dataload index 84\n",
      "dataload index 80\n",
      "dataload index 71\n",
      "dataload index 77\n",
      "dataload index 70\n",
      "dataload index 67\n",
      "dataload index 73\n",
      "dataload index 75\n",
      "dataload index 51\n",
      "dataload index 70\n",
      "dataload index 80\n",
      "dataload index 61\n",
      "dataload index 72\n",
      "dataload index 73\n",
      "dataload index 72\n",
      "dataload index 69\n",
      "dataload index 76\n",
      "dataload index 73\n",
      "dataload index 67\n",
      "dataload index 78\n",
      "dataload index 72\n",
      "dataload index 81\n",
      "dataload index 84\n",
      "dataload index 66\n",
      "dataload index 61\n",
      "dataload index 75\n",
      "dataload index 71\n",
      "dataload index 60\n",
      "dataload index 60\n",
      "dataload index 75\n",
      "dataload index 64\n",
      "dataload index 74\n",
      "dataload index 80\n",
      "dataload index 61\n",
      "dataload index 74\n",
      "dataload index 83\n",
      "dataload index 83\n",
      "dataload index 63\n",
      "dataload index 69\n",
      "dataload index 66\n",
      "dataload index 71\n",
      "dataload index 80\n",
      "dataload index 71\n",
      "dataload index 86\n",
      "dataload index 80\n",
      "dataload index 87\n",
      "dataload index 73\n",
      "dataload index 75\n",
      "dataload index 77\n",
      "dataload index 66\n",
      "dataload index 59\n",
      "dataload index 83\n",
      "dataload index 73\n",
      "dataload index 69\n",
      "dataload index 75\n",
      "dataload index 60\n",
      "dataload index 83\n",
      "dataload index 73\n",
      "dataload index 80\n",
      "dataload index 76\n",
      "dataload index 70\n",
      "dataload index 73\n",
      "dataload index 85\n",
      "dataload index 75\n",
      "dataload index 78\n",
      "dataload index 61\n",
      "dataload index 76\n",
      "dataload index 77\n",
      "dataload index 81\n",
      "dataload index 49\n",
      "dataload index 65\n",
      "dataload index 74\n",
      "dataload index 75\n",
      "dataload index 75\n",
      "dataload index 80\n",
      "dataload index 69\n",
      "dataload index 80\n",
      "dataload index 70\n",
      "dataload index 69\n",
      "dataload index 72\n",
      "dataload index 69\n",
      "dataload index 81\n",
      "dataload index 87\n",
      "dataload index 71\n",
      "dataload index 88\n",
      "dataload index 63\n",
      "dataload index 80\n",
      "dataload index 73\n",
      "dataload index 66\n",
      "dataload index 79\n",
      "dataload index 83\n",
      "dataload index 83\n",
      "dataload index 77\n",
      "dataload index 89\n",
      "dataload index 81\n",
      "dataload index 76\n",
      "dataload index 84\n",
      "dataload index 74\n",
      "dataload index 80\n",
      "dataload index 77\n",
      "dataload index 76\n",
      "dataload index 85\n",
      "dataload index 77\n",
      "dataload index 67\n",
      "dataload index 79\n",
      "dataload index 74\n",
      "dataload index 113\n",
      "dataload index 87\n",
      "dataload index 81\n",
      "dataload index 74\n",
      "dataload index 75\n",
      "dataload index 74\n",
      "dataload index 62\n",
      "dataload index 78\n",
      "dataload index 81\n",
      "dataload index 72\n",
      "dataload index 74\n",
      "dataload index 77\n",
      "dataload index 66\n",
      "dataload index 78\n",
      "dataload index 89\n",
      "dataload index 86\n",
      "dataload index 67\n",
      "dataload index 84\n",
      "dataload index 71\n",
      "dataload index 67\n",
      "dataload index 88\n",
      "dataload index 75\n",
      "dataload index 76\n",
      "dataload index 95\n",
      "dataload index 78\n",
      "dataload index 69\n",
      "dataload index 76\n",
      "dataload index 82\n",
      "dataload index 95\n",
      "dataload index 73\n",
      "dataload index 68\n",
      "dataload index 83\n",
      "dataload index 57\n",
      "dataload index 58\n",
      "dataload index 81\n",
      "dataload index 87\n",
      "dataload index 65\n",
      "dataload index 72\n",
      "dataload index 69\n",
      "dataload index 73\n",
      "dataload index 82\n",
      "dataload index 82\n",
      "dataload index 75\n",
      "dataload index 74\n",
      "dataload index 81\n",
      "dataload index 81\n",
      "dataload index 68\n",
      "dataload index 78\n",
      "dataload index 78\n",
      "dataload index 72\n",
      "dataload index 73\n",
      "dataload index 67\n",
      "dataload index 72\n",
      "dataload index 75\n",
      "dataload index 80\n",
      "dataload index 74\n",
      "dataload index 68\n",
      "dataload index 71\n",
      "dataload index 81\n",
      "dataload index 65\n",
      "dataload index 73\n",
      "dataload index 66\n",
      "dataload index 67\n",
      "dataload index 79\n",
      "dataload index 86\n",
      "dataload index 75\n",
      "dataload index 72\n",
      "dataload index 71\n",
      "dataload index 81\n",
      "dataload index 74\n",
      "dataload index 73\n",
      "dataload index 72\n",
      "dataload index 71\n",
      "dataload index 76\n",
      "dataload index 84\n",
      "dataload index 71\n",
      "dataload index 79\n",
      "dataload index 80\n",
      "dataload index 92\n",
      "dataload index 78\n",
      "dataload index 76\n",
      "dataload index 61\n",
      "dataload index 83\n",
      "dataload index 88\n",
      "dataload index 70\n",
      "dataload index 73\n",
      "dataload index 80\n",
      "dataload index 78\n",
      "dataload index 75\n",
      "dataload index 86\n",
      "dataload index 79\n",
      "dataload index 73\n",
      "dataload index 79\n",
      "dataload index 74\n",
      "dataload index 78\n",
      "dataload index 81\n",
      "dataload index 74\n",
      "dataload index 77\n",
      "dataload index 66\n",
      "dataload index 73\n",
      "dataload index 71\n",
      "dataload index 70\n",
      "dataload index 64\n",
      "dataload index 80\n",
      "dataload index 71\n",
      "dataload index 87\n",
      "dataload index 73\n",
      "dataload index 70\n",
      "dataload index 71\n",
      "dataload index 83\n",
      "dataload index 60\n",
      "dataload index 80\n",
      "dataload index 72\n",
      "dataload index 81\n",
      "dataload index 69\n",
      "dataload index 79\n",
      "dataload index 75\n",
      "dataload index 84\n",
      "dataload index 70\n",
      "dataload index 73\n",
      "dataload index 75\n",
      "dataload index 58\n",
      "dataload index 70\n",
      "dataload index 65\n",
      "dataload index 78\n",
      "dataload index 71\n",
      "dataload index 80\n",
      "dataload index 53\n",
      "dataload index 74\n",
      "dataload index 74\n",
      "dataload index 79\n",
      "dataload index 85\n",
      "dataload index 73\n",
      "dataload index 58\n",
      "dataload index 86\n",
      "dataload index 78\n",
      "dataload index 80\n",
      "dataload index 68\n",
      "dataload index 77\n",
      "dataload index 80\n",
      "dataload index 73\n",
      "dataload index 74\n",
      "dataload index 77\n",
      "dataload index 80\n",
      "dataload index 72\n",
      "dataload index 60\n",
      "dataload index 70\n",
      "dataload index 73\n",
      "dataload index 72\n",
      "dataload index 77\n",
      "dataload index 76\n",
      "dataload index 67\n",
      "dataload index 77\n",
      "dataload index 74\n",
      "dataload index 83\n",
      "dataload index 77\n",
      "dataload index 74\n",
      "dataload index 73\n",
      "dataload index 77\n",
      "dataload index 75\n",
      "dataload index 76\n",
      "dataload index 74\n",
      "dataload index 58\n",
      "dataload index 74\n",
      "dataload index 69\n",
      "dataload index 80\n",
      "dataload index 75\n",
      "dataload index 73\n",
      "dataload index 78\n",
      "dataload index 71\n",
      "dataload index 80\n",
      "dataload index 72\n",
      "dataload index 60\n",
      "dataload index 78\n",
      "dataload index 75\n",
      "dataload index 69\n",
      "dataload index 67\n",
      "dataload index 70\n",
      "dataload index 65\n",
      "dataload index 81\n",
      "dataload index 69\n",
      "dataload index 77\n",
      "dataload index 84\n",
      "dataload index 74\n",
      "dataload index 69\n",
      "dataload index 58\n",
      "dataload index 64\n",
      "dataload index 56\n",
      "dataload index 70\n",
      "dataload index 67\n",
      "dataload index 79\n",
      "dataload index 74\n",
      "dataload index 74\n",
      "dataload index 73\n",
      "dataload index 63\n",
      "dataload index 73\n",
      "dataload index 88\n",
      "dataload index 79\n",
      "dataload index 78\n",
      "dataload index 76\n",
      "dataload index 85\n",
      "dataload index 85\n",
      "dataload index 83\n",
      "dataload index 69\n",
      "dataload index 81\n",
      "dataload index 76\n",
      "dataload index 75\n",
      "dataload index 85\n",
      "dataload index 73\n",
      "dataload index 67\n",
      "dataload index 75\n",
      "dataload index 62\n",
      "dataload index 74\n",
      "dataload index 76\n",
      "dataload index 77\n",
      "dataload index 80\n",
      "dataload index 67\n",
      "dataload index 85\n",
      "dataload index 77\n",
      "dataload index 82\n",
      "dataload index 81\n",
      "dataload index 76\n",
      "dataload index 83\n",
      "dataload index 82\n",
      "dataload index 82\n",
      "dataload index 66\n",
      "dataload index 67\n",
      "dataload index 69\n",
      "dataload index 75\n",
      "dataload index 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataload index 79\n",
      "dataload index 73\n",
      "dataload index 78\n",
      "dataload index 59\n",
      "dataload index 84\n",
      "dataload index 78\n",
      "dataload index 58\n",
      "dataload index 82\n",
      "dataload index 75\n",
      "dataload index 72\n",
      "dataload index 77\n",
      "dataload index 81\n",
      "dataload index 72\n",
      "dataload index 84\n",
      "dataload index 71\n",
      "dataload index 62\n",
      "dataload index 90\n",
      "dataload index 75\n",
      "dataload index 75\n",
      "dataload index 66\n",
      "dataload index 74\n",
      "dataload index 78\n",
      "dataload index 84\n",
      "dataload index 90\n",
      "dataload index 78\n",
      "dataload index 48\n",
      "dataload index 66\n",
      "dataload index 80\n",
      "dataload index 84\n",
      "dataload index 69\n",
      "dataload index 72\n",
      "dataload index 70\n",
      "dataload index 77\n",
      "dataload index 64\n",
      "dataload index 74\n",
      "dataload index 68\n",
      "dataload index 76\n",
      "dataload index 70\n",
      "dataload index 93\n",
      "dataload index 80\n",
      "dataload index 78\n",
      "dataload index 75\n",
      "dataload index 67\n",
      "dataload index 69\n",
      "dataload index 76\n",
      "dataload index 80\n",
      "dataload index 82\n",
      "dataload index 81\n",
      "dataload index 77\n",
      "dataload index 73\n",
      "dataload index 77\n",
      "dataload index 82\n",
      "dataload index 72\n",
      "dataload index 72\n",
      "dataload index 75\n",
      "dataload index 85\n",
      "dataload index 74\n",
      "dataload index 71\n",
      "dataload index 81\n",
      "dataload index 71\n",
      "dataload index 63\n",
      "dataload index 75\n",
      "dataload index 80\n",
      "dataload index 78\n",
      "dataload index 71\n",
      "dataload index 75\n",
      "dataload index 79\n",
      "dataload index 75\n",
      "dataload index 81\n",
      "dataload index 80\n",
      "dataload index 77\n",
      "dataload index 75\n",
      "dataload index 43\n",
      "dataload index 76\n",
      "dataload index 76\n",
      "dataload index 80\n",
      "dataload index 73\n",
      "dataload index 77\n",
      "dataload index 82\n",
      "dataload index 72\n",
      "dataload index 69\n",
      "dataload index 75\n",
      "dataload index 68\n",
      "dataload index 89\n",
      "dataload index 67\n",
      "dataload index 74\n",
      "dataload index 77\n",
      "dataload index 75\n",
      "dataload index 82\n",
      "dataload index 88\n",
      "dataload index 69\n",
      "dataload index 77\n",
      "dataload index 80\n",
      "dataload index 85\n",
      "dataload index 82\n",
      "dataload index 77\n",
      "dataload index 66\n",
      "dataload index 82\n",
      "dataload index 85\n",
      "dataload index 72\n",
      "dataload index 82\n",
      "dataload index 77\n",
      "dataload index 90\n",
      "dataload index 81\n",
      "dataload index 84\n",
      "dataload index 84\n",
      "dataload index 69\n",
      "dataload index 77\n",
      "dataload index 79\n",
      "dataload index 72\n",
      "dataload index 57\n",
      "dataload index 73\n",
      "dataload index 73\n",
      "dataload index 85\n",
      "dataload index 82\n",
      "dataload index 82\n",
      "dataload index 74\n",
      "dataload index 75\n",
      "dataload index 78\n",
      "dataload index 70\n",
      "dataload index 77\n",
      "dataload index 82\n",
      "dataload index 68\n",
      "dataload index 77\n",
      "dataload index 87\n",
      "dataload index 78\n",
      "dataload index 73\n",
      "dataload index 90\n",
      "dataload index 72\n",
      "dataload index 79\n",
      "dataload index 75\n",
      "dataload index 75\n",
      "dataload index 65\n",
      "dataload index 79\n",
      "dataload index 82\n",
      "dataload index 79\n",
      "dataload index 70\n",
      "dataload index 63\n",
      "dataload index 70\n",
      "dataload index 67\n",
      "dataload index 74\n",
      "dataload index 56\n",
      "dataload index 52\n",
      "dataload index 69\n",
      "dataload index 78\n",
      "dataload index 78\n",
      "dataload index 71\n",
      "dataload index 77\n",
      "dataload index 76\n",
      "dataload index 62\n",
      "dataload index 67\n",
      "dataload index 83\n",
      "dataload index 88\n",
      "dataload index 68\n",
      "dataload index 88\n",
      "dataload index 83\n",
      "dataload index 77\n",
      "dataload index 71\n",
      "dataload index 68\n",
      "dataload index 68\n",
      "dataload index 74\n",
      "dataload index 77\n",
      "dataload index 65\n",
      "dataload index 72\n",
      "dataload index 71\n",
      "dataload index 46\n",
      "dataload index 59\n",
      "dataload index 83\n",
      "dataload index 80\n",
      "dataload index 83\n",
      "dataload index 70\n",
      "dataload index 81\n",
      "dataload index 89\n",
      "dataload index 75\n",
      "dataload index 72\n",
      "dataload index 65\n",
      "dataload index 82\n",
      "dataload index 73\n",
      "dataload index 74\n",
      "dataload index 68\n",
      "dataload index 72\n",
      "dataload index 68\n",
      "dataload index 82\n",
      "dataload index 73\n",
      "dataload index 75\n",
      "dataload index 69\n",
      "dataload index 74\n",
      "dataload index 80\n",
      "dataload index 81\n",
      "dataload index 73\n",
      "dataload index 78\n",
      "dataload index 68\n",
      "dataload index 70\n",
      "dataload index 87\n",
      "dataload index 69\n",
      "dataload index 84\n",
      "dataload index 73\n",
      "dataload index 77\n",
      "dataload index 73\n",
      "dataload index 70\n",
      "dataload index 56\n",
      "dataload index 79\n",
      "dataload index 76\n",
      "dataload index 83\n",
      "dataload index 63\n",
      "dataload index 78\n",
      "dataload index 54\n",
      "dataload index 74\n",
      "dataload index 66\n",
      "dataload index 87\n",
      "dataload index 74\n",
      "dataload index 78\n",
      "dataload index 75\n",
      "dataload index 72\n",
      "dataload index 78\n",
      "dataload index 65\n",
      "dataload index 86\n",
      "dataload index 68\n",
      "dataload index 72\n",
      "dataload index 81\n",
      "dataload index 83\n",
      "dataload index 77\n",
      "dataload index 71\n",
      "dataload index 67\n",
      "dataload index 70\n",
      "dataload index 87\n",
      "dataload index 67\n",
      "dataload index 89\n",
      "dataload index 69\n",
      "dataload index 80\n",
      "dataload index 77\n",
      "dataload index 75\n",
      "dataload index 77\n",
      "dataload index 75\n",
      "dataload index 77\n",
      "dataload index 76\n",
      "dataload index 72\n",
      "dataload index 81\n",
      "dataload index 88\n",
      "dataload index 80\n",
      "dataload index 89\n",
      "dataload index 80\n",
      "dataload index 83\n",
      "dataload index 85\n",
      "dataload index 83\n",
      "dataload index 72\n",
      "dataload index 85\n",
      "dataload index 71\n",
      "dataload index 74\n",
      "dataload index 90\n",
      "dataload index 68\n",
      "dataload index 82\n",
      "dataload index 75\n",
      "dataload index 70\n",
      "dataload index 71\n",
      "dataload index 86\n",
      "dataload index 85\n",
      "dataload index 86\n",
      "dataload index 71\n",
      "dataload index 75\n",
      "dataload index 76\n",
      "dataload index 78\n",
      "dataload index 67\n",
      "dataload index 58\n",
      "dataload index 73\n",
      "dataload index 74\n",
      "dataload index 64\n",
      "dataload index 75\n",
      "dataload index 65\n",
      "dataload index 73\n",
      "dataload index 75\n",
      "dataload index 69\n",
      "dataload index 65\n",
      "dataload index 79\n",
      "dataload index 80\n",
      "dataload index 85\n",
      "dataload index 69\n",
      "dataload index 76\n",
      "dataload index 65\n",
      "dataload index 62\n",
      "dataload index 82\n",
      "dataload index 85\n",
      "dataload index 79\n",
      "dataload index 75\n",
      "dataload index 76\n",
      "dataload index 67\n",
      "dataload index 70\n",
      "dataload index 56\n",
      "dataload index 67\n",
      "dataload index 76\n",
      "dataload index 85\n",
      "dataload index 83\n",
      "dataload index 67\n",
      "dataload index 73\n",
      "dataload index 78\n",
      "dataload index 67\n",
      "dataload index 83\n",
      "dataload index 73\n",
      "dataload index 67\n",
      "dataload index 64\n",
      "dataload index 74\n",
      "dataload index 65\n",
      "dataload index 86\n",
      "dataload index 86\n",
      "dataload index 72\n",
      "dataload index 82\n",
      "dataload index 56\n",
      "dataload index 81\n",
      "dataload index 83\n",
      "dataload index 93\n",
      "dataload index 69\n",
      "dataload index 93\n",
      "dataload index 74\n",
      "dataload index 69\n",
      "dataload index 68\n",
      "dataload index 72\n",
      "dataload index 75\n",
      "dataload index 71\n",
      "dataload index 99\n",
      "dataload index 89\n",
      "dataload index 90\n",
      "dataload index 79\n",
      "dataload index 63\n",
      "dataload index 62\n",
      "dataload index 78\n",
      "dataload index 83\n",
      "dataload index 78\n",
      "dataload index 76\n",
      "dataload index 71\n",
      "dataload index 74\n",
      "dataload index 69\n",
      "dataload index 64\n",
      "dataload index 72\n",
      "dataload index 63\n",
      "dataload index 63\n",
      "dataload index 80\n",
      "dataload index 72\n",
      "dataload index 75\n",
      "dataload index 75\n",
      "dataload index 76\n",
      "dataload index 77\n",
      "dataload index 80\n",
      "dataload index 72\n",
      "dataload index 72\n",
      "dataload index 89\n",
      "dataload index 70\n",
      "dataload index 81\n",
      "dataload index 85\n",
      "dataload index 69\n",
      "dataload index 82\n",
      "dataload index 83\n",
      "dataload index 79\n",
      "dataload index 72\n",
      "dataload index 70\n",
      "dataload index 71\n",
      "dataload index 74\n",
      "dataload index 64\n",
      "dataload index 91\n",
      "dataload index 83\n",
      "dataload index 75\n",
      "dataload index 83\n",
      "dataload index 78\n",
      "dataload index 88\n",
      "dataload index 72\n",
      "dataload index 73\n",
      "dataload index 77\n",
      "dataload index 92\n",
      "dataload index 81\n",
      "dataload index 78\n",
      "dataload index 63\n",
      "dataload index 75\n",
      "dataload index 83\n",
      "dataload index 58\n",
      "dataload index 81\n",
      "dataload index 81\n",
      "dataload index 82\n",
      "dataload index 69\n",
      "dataload index 64\n",
      "dataload index 68\n",
      "dataload index 47\n",
      "dataload index 81\n",
      "dataload index 64\n",
      "dataload index 86\n",
      "dataload index 77\n",
      "dataload index 81\n",
      "dataload index 60\n",
      "dataload index 74\n",
      "dataload index 75\n",
      "dataload index 84\n",
      "dataload index 73\n",
      "dataload index 54\n",
      "dataload index 66\n",
      "dataload index 51\n",
      "dataload index 66\n",
      "dataload index 67\n",
      "dataload index 75\n",
      "dataload index 61\n",
      "dataload index 63\n",
      "dataload index 79\n",
      "dataload index 82\n",
      "dataload index 78\n",
      "dataload index 71\n",
      "dataload index 74\n",
      "dataload index 74\n",
      "dataload index 73\n",
      "dataload index 78\n",
      "dataload index 69\n",
      "dataload index 69\n",
      "dataload index 78\n",
      "dataload index 87\n",
      "dataload index 75\n",
      "dataload index 59\n",
      "dataload index 76\n",
      "dataload index 76\n",
      "dataload index 83\n",
      "dataload index 64\n",
      "dataload index 86\n",
      "dataload index 71\n",
      "dataload index 75\n",
      "dataload index 77\n",
      "dataload index 81\n",
      "dataload index 68\n",
      "dataload index 70\n",
      "dataload index 67\n",
      "dataload index 74\n",
      "dataload index 72\n",
      "dataload index 50\n",
      "dataload index 75\n",
      "dataload index 74\n",
      "dataload index 68\n",
      "dataload index 80\n",
      "dataload index 67\n",
      "dataload index 71\n",
      "dataload index 85\n",
      "dataload index 66\n",
      "dataload index 70\n",
      "dataload index 76\n",
      "dataload index 72\n",
      "dataload index 87\n",
      "dataload index 80\n",
      "dataload index 80\n",
      "dataload index 82\n",
      "dataload index 81\n",
      "dataload index 79\n",
      "dataload index 71\n",
      "dataload index 59\n",
      "dataload index 80\n",
      "dataload index 81\n",
      "dataload index 71\n",
      "dataload index 69\n",
      "dataload index 76\n",
      "dataload index 70\n",
      "dataload index 78\n",
      "dataload index 87\n",
      "dataload index 83\n",
      "dataload index 72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataload index 68\n",
      "dataload index 78\n",
      "dataload index 63\n",
      "dataload index 73\n",
      "dataload index 88\n",
      "dataload index 89\n",
      "dataload index 74\n",
      "dataload index 77\n",
      "dataload index 82\n",
      "dataload index 86\n",
      "dataload index 65\n",
      "dataload index 73\n",
      "dataload index 82\n",
      "dataload index 81\n",
      "dataload index 68\n",
      "dataload index 83\n",
      "dataload index 81\n",
      "dataload index 73\n",
      "dataload index 71\n",
      "dataload index 82\n",
      "dataload index 78\n",
      "dataload index 71\n",
      "dataload index 64\n",
      "dataload index 74\n",
      "dataload index 76\n",
      "dataload index 77\n",
      "dataload index 76\n",
      "dataload index 64\n",
      "dataload index 64\n",
      "dataload index 76\n",
      "dataload index 79\n",
      "dataload index 84\n",
      "dataload index 86\n",
      "dataload index 76\n",
      "dataload index 82\n",
      "dataload index 71\n",
      "dataload index 52\n",
      "dataload index 82\n",
      "dataload index 65\n",
      "dataload index 72\n",
      "dataload index 74\n",
      "dataload index 75\n",
      "dataload index 78\n",
      "dataload index 65\n",
      "dataload index 77\n",
      "dataload index 84\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[128, 1, 1]' is invalid for input of size 12800",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[128, 1, 1]' is invalid for input of size 12800"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "D = Discriminator()\n",
    "D.to(device)\n",
    "G = Generator(batch_size)\n",
    "G.to(device)\n",
    "\n",
    "# train Discriminator and Generator\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print (\"epoch = \", epoch + 1)\n",
    "\n",
    "    # train Discriminator and Generator\n",
    "    for smiles,label in data_loader:\n",
    "        #########################################################                   \n",
    "        # train discriminator on true\n",
    "        #########################################################                   \n",
    "        target = torch.FloatTensor([1.0]).view(1,1,1).repeat(1, smiles.shape[0] ,1).to(device)\n",
    "        #print('1.before change label.shape', label.shape, 'smiles', smiles.shape)\n",
    "        label = label.float().to(device)\n",
    "        label = label.view(batch_size, 1, 1).repeat(1, smiles.shape[1], 1)\n",
    "        D.train(smiles.to(device).float(), label, target)\n",
    "        \n",
    "        \n",
    "        #########################################################                   \n",
    "        # train discriminator on false\n",
    "        # use detach() so gradients in G are not calculated\n",
    "        #########################################################                   \n",
    "        fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "        fake_label = torch.FloatTensor(generate_random_value(G_input_size)).to(device)\n",
    "        data_inx = G.forward(fake_input, fake_label).detach()\n",
    "        #print(\"data_inx\", data_inx)\n",
    "\n",
    "        fake = data_dataset[data_inx]\n",
    "        #print('fake', fake)\n",
    "        \n",
    "        fake_input = torch.FloatTensor(fake[0]).to(device)\n",
    "        fake_input = fake_input.reshape(1, fake_input.shape[0], fake_input.shape[1])\n",
    "        fake_label = torch.FloatTensor(fake[1]).to(device)\n",
    "        #print('fake_label.shape', fake_label.shape)\n",
    "        \n",
    "        fake_label = fake_label.view(fake_label.shape[0], 1, 1).repeat(1, fake_input.shape[1], 1)\n",
    "        target = torch.FloatTensor([0.0]).view(1,1,1).repeat(1, fake_input.shape[0] ,1).to(device)\n",
    "        D.train(fake_input, fake_label, target )\n",
    "\n",
    "        \n",
    "        #########################################################                   \n",
    "        # train generator\n",
    "        #########################################################                   \n",
    "        fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "        fake_label = torch.FloatTensor(generate_random_value(G_input_size)).to(device)\n",
    "        #fake_label = fake_label.unsqueeze(1).repeat(1, fake_input.shape[1], 1)\n",
    "        target = torch.FloatTensor([0.0]).view(1,1,1).to(device)\n",
    "        G.train(D, fake_input, fake_label, target)\n",
    "        \n",
    "    pass\n",
    "    \n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "G.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.2335],\n",
      "         [1.0464],\n",
      "         [0.9910],\n",
      "         [1.0026],\n",
      "         [1.0574],\n",
      "         [0.9256],\n",
      "         [1.0306],\n",
      "         [1.1781],\n",
      "         [1.3147],\n",
      "         [1.1278],\n",
      "         [1.0217],\n",
      "         [1.1074],\n",
      "         [1.1430],\n",
      "         [0.8984],\n",
      "         [1.0785],\n",
      "         [0.7798],\n",
      "         [0.9544],\n",
      "         [0.9899],\n",
      "         [1.1536],\n",
      "         [0.9857],\n",
      "         [1.1183],\n",
      "         [1.0405],\n",
      "         [1.0335],\n",
      "         [1.3471],\n",
      "         [0.9836],\n",
      "         [0.9728],\n",
      "         [0.9752],\n",
      "         [0.8600],\n",
      "         [1.0042],\n",
      "         [1.1834],\n",
      "         [1.1134],\n",
      "         [1.1356],\n",
      "         [0.8046],\n",
      "         [1.2327],\n",
      "         [0.7592],\n",
      "         [0.8193],\n",
      "         [0.8659],\n",
      "         [0.8445],\n",
      "         [0.9730],\n",
      "         [1.0772],\n",
      "         [0.9540],\n",
      "         [1.0295],\n",
      "         [0.9511],\n",
      "         [0.9405],\n",
      "         [1.2351],\n",
      "         [1.1187],\n",
      "         [1.0074],\n",
      "         [0.7431],\n",
      "         [1.1731],\n",
      "         [0.9980],\n",
      "         [1.1482],\n",
      "         [0.9551],\n",
      "         [0.8062],\n",
      "         [1.0688],\n",
      "         [0.8948],\n",
      "         [0.7757],\n",
      "         [0.8674],\n",
      "         [0.9349],\n",
      "         [0.9997],\n",
      "         [0.8697],\n",
      "         [0.9140],\n",
      "         [1.0489],\n",
      "         [1.0404],\n",
      "         [1.0788],\n",
      "         [0.9346],\n",
      "         [0.7669],\n",
      "         [1.4155],\n",
      "         [0.9260],\n",
      "         [0.8654],\n",
      "         [0.9681],\n",
      "         [0.7159],\n",
      "         [1.0032],\n",
      "         [1.0650],\n",
      "         [1.2568],\n",
      "         [1.1086],\n",
      "         [1.0281],\n",
      "         [1.1434],\n",
      "         [0.7798],\n",
      "         [1.0346],\n",
      "         [1.1567],\n",
      "         [0.9485],\n",
      "         [1.0786],\n",
      "         [0.9439],\n",
      "         [1.1696],\n",
      "         [0.9724],\n",
      "         [1.1550],\n",
      "         [0.9879],\n",
      "         [0.8679],\n",
      "         [0.9628],\n",
      "         [1.1344],\n",
      "         [0.8625],\n",
      "         [1.1167],\n",
      "         [1.3074],\n",
      "         [1.1446],\n",
      "         [0.9838],\n",
      "         [0.8754],\n",
      "         [1.0526],\n",
      "         [0.8281],\n",
      "         [0.7791],\n",
      "         [1.1042],\n",
      "         [0.8234],\n",
      "         [1.2361],\n",
      "         [1.1098],\n",
      "         [0.8914],\n",
      "         [0.8636],\n",
      "         [0.9043],\n",
      "         [1.0272],\n",
      "         [0.9659],\n",
      "         [0.7000],\n",
      "         [0.8487],\n",
      "         [0.9104],\n",
      "         [1.1336],\n",
      "         [0.8582],\n",
      "         [0.9659],\n",
      "         [1.2339],\n",
      "         [0.7503],\n",
      "         [0.9404],\n",
      "         [0.9506],\n",
      "         [0.8534],\n",
      "         [1.0838],\n",
      "         [1.0060],\n",
      "         [1.0857],\n",
      "         [0.9722],\n",
      "         [1.1109],\n",
      "         [0.9622],\n",
      "         [1.0292],\n",
      "         [1.2184],\n",
      "         [1.0106]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[[1.0808],\n",
      "         [1.2130],\n",
      "         [1.1960],\n",
      "         [1.2693],\n",
      "         [0.8708],\n",
      "         [1.1966],\n",
      "         [1.0881],\n",
      "         [0.9315],\n",
      "         [0.9598],\n",
      "         [0.9285],\n",
      "         [0.8982],\n",
      "         [0.9563],\n",
      "         [0.8001],\n",
      "         [1.0500],\n",
      "         [1.1406],\n",
      "         [0.8997],\n",
      "         [1.1447],\n",
      "         [1.0453],\n",
      "         [0.9453],\n",
      "         [0.9294],\n",
      "         [0.7004],\n",
      "         [0.8989],\n",
      "         [0.9864],\n",
      "         [1.2018],\n",
      "         [0.9799],\n",
      "         [1.0724],\n",
      "         [0.9502],\n",
      "         [1.0381],\n",
      "         [1.1191],\n",
      "         [1.0373],\n",
      "         [0.9050],\n",
      "         [1.0860],\n",
      "         [0.7597],\n",
      "         [1.1251],\n",
      "         [1.0656],\n",
      "         [1.0805],\n",
      "         [0.8171],\n",
      "         [1.1339],\n",
      "         [1.1351],\n",
      "         [0.9353],\n",
      "         [0.9827],\n",
      "         [1.1064],\n",
      "         [1.1699],\n",
      "         [1.0882],\n",
      "         [1.0200],\n",
      "         [0.9411],\n",
      "         [0.8070],\n",
      "         [1.1678],\n",
      "         [1.0600],\n",
      "         [0.8982],\n",
      "         [1.1867],\n",
      "         [0.9626],\n",
      "         [0.9954],\n",
      "         [1.1987],\n",
      "         [0.9755],\n",
      "         [0.9640],\n",
      "         [1.0974],\n",
      "         [1.0604],\n",
      "         [0.9996],\n",
      "         [0.9019],\n",
      "         [0.8228],\n",
      "         [0.8823],\n",
      "         [1.1918],\n",
      "         [0.9964],\n",
      "         [0.9310],\n",
      "         [0.7529],\n",
      "         [1.0829],\n",
      "         [1.1267],\n",
      "         [1.1040],\n",
      "         [0.9741],\n",
      "         [1.0059],\n",
      "         [0.9182],\n",
      "         [0.9904],\n",
      "         [1.0245],\n",
      "         [0.9054],\n",
      "         [1.0237],\n",
      "         [1.1837],\n",
      "         [0.9058],\n",
      "         [0.9677],\n",
      "         [1.0180],\n",
      "         [1.0011],\n",
      "         [0.7458],\n",
      "         [1.0404],\n",
      "         [1.0925],\n",
      "         [0.9808],\n",
      "         [0.8187],\n",
      "         [0.8664],\n",
      "         [0.8511],\n",
      "         [0.9571],\n",
      "         [0.9728],\n",
      "         [0.7377],\n",
      "         [0.7202],\n",
      "         [1.0519],\n",
      "         [0.9923],\n",
      "         [0.8665],\n",
      "         [0.8146],\n",
      "         [0.9345],\n",
      "         [1.0337],\n",
      "         [1.2933],\n",
      "         [1.0305],\n",
      "         [0.9903],\n",
      "         [1.1980],\n",
      "         [0.8219],\n",
      "         [0.9937],\n",
      "         [1.1671],\n",
      "         [1.4522],\n",
      "         [0.7802],\n",
      "         [1.0676],\n",
      "         [1.0863],\n",
      "         [1.0195],\n",
      "         [0.7025],\n",
      "         [0.9943],\n",
      "         [1.0379],\n",
      "         [1.0317],\n",
      "         [0.9297],\n",
      "         [0.7137],\n",
      "         [0.8406],\n",
      "         [1.2017],\n",
      "         [1.0331],\n",
      "         [0.9516],\n",
      "         [1.1354],\n",
      "         [0.9548],\n",
      "         [0.9006],\n",
      "         [1.0255],\n",
      "         [0.9215],\n",
      "         [0.9194],\n",
      "         [0.8740],\n",
      "         [0.7940]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[[0.9684],\n",
      "         [0.9466],\n",
      "         [0.9471],\n",
      "         [1.1040],\n",
      "         [0.7643],\n",
      "         [1.0906],\n",
      "         [1.0263],\n",
      "         [0.6598],\n",
      "         [0.9936],\n",
      "         [0.9883],\n",
      "         [0.9774],\n",
      "         [0.9114],\n",
      "         [0.6885],\n",
      "         [1.0602],\n",
      "         [1.1150],\n",
      "         [0.9753],\n",
      "         [1.2460],\n",
      "         [0.9893],\n",
      "         [1.0496],\n",
      "         [0.8198],\n",
      "         [0.9187],\n",
      "         [1.0177],\n",
      "         [1.1123],\n",
      "         [0.9867],\n",
      "         [0.7442],\n",
      "         [1.1124],\n",
      "         [1.1934],\n",
      "         [0.9445],\n",
      "         [1.1246],\n",
      "         [0.7886],\n",
      "         [0.9784],\n",
      "         [1.2034],\n",
      "         [1.1855],\n",
      "         [1.0797],\n",
      "         [0.9955],\n",
      "         [0.9554],\n",
      "         [1.2206],\n",
      "         [1.0168],\n",
      "         [1.0425],\n",
      "         [1.0854],\n",
      "         [1.1909],\n",
      "         [1.2839],\n",
      "         [1.1850],\n",
      "         [1.0210],\n",
      "         [1.1243],\n",
      "         [0.9034],\n",
      "         [0.9849],\n",
      "         [1.1594],\n",
      "         [0.8855],\n",
      "         [0.9839],\n",
      "         [1.2299],\n",
      "         [0.9470],\n",
      "         [1.1764],\n",
      "         [1.1843],\n",
      "         [0.8822],\n",
      "         [0.7984],\n",
      "         [0.8629],\n",
      "         [1.1761],\n",
      "         [0.8114],\n",
      "         [1.0896],\n",
      "         [1.0483],\n",
      "         [0.7277],\n",
      "         [0.9910],\n",
      "         [0.9441],\n",
      "         [1.0076],\n",
      "         [0.8845],\n",
      "         [0.8687],\n",
      "         [0.7685],\n",
      "         [0.6253],\n",
      "         [0.8319],\n",
      "         [0.8522],\n",
      "         [0.8686],\n",
      "         [0.9881],\n",
      "         [0.9546],\n",
      "         [1.0175],\n",
      "         [0.8007],\n",
      "         [1.0239],\n",
      "         [1.1537],\n",
      "         [1.2147],\n",
      "         [0.8791],\n",
      "         [1.2129],\n",
      "         [0.9552],\n",
      "         [1.0242],\n",
      "         [0.7745],\n",
      "         [1.1813],\n",
      "         [0.8765],\n",
      "         [0.8031],\n",
      "         [0.9117],\n",
      "         [1.3814],\n",
      "         [1.0579],\n",
      "         [0.8700],\n",
      "         [0.9134],\n",
      "         [1.0625],\n",
      "         [1.1014],\n",
      "         [0.9025],\n",
      "         [1.0208],\n",
      "         [1.0608],\n",
      "         [0.9602],\n",
      "         [0.8788],\n",
      "         [0.8555],\n",
      "         [1.0317],\n",
      "         [1.3095],\n",
      "         [0.9983],\n",
      "         [1.0438],\n",
      "         [1.0859],\n",
      "         [0.7868],\n",
      "         [1.2429],\n",
      "         [0.8264],\n",
      "         [1.1995],\n",
      "         [0.6214],\n",
      "         [1.0689],\n",
      "         [1.0830],\n",
      "         [1.0318],\n",
      "         [0.9224],\n",
      "         [1.2622],\n",
      "         [0.9084],\n",
      "         [1.1911],\n",
      "         [0.8874],\n",
      "         [0.9476],\n",
      "         [0.9044],\n",
      "         [0.8120],\n",
      "         [1.2919],\n",
      "         [0.9472],\n",
      "         [0.9391],\n",
      "         [0.9750],\n",
      "         [1.1043],\n",
      "         [1.0995],\n",
      "         [0.7781]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[[0.7561],\n",
      "         [0.9899],\n",
      "         [0.7413],\n",
      "         [1.1944],\n",
      "         [1.0247],\n",
      "         [1.0620],\n",
      "         [1.1556],\n",
      "         [0.8644],\n",
      "         [0.9940],\n",
      "         [1.0462],\n",
      "         [1.0057],\n",
      "         [1.0534],\n",
      "         [0.7977],\n",
      "         [1.0986],\n",
      "         [0.7078],\n",
      "         [1.1009],\n",
      "         [0.7790],\n",
      "         [0.8136],\n",
      "         [1.0287],\n",
      "         [0.8640],\n",
      "         [0.9201],\n",
      "         [1.1128],\n",
      "         [0.9150],\n",
      "         [1.0375],\n",
      "         [1.0601],\n",
      "         [1.1912],\n",
      "         [1.0691],\n",
      "         [1.3489],\n",
      "         [0.9649],\n",
      "         [0.9528],\n",
      "         [0.8498],\n",
      "         [0.9441],\n",
      "         [0.8669],\n",
      "         [0.8966],\n",
      "         [0.7477],\n",
      "         [1.0594],\n",
      "         [1.0917],\n",
      "         [0.9676],\n",
      "         [0.7979],\n",
      "         [0.9061],\n",
      "         [1.1524],\n",
      "         [1.0744],\n",
      "         [0.8803],\n",
      "         [0.8720],\n",
      "         [1.2468],\n",
      "         [0.8984],\n",
      "         [0.7368],\n",
      "         [0.8960],\n",
      "         [0.9263],\n",
      "         [0.9169],\n",
      "         [0.8825],\n",
      "         [0.9677],\n",
      "         [0.9555],\n",
      "         [0.8751],\n",
      "         [1.0358],\n",
      "         [0.9161],\n",
      "         [1.0339],\n",
      "         [0.8958],\n",
      "         [1.0309],\n",
      "         [1.0880],\n",
      "         [0.7457],\n",
      "         [1.2299],\n",
      "         [1.1424],\n",
      "         [1.1015],\n",
      "         [1.0184],\n",
      "         [0.9413],\n",
      "         [0.9073],\n",
      "         [1.1061],\n",
      "         [0.8657],\n",
      "         [1.1767],\n",
      "         [0.9057],\n",
      "         [1.0204],\n",
      "         [0.9978],\n",
      "         [0.8248],\n",
      "         [0.9073],\n",
      "         [0.7415],\n",
      "         [0.7884],\n",
      "         [0.9427],\n",
      "         [0.6988],\n",
      "         [0.9994],\n",
      "         [1.1156],\n",
      "         [1.1217],\n",
      "         [0.8643],\n",
      "         [1.1785],\n",
      "         [1.0331],\n",
      "         [0.9871],\n",
      "         [1.0348],\n",
      "         [0.7401],\n",
      "         [1.0510],\n",
      "         [1.0288],\n",
      "         [0.8744],\n",
      "         [1.0739],\n",
      "         [1.3197],\n",
      "         [1.0350],\n",
      "         [0.9053],\n",
      "         [0.9693],\n",
      "         [1.0438],\n",
      "         [0.9000],\n",
      "         [0.8870],\n",
      "         [0.8221],\n",
      "         [1.0067],\n",
      "         [1.0697],\n",
      "         [0.8971],\n",
      "         [0.8127],\n",
      "         [0.8168],\n",
      "         [1.1648],\n",
      "         [0.9026],\n",
      "         [0.9871],\n",
      "         [0.6281],\n",
      "         [0.9630],\n",
      "         [0.7972],\n",
      "         [0.9121],\n",
      "         [0.9524],\n",
      "         [0.7676],\n",
      "         [1.1618],\n",
      "         [0.9743],\n",
      "         [1.0669],\n",
      "         [0.8315],\n",
      "         [1.1092],\n",
      "         [0.9465],\n",
      "         [1.0401],\n",
      "         [0.7941],\n",
      "         [0.9278],\n",
      "         [0.7891],\n",
      "         [0.7997],\n",
      "         [1.1190],\n",
      "         [0.8343],\n",
      "         [0.9027]]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for smiles,label in data_loader:\n",
    "    # real\n",
    "    target = torch.FloatTensor([1.0]).view(1,1,1).repeat(1, smiles.shape[0] ,1).to(device)\n",
    "    label = label.float().to(device)\n",
    "    label = label.view(batch_size, 1, 1).repeat(1, smiles.shape[1], 1)\n",
    "    print(D.forward(smiles.to(device).float(), label))\n",
    "    \n",
    "    i += 1\n",
    "    if (i >= 4):\n",
    "        break\n",
    "    pass\n",
    "\n",
    "for i in range(4):\n",
    "    fake_input = []\n",
    "    fake_label = []\n",
    "    for finput, label in generate_random_seed(batch_size):\n",
    "        fake_input.append(finput)\n",
    "        fake_label.append(label)\n",
    "    \n",
    "    \n",
    "    fake_input = torch.FloatTensor(fake_input).to(device)\n",
    "    \n",
    "    #fake_input = fake_input.reshape(1, fake_input.shape[0], fake_input.shape[1])\n",
    "    fake_label = torch.FloatTensor(fake_label).to(device)\n",
    "    #print('2.before change label.shape', fake_input.shape, 'fake_label', fake_label.shape)\n",
    "    fake_label = fake_label.view(batch_size, 1, 1).repeat(1, fake_input.shape[1], 1)\n",
    "    #print('fake_input.shape', fake_input.shape, 'fake_label.shape', fake_label.shape)\n",
    "    target = torch.FloatTensor([0.0]).view(1,1,1).repeat(1, fake_input.shape[0] ,1).to(device)\n",
    "    D.forward(fake_input, fake_label)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result tensor(47370, device='cuda:0') idx 47370 fake_input torch.Size([100]) fake_label.shape torch.Size([100]) result.shape torch.Size([])\n",
      "O=C1CCOC(C1)C#C\n"
     ]
    }
   ],
   "source": [
    "fake_input = torch.FloatTensor(generate_random_seed_G(G_input_size)).to(device)\n",
    "fake_label = torch.FloatTensor(generate_random_value(G_input_size)).to(device)\n",
    "result = G.forward(fake_input, fake_label).detach()\n",
    "idx = result.cpu().numpy()\n",
    "print('result', result, 'idx', idx, 'fake_input', fake_input.shape, 'fake_label.shape', fake_label.shape,  'result.shape', result.shape)\n",
    "        \n",
    "#idx = self.get_index(G.forward(fake_input, fake_label)).detach().cpu().numpy()\n",
    "print(data['smiles'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O=C1CCOC(C1)C#C\n",
      "CC(=O)NCCC#N\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1C2CC3C(N23)C1=O\n",
      "COC1C2CC(O)C12\n",
      "CCC1CC=CC1OC\n",
      "O=C1CCOC(C1)C#C\n",
      "C1CC11OCCC11CN1\n",
      "CC1C2C(O)C2(O)C1O\n",
      "O=C1CCOC(C1)C#C\n",
      "CCC12OC1C(C)C2C\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1(C=O)C2CCCC12\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1(C)C2CCC=CC12\n",
      "CC1CN2CC2(C)CO1\n",
      "O=C1CCOC(C1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "O=CC1C2OC=NC12\n",
      "CC1C(=O)C=CC1(C)O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "c1c(c(nc(=O)o1)F)F\n",
      "C#Cc1cnc(cn1)F\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC1COC(C)(O1)C#C\n",
      "CN1C2C3OC2(C#N)C13\n",
      "CC(=O)C(CO)CO\n",
      "CC1COC(C)(O1)C#C\n",
      "CC1C2CN1C21CC1O\n",
      "COC1CCOCC=C1\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CN1C2C3OC2(C#N)C13\n",
      "O=CC1NC(=O)C1C#C\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CCC12OC1C(C)C2C\n",
      "c1(c(nc([nH]1)O)O)N\n",
      "CC1(C=O)C2CCCC12\n",
      "O=C1CCOC(C1)C#C\n",
      "COC1CCOCC=C1\n",
      "CC1C2C(O)C2(O)C1O\n",
      "COC1CCOCC=C1\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC1OCC2CCC12O\n",
      "CN1C2C3OC2(C#N)C13\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1CC=C(C)C1C#N\n",
      "COC1CCOCC=C1\n",
      "CC(=O)NCCC#N\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "c1cc(cnc1)C(=O)N\n",
      "CC(=O)C(CO)CO\n",
      "CC1C2CC3C(N23)C1=O\n",
      "COC1CCOCC=C1\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC1(C=O)C2CCCC12\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC1CC1N=C(N)C=O\n",
      "CCC1(CC)CN2CC12\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC1CC1N=C(N)C=O\n",
      "O=CC1NC(=O)C1C#C\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "COC1CCOCC=C1\n",
      "FC1=NC(F)=NC(=N)N1\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2CC3C(N23)C1=O\n",
      "C1NC11C2C3N2CC=C13\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1C2CC3C(N23)C1=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2CC3C(N23)C1=O\n",
      "COC1CCOCC=C1\n",
      "OC1C2C3CCOC2C13\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC1OCC2CCC12O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "O=C1CCOC(C1)C#C\n",
      "OC1CC1N1N=CC=N1\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1(C)C2CCC=CC12\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CCC12OC1C(C)C2C\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC1NC=CC(=O)C1C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC1COC(C)(O1)C#C\n",
      "O=CC1NC(=O)C1C#C\n",
      "O=CC1NC(=O)C1C#C\n",
      "CC1CC1N=C(N)C=O\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(G.get_smiles(5.1411))\n",
    "#CC1CC1,41.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COC1CCOCC=C1\n",
      "CC(=O)NCCC#N\n",
      "COC1CCOCC=C1\n",
      "CC1(C=O)C2CCCC12\n",
      "CC1CC1N1N=CC=N1\n",
      "COC1CCOCC=C1\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(C)CC1CC(=O)C1\n",
      "CC1(C=O)C2CCCC12\n",
      "CC1C2CC3C(N23)C1=O\n",
      "C#Cc1cnc(cn1)F\n",
      "COC1C2NC1C2O\n",
      "CC1CC1N=C(N)C=O\n",
      "OC12CNC1C=CC2=O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC(O)C(=O)C#CC=O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "O=CC1NC(=O)C1C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "CN1C2C3OC2(C#N)C13\n",
      "COC1CCOCC=C1\n",
      "CC1CC1N=C(N)C=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "COC1CC(=O)CC1O\n",
      "OC12CC(C1)C1OC21\n",
      "CC(=O)NCCC#N\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1C2CC=CC12O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "COC1CCOCC=C1\n",
      "COC1CCOCC=C1\n",
      "c1coc2c1CCC2=O\n",
      "O=C1CCOC(C1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(=O)NCCC#N\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CCC1=CC(CC1)C=O\n",
      "COC1CCOCC=C1\n",
      "Cc1cnc(nn1)C#C\n",
      "CC1OCC2CCC12O\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1COC(C)(O1)C#C\n",
      "CCC1(NC1C=O)C=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(O)C(=O)C#CC=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "O=C1CCOC(C1)C#C\n",
      "COC1CCOCC=C1\n",
      "CC1C2CN1C21CC1O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "C(=O)c1c([nH]nc1O)N\n",
      "CC1C2C(O)C2(O)C1O\n",
      "[O-]C(=O)C[NH2+]C1CCC1\n",
      "CC1OCC2CCC12O\n",
      "COC1CCOCC=C1\n",
      "O=CC1NC(=O)C1C#C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "OC1CCC1C1(O)CC1\n",
      "CC1CC1N=C(N)C=O\n",
      "COC1CCOCC=C1\n",
      "O=CC1C2OC=NC12\n",
      "CC#CC#CC(C)(C)O\n",
      "OC(C#N)C1COC=N1\n",
      "COC1CCOCC=C1\n",
      "O=C1CCOC(C1)C#C\n",
      "ON=C1C(O)COC1=N\n",
      "CC1C2CN1C21CC1O\n",
      "NC(=O)NC1CCC1O\n",
      "CC1(C=O)C2CCCC12\n",
      "OC(C#N)C1COC=N1\n",
      "CC1COC(C)(O1)C#C\n",
      "O=CC1NC(=O)C1C#C\n",
      "N#CCC1CC=CC1\n",
      "CC1COC(C)(O1)C#C\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1C2CN1C21CC1O\n",
      "CC1COC(C)(O1)C#C\n",
      "COC1CCOCC=C1\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1COC(C)(O1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "OC12CNC1C=CC2=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2CC3C(N23)C1=O\n",
      "C#Cc1cnc(cn1)F\n",
      "CC1C2C(O)C2(O)C1O\n",
      "C#Cc1cnc(cn1)F\n",
      "COC1CCOCC=C1\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(G.get_smiles(1.9354))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OC12CC(C1)C1OC21\n",
      "CC1C2NC2C1C#C\n",
      "CC(=O)C(CO)CO\n",
      "CNC(CN)C#N\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CCOCC1=CCOC1\n",
      "N#CC1C=CC2CN12\n",
      "COC1CCOCC=C1\n",
      "CC1COC(C)(O1)C#C\n",
      "CC(=O)NCCC#N\n",
      "CC1C2C(O)C2(O)C1O\n",
      "COC1CCOCC=C1\n",
      "CC1=CN(CC1=NO)C\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "COC=NC1CCC1C\n",
      "CC1CC1N=C(N)C=O\n",
      "COC1CCOCC=C1\n",
      "CC1(C=O)C2CCCC12\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1C2C(O)C2(O)C1O\n",
      "COC1CCOCC=C1\n",
      "CC1CC1N=C(N)C=O\n",
      "O=C1CCOC(C1)C#C\n",
      "OC12CNC1C=CC2=O\n",
      "CC1C2C(O)C2(O)C1O\n",
      "N=C1OC2CC(C2)C1=O\n",
      "CC1CC1N=C(N)C=O\n",
      "Cc1cnc(nn1)C#C\n",
      "OC1CCC1C1(O)CC1\n",
      "O=C1CCOC(C1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "OC1C(C=O)C11COC1\n",
      "CNC(=N)C(=O)CC#C\n",
      "C#Cc1cnc(cn1)F\n",
      "COC1CCOCC=C1\n",
      "CCN1CC1CC(N)=O\n",
      "[NH3+]C(CC#C)C([O-])=O\n",
      "CC1CC1N=C(N)C=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CCN1CC1CC(N)=O\n",
      "COC1CCOCC=C1\n",
      "C1C2C1C13CC4C1C2C34\n",
      "CCC1(NC1C=O)C=O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "OC1CC2OC=NC12\n",
      "CC1C2C(O)C2(O)C1O\n",
      "COC1CCOCC=C1\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC1COC(C)(O1)C#C\n",
      "CCC(C=O)C#CCO\n",
      "CC1=NCC2CC2CO1\n",
      "[NH3+]C(CC#C)C([O-])=O\n",
      "NC1=NC(COC1)C=O\n",
      "O=CC1NC(=O)C1C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "COC1CCOCC=C1\n",
      "CC1COC(C)(O1)C#C\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CNC(=N)C(=O)CC#C\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "COC1CCOCC=C1\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1CC1N=C(N)C=O\n",
      "COC1CC(=O)CC1O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1(C)C2CCC=CC12\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC1C2C(O)C2(O)C1O\n",
      "Cc1c(ocn1)N(=O)=O\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC1CC1N=C(N)C=O\n",
      "OC(C#N)C1COC=N1\n",
      "COC1CCOCC=C1\n",
      "CC1C2CC3C(N23)C1=O\n",
      "OCC1NC2C1OC2=N\n",
      "C1CC11OCCC11CN1\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "COC1CC(=O)CC1O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "O=C1CCOC(C1)C#C\n",
      "C1C2C1C13CC4C1C2C34\n",
      "C#Cc1cnc(cn1)F\n",
      "COC1CCOCC=C1\n",
      "OC12CNC1C=CC2=O\n",
      "CCC(=O)NC(=N)CO\n",
      "COC1CCOCC=C1\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC(C)CC1CC(=O)C1\n",
      "CC(=O)C(CO)CO\n",
      "COC1CCOCC=C1\n",
      "CC1C2C(O)C2(O)C1O\n",
      "COC1CCOCC=C1\n",
      "CC1C2C(O)C2(O)C1O\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(G.get_smiles(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC1(C)C2N3CC3C12O\n",
      "CNC(=N)C(=O)CC#C\n",
      "CC1(C=O)C2CCCC12\n",
      "O=C1CCOC(C1)C#C\n",
      "OC12CC(C1)OCOC2\n",
      "CC1(C=O)C2CCCC12\n",
      "CCC12OC1C(C)C2C\n",
      "COC1CCOCC=C1\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1C2CC3C(N23)C1=O\n",
      "C#Cc1cnc(cn1)F\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(=O)NCCC#N\n",
      "O=C1CCOC(C1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(=O)NCCC#N\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC(=O)NCCC#N\n",
      "O=C1CCOC(C1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "COC(=O)CC1NC1C\n",
      "CC1COC(C)(O1)C#C\n",
      "CC1C2C(O)C2(O)C1O\n",
      "COC1CCOCC=C1\n",
      "O=C1CCOC(C1)C#C\n",
      "COC1CCOCC=C1\n",
      "CCOC=NCCC#N\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CNC(=N)C(=O)CC#C\n",
      "O=C1CCOC(C1)C#C\n",
      "CN1C2C3OC2(C#N)C13\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1COC(C)(O1)C#C\n",
      "COC1CCOCC=C1\n",
      "O=C1CCOC(C1)C#C\n",
      "COC1CCOCC=C1\n",
      "CC1CC1N=C(N)C=O\n",
      "c1cnc(cc1N)O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "O=C1CCOC(C1)C#C\n",
      "O=CC1NC(=O)C1C#C\n",
      "CC(=O)C(CO)CO\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "O=CC1NC(=O)C1C#C\n",
      "CC1CC1N=C(N)C=O\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "O=C1CCOC(C1)C#C\n",
      "OC12CNC1C=CC2=O\n",
      "CC1CCC(=O)C=C1\n",
      "O=C1CCOC(C1)C#C\n",
      "CNC(=N)C(=O)CC#C\n",
      "CC(=O)NCCC#N\n",
      "NC(=O)NC1CCC1O\n",
      "OC1CC(O)C(C1)C=O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1OCC2CCC12O\n",
      "C1OC2COCC2=C1\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1C2C(O)C2(O)C1O\n",
      "CN1C2C3OC2(C#N)C13\n",
      "CC1COC(C)(O1)C#C\n",
      "O=C1CCOC(C1)C#C\n",
      "COC1CCOCC=C1\n",
      "CC1(C=O)C2CCCC12\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1(C=O)C2CCCC12\n",
      "OC12C3CC(C13)C21CO1\n",
      "CC1(C=O)C2CCCC12\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC1CC1N=C(N)C=O\n",
      "CC(=O)NCCC#N\n",
      "COC1CC(=O)CC1O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC(=O)NCCC#N\n",
      "COC1CNC11COC1\n",
      "N#CC1(CCO1)C1CO1\n",
      "O=C1CCOC(C1)C#C\n",
      "CCC1(NC1C=O)C=O\n",
      "CC1OCC2CCC12O\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC(=O)NCCC#N\n",
      "CC1OCC2CCC12O\n",
      "CC1COC(C)(O1)C#C\n",
      "OC(C#N)C1COC=N1\n",
      "CC(O)C12C3C4C(C13)N24\n",
      "OC12CNC1C=CC2=O\n",
      "CN=c1oc(no1)C#C\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC1(C=O)C2CCCC12\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CC1OCC2CCC12O\n",
      "CC1C2CC3C(N23)C1=O\n",
      "CCC12CC3C(C1O)N23\n",
      "O=C1CCOC(C1)C#C\n",
      "CC1C2C(O)C2(O)C1O\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(G.get_smiles(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model to file: pre_train_model/GAN13G202104121727.sav\n",
      "save model to file: pre_train_model/GAN13G202104121727.sav\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now() \n",
    "date_time = now.strftime(\"%Y%m%d%H%M\")\n",
    "G_filename = 'pre_train_model/GAN13G' + date_time + '.sav'\n",
    "print('save model to file:', G_filename)\n",
    "pickle.dump(G, open(G_filename, 'wb'))\n",
    "\n",
    "D_filename = 'pre_train_model/GAN13D' + date_time + '.sav'\n",
    "print('save model to file:', G_filename)\n",
    "pickle.dump(D, open(D_filename, 'wb'))\n",
    "\n",
    "\n",
    "#G_model = pickle.load(open(G_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
